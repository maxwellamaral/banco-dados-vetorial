# Dockerfile para Ollama com modelos de embeddings pr√©-instalados
# Baseado em ollama/ollama:latest com modelos necess√°rios para o curso
# Data: 2025-12-08

FROM ollama/ollama:latest

# Instalar curl se n√£o estiver dispon√≠vel
USER root
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*

# Criar script para baixar modelos
RUN echo '#!/bin/bash\n\
set -e\n\
echo "üöÄ Iniciando Ollama em background..."\n\
ollama serve &\n\
OLLAMA_PID=$!\n\
\n\
echo "‚è≥ Aguardando Ollama ficar online..."\n\
for i in {1..30}; do\n\
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then\n\
        echo "‚úÖ Ollama est√° online!"\n\
        break\n\
    fi\n\
    echo "   Tentativa $i/30..."\n\
    sleep 2\n\
done\n\
\n\
echo "üì¶ Baixando modelos de embeddings..."\n\
echo ""\n\
\n\
echo "1Ô∏è‚É£ Baixando all-minilm:latest (384 dim, ~23MB)..."\n\
ollama pull all-minilm:latest\n\
echo "‚úÖ all-minilm:latest instalado!"\n\
echo ""\n\
\n\
echo "2Ô∏è‚É£ Baixando nomic-embed-text:latest (768 dim, ~274MB)..."\n\
ollama pull nomic-embed-text:latest\n\
echo "‚úÖ nomic-embed-text:latest instalado!"\n\
echo ""\n\
\n\
echo "3Ô∏è‚É£ Baixando mxbai-embed-large:latest (1024 dim, ~670MB)..."\n\
ollama pull mxbai-embed-large:latest\n\
echo "‚úÖ mxbai-embed-large:latest instalado!"\n\
echo ""\n\
\n\
echo "üéâ Todos os modelos foram instalados com sucesso!"\n\
echo "üìã Modelos dispon√≠veis:"\n\
ollama list\n\
echo ""\n\
\n\
echo "üõë Parando Ollama tempor√°rio..."\n\
kill $OLLAMA_PID\n\
wait $OLLAMA_PID 2>/dev/null || true\n\
\n\
echo "‚úÖ Setup completo! Container pronto para uso."\n\
' > /usr/local/bin/setup-models.sh && chmod +x /usr/local/bin/setup-models.sh

# Executar setup de modelos durante o build
# NOTA: Isso aumenta o tempo de build mas garante que os modelos estejam dispon√≠veis
RUN /usr/local/bin/setup-models.sh

# Expor porta padr√£o
EXPOSE 11434

# Comando padr√£o (serve Ollama)
CMD ["ollama", "serve"]
