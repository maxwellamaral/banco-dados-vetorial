{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2349cee0",
   "metadata": {},
   "source": [
    "## üìö Lab 1.4 - Comparativo de Modelos de Embeddings (APIs Cloud)\n",
    "\n",
    "### üéØ Objetivo deste notebook\n",
    "\n",
    "Neste laborat√≥rio, vamos **comparar modelos de embeddings de APIs cloud**:\n",
    "- **OpenAI** - `text-embedding-3-small` e `text-embedding-3-large`\n",
    "- **Google Gemini** - `gemini-embedding-001`\n",
    "\n",
    "**O que vamos avaliar:**\n",
    "1. ‚úÖ **Dimensionalidade** - Tamanho dos vetores (384, 768, 1536, 3072)\n",
    "2. ‚úÖ **Qualidade sem√¢ntica** - Capacidade de distinguir conceitos\n",
    "3. ‚úÖ **Tokens consumidos** - Contagem EXATA via APIs oficiais\n",
    "4. ‚úÖ **Custo real** - C√°lculo baseado em tokens exatos (n√£o estimados)\n",
    "5. ‚úÖ **Visualiza√ß√µes** - Gr√°ficos de similaridade e custos\n",
    "\n",
    "### üí° Por que comparar APIs cloud?\n",
    "\n",
    "**Vantagens das APIs:**\n",
    "- ‚úÖ Sem necessidade de infraestrutura (GPU, servidores)\n",
    "- ‚úÖ Escalabilidade autom√°tica\n",
    "- ‚úÖ Modelos state-of-the-art sempre atualizados\n",
    "- ‚úÖ Baixa lat√™ncia (rede global otimizada)\n",
    "\n",
    "**Desvantagens:**\n",
    "- ‚ùå Custo por token (paga por uso)\n",
    "- ‚ùå Dados enviados para nuvem (privacidade)\n",
    "- ‚ùå Depend√™ncia de internet\n",
    "\n",
    "### üîß Passo 1: Depend√™ncias\n",
    "\n",
    "Instale as bibliotecas necess√°rias (j√° dispon√≠veis no container Jupyter):\n",
    "\n",
    "```bash\n",
    "pip install -U openai numpy scikit-learn python-dotenv langchain-google-genai requests\n",
    "```\n",
    "\n",
    "**Bibliotecas usadas:**\n",
    "- `openai` - SDK oficial da OpenAI\n",
    "- `langchain-google-genai` - Integra√ß√£o Google com LangChain\n",
    "- `requests` - Chamadas REST diretas (para obter metadados completos do Google)\n",
    "- `numpy` - C√°lculos de similaridade cosseno\n",
    "- `dotenv` - Gerenciamento de API keys\n",
    "\n",
    "**‚ö†Ô∏è Nota importante:** N√£o instale `google-generativeai` junto com `langchain-google-genai` (conflito de depend√™ncias). Usamos REST API direta quando precisamos de metadados completos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "834d2801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.5) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Tuple, Optional\n",
    "from openai import OpenAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580f850",
   "metadata": {},
   "source": [
    "## üîë Passo 2: Configurar API Keys\n",
    "\n",
    "As APIs cloud exigem **chaves de autentica√ß√£o** para uso.\n",
    "\n",
    "#### Como obter API keys:\n",
    "\n",
    "**OpenAI:**\n",
    "1. Acesse: https://platform.openai.com/api-keys\n",
    "2. Crie uma conta (se n√£o tiver)\n",
    "3. Gere uma nova API key (come√ßar√° com `sk-...`)\n",
    "4. **Importante:** Copie imediatamente (s√≥ aparece uma vez!)\n",
    "\n",
    "**Google Gemini:**\n",
    "1. Acesse: https://aistudio.google.com/app/apikey\n",
    "2. Fa√ßa login com conta Google\n",
    "3. Clique em \"Create API key\"\n",
    "4. Copie a chave gerada\n",
    "\n",
    "#### Estrutura do arquivo `.env`:\n",
    "\n",
    "Crie um arquivo `.env` na raiz do projeto:\n",
    "\n",
    "```ini\n",
    "OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxx\n",
    "GOOGLE_API_KEY=AIzaSyXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "```\n",
    "\n",
    "**Seguran√ßa:**\n",
    "- ‚úÖ Arquivo `.env` deve estar no `.gitignore` (n√£o commitar!)\n",
    "- ‚úÖ Nunca compartilhe suas API keys publicamente\n",
    "- ‚úÖ Use vari√°veis de ambiente em produ√ß√£o\n",
    "\n",
    "O c√≥digo abaixo verifica se as chaves foram carregadas corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b5308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé .env carregado -> E:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\.env\n",
      "OPENAI_API_KEY set? -> True\n",
      "GOOGLE_API_KEY set? -> True\n"
     ]
    }
   ],
   "source": [
    "# 2) Configura√ß√£o e carregamento do .env (simplificado)\n",
    "env_path = Path.cwd().joinpath('..', '..', '.env').resolve()\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f'üîé .env carregado -> {env_path.resolve()}')\n",
    "else:\n",
    "    print('‚ö†Ô∏è  .env n√£o encontrado. Defina as vari√°veis de ambiente manualmente.')\n",
    "\n",
    "\n",
    "# Checar chaves (r√≥tulos simples)\n",
    "print('OPENAI_API_KEY set? ->', bool(os.getenv('OPENAI_API_KEY')))\n",
    "print('GOOGLE_API_KEY set? ->', bool(os.getenv('GOOGLE_API_KEY')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1de86d",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Passo 3: Fun√ß√µes de Embedding\n",
    "\n",
    "Vamos criar **wrappers simples** para as APIs de embeddings.\n",
    "\n",
    "### Arquitetura das fun√ß√µes:\n",
    "\n",
    "```python\n",
    "openai_embedding(text) ‚Üí (embedding_vector, token_count)\n",
    "google_embedding(text) ‚Üí (embedding_vector, token_count)\n",
    "```\n",
    "\n",
    "**Fluxo interno:**\n",
    "1. Recebe texto (ex: \"O gato √© um animal dom√©stico\")\n",
    "2. Envia para API cloud via HTTP\n",
    "3. API processa com modelo de embeddings\n",
    "4. Retorna vetor + metadados (tokens, dimens√µes)\n",
    "\n",
    "### Por que retornar tokens?\n",
    "\n",
    "**Tokens s√£o a unidade de cobran√ßa das APIs:**\n",
    "- OpenAI: $0.02 por 1M tokens (small), $0.13 por 1M tokens (large)\n",
    "- Google: Free at√© limite, depois $0.15 por 1M tokens\n",
    "\n",
    "üí° **Analogia:** √â como um t√°xi - voc√™ paga pela \"dist√¢ncia percorrida\" (tokens processados), n√£o pelo n√∫mero de chamadas.\n",
    "\n",
    "**Contagem exata vs estimada:**\n",
    "- ‚úÖ **EXATA** (oficial): Retornada pela API (usada neste notebook)\n",
    "- ‚ùå **ESTIMADA** (heur√≠stica): ~4 chars = 1 token (imprecisa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e3874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OpenAI embedding wrapper\n",
    "def openai_embedding(text: str, model: str = 'text-embedding-3-small', return_usage: bool = False) -> Tuple[List[float], Optional[int]]:\n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    resp = client.embeddings.create(input=text, model=model)\n",
    "    emb = resp.data[0].embedding\n",
    "    if return_usage:\n",
    "        usage = getattr(resp, 'usage', None)\n",
    "        total_tokens = getattr(usage, 'total_tokens', None) if usage is not None else None\n",
    "        return emb, total_tokens\n",
    "    return emb, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef441742",
   "metadata": {},
   "source": [
    "## üîç Implementa√ß√£o REST da API Google (Detalhes T√©cnicos)\n",
    "\n",
    "A fun√ß√£o `google_embedding` usa **duas abordagens** dependendo da necessidade:\n",
    "\n",
    "##### Modo 1: `return_usage=True` (Tokens Exatos)\n",
    "\n",
    "**Fluxo completo:**\n",
    "\n",
    "```text\n",
    "1. POST https://generativelanguage.googleapis.com/v1beta/models/{model}:embedContent\n",
    "   ‚Üì\n",
    "2. Recebe: embedding + metadados (pode incluir tokenCount)\n",
    "   ‚Üì\n",
    "3. Se tokenCount n√£o vier, faz 2¬™ chamada:\n",
    "   POST .../{model}:countTokens\n",
    "   ‚Üì\n",
    "4. Retorna: (embedding, token_count_exato)\n",
    "```\n",
    "\n",
    "**Endpoints usados:**\n",
    "- `:embedContent` - Gera embeddings + retorna metadados\n",
    "- `:countTokens` - Conta tokens de um texto (fallback)\n",
    "\n",
    "##### Modo 2: `return_usage=False` (Simples)\n",
    "\n",
    "**Fluxo simplificado:**\n",
    "\n",
    "```text\n",
    "1. Usa GoogleGenerativeAIEmbeddings do LangChain\n",
    "   ‚Üì\n",
    "2. Retorna apenas embedding (sem contagem de tokens)\n",
    "```\n",
    "\n",
    "### Por que usar REST direta?\n",
    "\n",
    "| Aspecto | Google REST | OpenAI REST | LangChain |\n",
    "|---------|-------------|-------------|-----------|\n",
    "| **Token count** | ‚úÖ Exato (embedContent/countTokens) | ‚úÖ Exato (response.usage.total_tokens) | ‚ùå Nem sempre dispon√≠vel |\n",
    "| **Metadados** | ‚úÖ Completos | ‚úÖ Completos | ‚ö†Ô∏è Limitados (depende do wrapper) |\n",
    "| **Simplicidade** | ‚ùå Mais c√≥digo (requests + parsing) | ‚úÖ SDK simplifica | ‚úÖ Mais f√°cil (integra√ß√£o LangChain) |\n",
    "| **Conflitos** | ‚úÖ Nenhum | ‚úÖ Nenhum | ‚ö†Ô∏è Poss√≠vel com google-generativeai |\n",
    "\n",
    "### Fallback robusto\n",
    "\n",
    "Se a REST API falhar (rede, erro tempor√°rio):\n",
    "```python\n",
    "try:\n",
    "    # Tenta REST API\n",
    "    embedding = rest_api_call()\n",
    "except:\n",
    "    # Fallback para LangChain + estimativa\n",
    "    embedding = langchain_call()\n",
    "    tokens = estimate_tokens(text)  # ~1 token por 4 chars\n",
    "```\n",
    "\n",
    "### üìñ Documenta√ß√£o oficial:\n",
    "\n",
    "- **embedContent**: https://ai.google.dev/api/rest/v1beta/models/embedContent\n",
    "- **countTokens**: https://ai.google.dev/api/rest/v1beta/models/countTokens\n",
    "- **Pricing**: https://ai.google.dev/gemini-api/docs/pricing#gemini-embedding\n",
    "\n",
    "üí° **Dica:** Para casos simples, use LangChain. Para controle de custos preciso, use REST direta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e48934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Google embedding wrapper (retorna embedding e tokens exatos via REST API)\n",
    "def google_embedding(text: str, model: str = 'gemini-embedding-001', return_usage: bool = True) -> Tuple[List[float], Optional[int]]:        \n",
    "    \"\"\"\n",
    "    Gera embeddings usando Google Gemini.\n",
    "    \n",
    "    Quando return_usage=True, usa REST API direta para obter token count exato.\n",
    "    Quando return_usage=False, usa LangChain para simplicidade.\n",
    "    \"\"\"\n",
    "    if return_usage:\n",
    "        # Usar REST API direta para obter metadados completos incluindo token count\n",
    "        import requests\n",
    "        \n",
    "        api_key = os.getenv('GOOGLE_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError('GOOGLE_API_KEY n√£o encontrada nas vari√°veis de ambiente')\n",
    "        \n",
    "        url = f'https://generativelanguage.googleapis.com/v1beta/models/{model}:embedContent?key={api_key}'\n",
    "        \n",
    "        headers = {\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            'model': f'models/{model}',\n",
    "            'content': {\n",
    "                'parts': [{'text': text}]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=payload)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            # Extrair embedding\n",
    "            embedding = data.get('embedding', {}).get('values', [])\n",
    "            \n",
    "            # Extrair token count (pode estar em diferentes locais dependendo da vers√£o da API)\n",
    "            token_count = None\n",
    "            \n",
    "            # Tentar extrair de metadata\n",
    "            if 'metadata' in data:\n",
    "                token_count = data['metadata'].get('tokenCount')\n",
    "            \n",
    "            # Fallback: usar a API de count tokens se n√£o vier na resposta\n",
    "            if token_count is None:\n",
    "                count_url = f'https://generativelanguage.googleapis.com/v1beta/models/{model}:countTokens?key={api_key}'\n",
    "                count_payload = {\n",
    "                    'contents': [{'parts': [{'text': text}]}]\n",
    "                }\n",
    "                count_response = requests.post(count_url, headers=headers, json=count_payload)\n",
    "                if count_response.status_code == 200:\n",
    "                    count_data = count_response.json()\n",
    "                    token_count = count_data.get('totalTokens')\n",
    "            \n",
    "            return list(embedding), token_count\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f'Erro na chamada REST API do Google: {e}')\n",
    "            # Fallback para LangChain com estimativa\n",
    "            emb = GoogleGenerativeAIEmbeddings(model=model).embed_query(text)\n",
    "            estimated_tokens = len(text) // 4\n",
    "            return list(emb), estimated_tokens\n",
    "    else:\n",
    "        # Usar LangChain quando n√£o precisar de usage (mais simples)\n",
    "        emb = GoogleGenerativeAIEmbeddings(model=model).embed_query(text)\n",
    "        return list(emb), None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9d81c",
   "metadata": {},
   "source": [
    "## üß™ Passo 4: Experimento Pr√°tico\n",
    "\n",
    "Vamos gerar embeddings para **3 frases cuidadosamente escolhidas** e medir similaridade.\n",
    "\n",
    "### Dataset de teste:\n",
    "\n",
    "| # | Frase | Conceito |\n",
    "|---|-------|----------|\n",
    "| 1 | \"O gato √© um animal dom√©stico\" | Animais/Pets |\n",
    "| 2 | \"O gato √© um felino de estima√ß√£o\" | Animais/Pets |\n",
    "| 3 | \"A programa√ß√£o √© importante para engenheiros de software\" | Tecnologia |\n",
    "\n",
    "### O que esperamos?\n",
    "\n",
    "‚úÖ **Similaridade 1-2 ALTA** (>0.8)\n",
    "- Ambas falam de **gatos** como **animais de estima√ß√£o**\n",
    "- Conceitos semanticamente id√™nticos\n",
    "- Embeddings deveriam ser muito pr√≥ximos\n",
    "\n",
    "‚úÖ **Similaridade 1-3 BAIXA** (<0.4)\n",
    "- Conceitos completamente **distintos** (animais vs tecnologia)\n",
    "- Sem rela√ß√£o sem√¢ntica\n",
    "- Embeddings deveriam ser distantes\n",
    "\n",
    "üí° **Analogia:** √â como testar se um detector de cores consegue distinguir:\n",
    "- Vermelho vs Rosa (similar) ‚Üí Deveria dar score alto\n",
    "- Vermelho vs Azul (diferente) ‚Üí Deveria dar score baixo\n",
    "- **Grande diferen√ßa** = Detector funciona bem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca89e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo e compara√ß√£o: gerar embeddings e calcular similaridade\n",
    "\n",
    "def cosine_sim(v1, v2):\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "\n",
    "texts = [\n",
    "    'O gato √© um animal dom√©stico',\n",
    "    'O gato √© um felino de estima√ß√£o',\n",
    "    'A programa√ß√£o √© importante para engenheiros de software'\n",
    "]\n",
    "\n",
    "emb1 = emb2 = emb3 = None\n",
    "backend = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2147ae",
   "metadata": {},
   "source": [
    "## üìê Similaridade Cosseno - Fundamentos Matem√°ticos\n",
    "\n",
    "A **similaridade cosseno** √© a m√©trica mais usada para comparar embeddings. Ela mede o **√¢ngulo entre dois vetores** no espa√ßo multidimensional.\n",
    "\n",
    "### Intui√ß√£o visual:\n",
    "\n",
    "```text\n",
    "Espa√ßo 2D (simplificado):\n",
    "\n",
    "Vetor A (texto 1): ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí (dire√ß√£o: 30¬∞)\n",
    "Vetor B (texto 2): ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  (dire√ß√£o: 35¬∞)  ‚Üê √Çngulo pequeno = SIMILAR\n",
    "Vetor C (texto 3):    ‚Üì      (dire√ß√£o: 90¬∞)  ‚Üê √Çngulo grande = DIFERENTE\n",
    "                      \n",
    "Similaridade A-B: cos(5¬∞) ‚âà 0.996 (muito similar!)\n",
    "Similaridade A-C: cos(60¬∞) ‚âà 0.5 (moderado)\n",
    "Similaridade A-D: cos(90¬∞) = 0.0 (perpendiculares, sem rela√ß√£o)\n",
    "```\n",
    "\n",
    "### F√≥rmula matem√°tica:\n",
    "\n",
    "$$\n",
    "\\text{cosine\\_similarity}(v_1, v_2) = \\frac{v_1 \\cdot v_2}{\\|v_1\\| \\times \\|v_2\\|}\n",
    "$$\n",
    "\n",
    "**Componentes:**\n",
    "- $v_1 \\cdot v_2$ = **Produto escalar** (dot product)\n",
    "  - Soma dos produtos elemento a elemento: $\\sum_{i} v_{1i} \\times v_{2i}$\n",
    "- $\\|v_1\\|$ = **Norma L2** do vetor 1\n",
    "  - Comprimento do vetor: $\\sqrt{\\sum_{i} v_{1i}^2}$\n",
    "- $\\|v_2\\|$ = **Norma L2** do vetor 2\n",
    "\n",
    "### Interpreta√ß√£o dos valores:\n",
    "\n",
    "| Valor | √Çngulo | Significado | Exemplo |\n",
    "|-------|--------|-------------|---------|\n",
    "| **1.0** | 0¬∞ | Vetores id√™nticos | Mesma frase repetida |\n",
    "| **0.9 - 0.99** | 0¬∞ - 26¬∞ | Muito similares | \"Gato\" vs \"Felino\" |\n",
    "| **0.7 - 0.89** | 26¬∞ - 45¬∞ | Similares | \"Cachorro\" vs \"Animal\" |\n",
    "| **0.5 - 0.69** | 45¬∞ - 60¬∞ | Moderadamente relacionados | \"Cachorro\" vs \"Treinamento\" |\n",
    "| **0.3 - 0.49** | 60¬∞ - 73¬∞ | Pouco relacionados | \"Cachorro\" vs \"Computador\" |\n",
    "| **0.0 - 0.29** | 73¬∞ - 90¬∞ | Sem rela√ß√£o | \"Gato\" vs \"Matem√°tica\" |\n",
    "| **0.0** | 90¬∞ | Perpendiculares | Sem rela√ß√£o alguma |\n",
    "| **-1.0** | 180¬∞ | Opostos | \"Quente\" vs \"Frio\" |\n",
    "\n",
    "### Por que cosseno √© ideal para embeddings?\n",
    "\n",
    "1. **Normalizado** ‚úÖ\n",
    "   - Resultado sempre entre -1 e 1\n",
    "   - F√°cil de interpretar e comparar\n",
    "\n",
    "2. **Invariante √† magnitude** ‚úÖ\n",
    "   - Divide pelas normas ‚Üí ignora \"tamanho\" do vetor\n",
    "   - Foca apenas na **dire√ß√£o sem√¢ntica**\n",
    "   - Textos longos e curtos compar√°veis\n",
    "\n",
    "3. **Eficiente computacionalmente** ‚úÖ\n",
    "   - Opera√ß√µes vetoriais r√°pidas com NumPy/GPU\n",
    "   - $O(n)$ onde $n$ √© a dimens√£o do vetor\n",
    "\n",
    "4. **Padr√£o da ind√∫stria** ‚úÖ\n",
    "   - Usado por FAISS, Pinecone, Qdrant, Weaviate\n",
    "   - Compat√≠vel com normaliza√ß√£o L2 (otimiza√ß√£o comum)\n",
    "\n",
    "### Exemplo pr√°tico deste notebook:\n",
    "\n",
    "Se os resultados mostrarem:\n",
    "- **Sim(1,2) = 0.87** ‚Üí \"Gato dom√©stico\" e \"Felino de estima√ß√£o\" s√£o muito similares ‚úÖ\n",
    "- **Sim(1,3) = 0.32** ‚Üí \"Gato dom√©stico\" e \"Programa√ß√£o\" t√™m pouca rela√ß√£o ‚úÖ\n",
    "- **Diferen√ßa = 0.55** ‚Üí Modelo distingue muito bem os conceitos! üéØ\n",
    "\n",
    "üí° **Dica:** Sempre normalize vetores antes de armazenar no banco (usa produto escalar simples = mais r√°pido)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471a8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tentar OpenAI (pequeno) -> OpenAI (large) -> Google -> Erro amig√°vel\n",
    "openai_small_available = bool(os.getenv('OPENAI_API_KEY'))\n",
    "openai_large_available = bool(os.getenv('OPENAI_API_KEY'))\n",
    "google_available = bool(os.getenv('GOOGLE_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06abbe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fun√ß√£o helper para rodar OpenAI e obter uso\n",
    "\n",
    "def get_openai_embeddings(texts_list, model_name):\n",
    "    embeddings = []\n",
    "    total_tokens = 0\n",
    "    for t in texts_list:\n",
    "        emb, usage = openai_embedding(t, model=model_name, return_usage=True)\n",
    "        embeddings.append(emb)\n",
    "        if usage is not None:\n",
    "            try:\n",
    "                total_tokens += int(usage)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return embeddings, total_tokens if total_tokens else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f4a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui v√£o ser armazenados os resultados com os embeddings gerados pelas APIs da OpenAI e Google\n",
    "\n",
    "# Exemplo de dicion√°rio para armazenar os resultados\n",
    "\n",
    "# results = {\n",
    "#    'openai_small': {'embeddings': [...], 'tokens': 123, 'dim': 1536},\n",
    "#    'openai_large': {'embeddings': [...], 'tokens': 456, 'dim': 3072},\n",
    "#    'google': {'embeddings': [...], 'tokens': 789, 'dim': 3072},\n",
    "# }\n",
    "\n",
    "results = {}\n",
    "\n",
    "# OpenAI small\n",
    "if openai_small_available:\n",
    "    try:\n",
    "        emb_small, tokens_small = get_openai_embeddings(texts, 'text-embedding-3-small')\n",
    "        results['openai_small'] = {'embeddings': emb_small, 'tokens': tokens_small, 'dim': len(emb_small[0])}\n",
    "    except Exception as e:\n",
    "        print('Falha ao gerar embeddings OpenAI small:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e8d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI large\n",
    "if openai_large_available:\n",
    "    try:\n",
    "        emb_large, tokens_large = get_openai_embeddings(texts, 'text-embedding-3-large')\n",
    "        results['openai_large'] = {'embeddings': emb_large, 'tokens': tokens_large, 'dim': len(emb_large[0])}\n",
    "    except Exception as e:\n",
    "        print('Falha ao gerar embeddings OpenAI large:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401f49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google embeddings\n",
    "if google_available:\n",
    "    try:\n",
    "        # Gera os embeddings com a API REST para obter token count exato\n",
    "        emb_google = [google_embedding(t, return_usage=True) for t in texts]\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        results[\"google\"] = {\n",
    "            \"embeddings\": [e[0] for e in emb_google],\n",
    "            \"tokens\": [e[1] for e in emb_google],\n",
    "            \"dim\": len(emb_google[0][0]),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"Falha ao gerar embeddings Google:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebd670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backend: openai_small\n",
      "Dimens√£o: 1536\n",
      "Provider: OpenAI  Method: SDK\n",
      "Tokens (se dispon√≠vel): 32\n",
      " Embedding 1 primeiros 5: [0.001428517745807767, -0.004510881379246712, -0.04022705927491188, 0.04195206239819527, 0.015516397543251514]\n",
      " Embedding 2 primeiros 5: [-0.012964113615453243, 0.009385946206748486, -0.061422210186719894, 0.0561358705163002, 0.017261510714888573]\n",
      " Embedding 3 primeiros 5: [0.019466428086161613, 0.027966158464550972, -0.0038620447739958763, -0.009738600812852383, 0.04860682040452957]\n",
      " Similaridade 1-2: 0.8135\n",
      " Similaridade 1-3: 0.1420\n",
      " Est Cost USD (aproximado): N/A\n",
      "\n",
      "Backend: openai_large\n",
      "Dimens√£o: 3072\n",
      "Provider: OpenAI  Method: SDK\n",
      "Tokens (se dispon√≠vel): 32\n",
      " Embedding 1 primeiros 5: [-0.021800197660923004, 0.039917152374982834, -0.00277250399813056, 0.0035163466818630695, 0.010698671452701092]\n",
      " Embedding 2 primeiros 5: [-0.016434069722890854, 0.02808525785803795, -0.002878795610740781, -0.02375573106110096, 0.024798443540930748]\n",
      " Embedding 3 primeiros 5: [0.0003863089077640325, 0.003473639488220215, -0.02358054742217064, 0.038970090448856354, -0.0026099407114088535]\n",
      " Similaridade 1-2: 0.8490\n",
      " Similaridade 1-3: 0.2332\n",
      " Est Cost USD (aproximado): N/A\n",
      "\n",
      "Backend: google\n",
      "Dimens√£o: 3072\n",
      "Provider: Google  Method: REST\n",
      "Tokens (se dispon√≠vel): 24 (total de 3 chamadas)\n",
      " Embedding 1 primeiros 5: [-0.01546041, 0.013743455, 0.037031002, -0.057048496, 0.0026470574]\n",
      " Embedding 2 primeiros 5: [-0.03552813, 0.0063926117, 0.033068012, -0.064242266, -0.0032477966]\n",
      " Embedding 3 primeiros 5: [0.008538279, -0.0011638638, 0.02327945, -0.056141205, -0.014525335]\n",
      " Similaridade 1-2: 0.8846\n",
      " Similaridade 1-3: 0.5313\n",
      " Est Cost USD (aproximado): N/A\n"
     ]
    }
   ],
   "source": [
    "# Mostrar resultados: dimens√£o, primeiros 5 valores e similaridades por backend\n",
    "# Garantir que results_cost exista (pode ter sido criado em c√©lula futura)\n",
    "if 'results_cost' not in globals():\n",
    "    results_cost = {}\n",
    "\n",
    "for k, v in results.items():\n",
    "    print('\\nBackend:', k)\n",
    "    print('Dimens√£o:', v['dim'])\n",
    "\n",
    "    # Mapear provider e m√©todo\n",
    "    if k.startswith('openai'):\n",
    "        provider = 'OpenAI'\n",
    "        method = 'SDK'\n",
    "    elif k == 'google':\n",
    "        provider = 'Google'\n",
    "        method = 'REST'\n",
    "    else:\n",
    "        provider = 'Other'\n",
    "        method = 'Unknown'\n",
    "\n",
    "    print(f'Provider: {provider}  Method: {method}')\n",
    "\n",
    "    # Exibir tokens (somar se for lista)\n",
    "    tokens_value = v.get('tokens')\n",
    "    if isinstance(tokens_value, list):\n",
    "        total_tokens = sum(t for t in tokens_value if t is not None)\n",
    "        print(f'Tokens (se dispon√≠vel): {total_tokens} (total de {len(tokens_value)} chamadas)')\n",
    "    else:\n",
    "        print('Tokens (se dispon√≠vel):', tokens_value)\n",
    "\n",
    "    for i, e in enumerate(v['embeddings']):\n",
    "        print(f' Embedding {i+1} primeiros 5:', e[:5])\n",
    "        \n",
    "    # calcular similaridade\n",
    "    sim_12 = cosine_sim(v['embeddings'][0], v['embeddings'][1])\n",
    "    sim_13 = cosine_sim(v['embeddings'][0], v['embeddings'][2])\n",
    "    print(f' Similaridade 1-2: {sim_12:.4f}')\n",
    "    print(f' Similaridade 1-3: {sim_13:.4f}')\n",
    "\n",
    "    est_cost = results_cost.get(k)\n",
    "    print(f' Est Cost USD (aproximado): {est_cost if est_cost is not None else \"N/A\"}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b540a82",
   "metadata": {},
   "source": [
    "## üìä Interpretando os Resultados Comparativos\n",
    "\n",
    "Nesta se√ß√£o, comparamos **3 modelos de embeddings** em m√∫ltiplas dimens√µes:\n",
    "\n",
    "### Modelos testados:\n",
    "\n",
    "| Modelo | Dimens√µes | Provedor | Otimizado para |\n",
    "|--------|-----------|----------|----------------|\n",
    "| **text-embedding-3-small** | 1536 | OpenAI | Velocidade e custo |\n",
    "| **text-embedding-3-large** | 3072 | OpenAI | M√°xima qualidade |\n",
    "| **gemini-embedding-001** | 3072 | Google | M√°xima qualidade |\n",
    "\n",
    "### M√©tricas analisadas:\n",
    "\n",
    "#### 1. **Dimensionalidade (dim)**\n",
    "\n",
    "**O que √©:** N√∫mero de componentes no vetor de embedding.\n",
    "\n",
    "| Dimens√µes | Implica√ß√µes |\n",
    "|-----------|-------------|\n",
    "| **768** | ‚úÖ Leve, r√°pido, menor custo de armazenamento |\n",
    "| **1536** | üü° Equil√≠brio qualidade/performance |\n",
    "| **3072** | üî¥ M√°xima qualidade, mas 2x mais pesado |\n",
    "\n",
    "üí° **Analogia:** √â como resolu√ß√£o de imagem:\n",
    "- 768 = HD (suficiente para maioria)\n",
    "- 1536 = Full HD (√≥timo equil√≠brio)\n",
    "- 3072 = 4K (m√°ximo detalhe, mas arquivo grande)\n",
    "\n",
    "#### 2. **Tokens (contagem exata)**\n",
    "\n",
    "**O que √©:** Unidade de processamento das APIs (palavras, subpalavras, caracteres).\n",
    "\n",
    "**Fontes dos dados:**\n",
    "- OpenAI: `response.usage.total_tokens` (oficial)\n",
    "- Google: REST API `:embedContent` ou `:countTokens` (oficial)\n",
    "\n",
    "**Por que importa:**\n",
    "- üîë Determina o **custo exato** da opera√ß√£o\n",
    "- üìä Permite comparar efici√™ncia de tokeniza√ß√£o entre APIs\n",
    "- üí∞ Essencial para planejamento de budget\n",
    "\n",
    "**Compara√ß√£o t√≠pica:**\n",
    "\n",
    "```text\n",
    "Texto: \"O gato √© um animal dom√©stico\" (7 palavras)\n",
    "\n",
    "OpenAI: ~6 tokens (tokeniza√ß√£o BPE otimizada¬π)\n",
    "Google: ~8 tokens (tokeniza√ß√£o mais granular)\n",
    "```\n",
    "\n",
    "> ¬π Tokeniza√ß√£o BPE otimizada √© uma t√©cnica que divide palavras em subunidades frequentes, reduzindo o n√∫mero total de tokens para textos comuns.\n",
    "> - BPE (Byte Pair Encoding) √© uma t√©cnica de tokeniza√ß√£o por subpalavras: ela representa textos como tokens que podem ser caracteres, subpalavras ou combina√ß√µes frequentes.\n",
    "> - ‚ÄúBPE otimizada‚Äù significa que o vocabul√°rio e as regras de merge foram ajustados para esse modelo espec√≠fico, gerando:\n",
    ">   - menos tokens por texto (melhor compress√£o),\n",
    ">   - mais tokens inteiros relevantes (menos fragmenta√ß√£o),\n",
    ">   - e geralmente resultados mais eficientes (custo e lat√™ncia menores).\n",
    "> \n",
    "> Em resumo: em vez de dividir cada palavra em muitos peda√ßos, o modelo usa pares/substrings mais ‚Äúinteligentes‚Äù e frequentes para reduzir tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 3. **Primeiros 5 valores do embedding**\n",
    "\n",
    "**O que √©:** Amostra dos componentes do vetor.\n",
    "\n",
    "**Para que serve:**\n",
    "- ‚úÖ Verificar distribui√ß√£o dos valores (normalmente -1 a +1)\n",
    "- ‚úÖ Detectar anomalias (valores extremos, NaN)\n",
    "- ‚úÖ Comparar escala entre modelos\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "[0.0234, -0.1567, 0.0891, -0.0456, 0.1234]\n",
    "```\n",
    "\n",
    "#### 4. **Similaridade 1-2 vs 1-3**\n",
    "\n",
    "**O que esperamos:**\n",
    "\n",
    "```\n",
    "| Sim(1,2) >> Sim(1,3) |\n",
    "|   ‚Üì           ‚Üì      |\n",
    "| ALTA       BAIXA     |\n",
    "| (>0.8)     (<0.5)    |\n",
    "```\n",
    "\n",
    "**Interpreta√ß√£o:**\n",
    "\n",
    "| Cen√°rio | Sim(1,2) | Sim(1,3) | Diferen√ßa | Avalia√ß√£o |\n",
    "|---------|----------|----------|-----------|-----------|\n",
    "| **Ideal** | 0.89 | 0.28 | 0.61 | üü¢ Excelente discrimina√ß√£o |\n",
    "| **Bom** | 0.85 | 0.45 | 0.40 | üü° Boa discrimina√ß√£o |\n",
    "| **Moderado** | 0.78 | 0.58 | 0.20 | üü† Discrimina√ß√£o fraca |\n",
    "| **Ruim** | 0.72 | 0.68 | 0.04 | üî¥ Modelo n√£o distingue conceitos |\n",
    "\n",
    "### Como ler os resultados:\n",
    "\n",
    "**Exemplo de sa√≠da:**\n",
    "```\n",
    "| Backend: openai_small                                                 |\n",
    "| Dimens√£o: 1536                                                        |\n",
    "| Tokens: 18                                                            |\n",
    "| Embedding 1 primeiros 5: [0.0234, -0.1567, 0.0891, -0.0456, 0.1234]   |\n",
    "| Embedding 2 primeiros 5: [0.0198, -0.1489, 0.0923, -0.0412, 0.1189]   |\n",
    "| Embedding 3 primeiros 5: [-0.0876, 0.0234, -0.1123, 0.0567, -0.0234]  |\n",
    "| Similaridade 1-2: 0.8932  ‚Üê ALTA ‚úÖ (textos similares)                |\n",
    "| Similaridade 1-3: 0.2134  ‚Üê BAIXA ‚úÖ (textos diferentes)              |\n",
    "```\n",
    "\n",
    "**An√°lise:**\n",
    "- ‚úÖ Diferen√ßa de 0.68 = Excelente!\n",
    "- ‚úÖ Modelo captura sem√¢ntica corretamente\n",
    "- ‚úÖ Pronto para uso em RAG/busca sem√¢ntica\n",
    "\n",
    "### Fatores que afetam similaridade:\n",
    "\n",
    "1. **Qualidade do modelo**\n",
    "   - Modelos maiores (3072 dim) tendem a ter melhor discrimina√ß√£o\n",
    "   - Mas nem sempre: depende do treinamento\n",
    "\n",
    "2. **Dom√≠nio do texto**\n",
    "   - Modelos treinados em textos gerais funcionam bem para casos gerais\n",
    "   - Dom√≠nios espec√≠ficos (m√©dico, legal) podem precisar fine-tuning\n",
    "\n",
    "3. **Tamanho do texto**\n",
    "   - Textos muito curtos (<5 palavras): mais dif√≠cil distinguir\n",
    "   - Textos longos (>100 palavras): embeddings mais est√°veis\n",
    "\n",
    "### Quando um modelo √© considerado bom?\n",
    "\n",
    "‚úÖ **Crit√©rios de qualidade:**\n",
    "- [ ] Similaridade 1-2 > 0.75 (conceitos similares agrupados)\n",
    "- [ ] Similaridade 1-3 < 0.50 (conceitos distintos separados)\n",
    "- [ ] Diferen√ßa > 0.30 (boa discrimina√ß√£o)\n",
    "- [ ] Tokens compat√≠veis com budget (custo aceit√°vel)\n",
    "- [ ] Dimens√µes adequadas para infraestrutura (armazenamento/consulta)\n",
    "\n",
    "### Compara√ß√£o custo vs qualidade:\n",
    "\n",
    "```text\n",
    "Trade-off t√≠pico:\n",
    "\n",
    "Qualidade Alta ‚îÇ  text-emb-3-large (3072 dim, $0.13/1M)\n",
    "               ‚îÇ  gemini-emb-001   (3072 dim, free/baixo custo, depois $0.15/1M)\n",
    "Qualidade Boa  ‚îÇ  text-emb-3-small (1536 dim, $0.02/1M)\n",
    "               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "                 Custo Baixo    ‚Üí    Custo Alto\n",
    "```\n",
    "\n",
    "üí° **Recomenda√ß√£o geral:**\n",
    "- **Prototipagem**: text-embedding-3-small (r√°pido, barato)\n",
    "- **Produ√ß√£o m√©dia escala**: gemini-embedding-001 (free tier generoso)\n",
    "- **Produ√ß√£o alta qualidade**: text-embedding-3-large (m√°xima precis√£o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c970b0d4",
   "metadata": {},
   "source": [
    "## üí∞ Pre√ßos Oficiais das APIs (Atualizado Dez/2025)\n",
    "\n",
    "### Tabela de pre√ßos por modelo:\n",
    "\n",
    "| Modelo | Dimens√µes | Pre√ßo por 1M tokens | Pre√ßo por 1K tokens | Provedor |\n",
    "|--------|-----------|---------------------|---------------------|----------|\n",
    "| **text-embedding-3-small** | 1536 | $0.020 | $0.00002 | OpenAI |\n",
    "| **text-embedding-3-large** | 3072 | $0.130 | $0.00013 | OpenAI |\n",
    "| **gemini-embedding-001** | 3072 | $0.150 * | $0.00015 | Google |\n",
    "\n",
    "**\\* Google oferece free tier generoso:**\n",
    "- Primeiros 1M tokens/m√™s: **GR√ÅTIS** (permite a Google treinar seus modelos)\n",
    "- Depois: $0.15 por 1M tokens\n",
    "\n",
    "### Exemplo de c√°lculo de custo:\n",
    "\n",
    "```python\n",
    "Texto: \"O gato √© um animal dom√©stico\"\n",
    "Tokens: ~8 tokens (varia por tokenizador)\n",
    "\n",
    "# OpenAI small\n",
    "custo = (8 / 1_000_000) * 0.020 = $0.00000016\n",
    "\n",
    "# OpenAI large  \n",
    "custo = (8 / 1_000_000) * 0.130 = $0.00000104\n",
    "\n",
    "# Google\n",
    "custo = (8 / 1_000_000) * 0.150 = $0.00000120\n",
    "```\n",
    "\n",
    "### Compara√ß√£o de custo por opera√ß√£o:\n",
    "\n",
    "| Opera√ß√£o | Tokens | OpenAI small | OpenAI large | Google |\n",
    "|----------|--------|--------------|--------------|--------|\n",
    "| **1 frase curta** | ~8 | $0.0000002 | $0.0000010 | $0.0000012 |\n",
    "| **1 par√°grafo** | ~100 | $0.000002 | $0.000013 | $0.000015 |\n",
    "| **1 documento** | ~1000 | $0.00002 | $0.00013 | $0.00015 |\n",
    "| **10K documentos** | 1M | $0.02 | $0.13 | $0.15 |\n",
    "\n",
    "### An√°lise custo-benef√≠cio:\n",
    "\n",
    "**Cen√°rio 1: Startup (baixo volume)**\n",
    "```\n",
    "‚úÖ Recomenda√ß√£o: Google Gemini\n",
    "üìä Volume: <1M tokens/m√™s\n",
    "üí∞ Custo: $0 (free tier)\n",
    "üéØ Qualidade: Boa (768 dim)\n",
    "```\n",
    "\n",
    "**Cen√°rio 2: Empresa m√©dia (m√©dio volume)**\n",
    "```\n",
    "‚úÖ Recomenda√ß√£o: OpenAI text-embedding-3-small\n",
    "üìä Volume: 10M-100M tokens/m√™s\n",
    "üí∞ Custo: $0.20 - $2.00/m√™s\n",
    "üéØ Qualidade: Excelente (1536 dim)\n",
    "```\n",
    "\n",
    "**Cen√°rio 3: Enterprise (alto volume + m√°xima qualidade)**\n",
    "```\n",
    "‚úÖ Recomenda√ß√£o: OpenAI text-embedding-3-large\n",
    "üìä Volume: >100M tokens/m√™s\n",
    "üí∞ Custo: ~$13/m√™s por 100M\n",
    "üéØ Qualidade: State-of-the-art (3072 dim)\n",
    "```\n",
    "\n",
    "### Refer√™ncias oficiais:\n",
    "\n",
    "**OpenAI Pricing:**\n",
    "- üåê https://platform.openai.com/docs/models\n",
    "- üìñ Embedding models: https://platform.openai.com/docs/guides/embeddings\n",
    "\n",
    "**Google AI Pricing:**\n",
    "- üåê https://ai.google.dev/gemini-api/docs/pricing#gemini-embedding\n",
    "- üìñ Free tier details: https://ai.google.dev/pricing\n",
    "\n",
    "### üí° Dicas para reduzir custos:\n",
    "\n",
    "1. **Cache de embeddings** ‚úÖ\n",
    "   - Salve embeddings j√° calculados\n",
    "   - Evite processar o mesmo texto 2x\n",
    "\n",
    "2. **Batch processing** ‚úÖ\n",
    "   - Agrupe m√∫ltiplos textos em uma chamada\n",
    "   - Reduz overhead de rede\n",
    "\n",
    "3. **Chunking inteligente** ‚úÖ\n",
    "   - Divida documentos longos em peda√ßos\n",
    "   - Use apenas chunks relevantes para embedding\n",
    "\n",
    "4. **Modelo h√≠brido** ‚úÖ\n",
    "   - Use modelo pequeno para filtragem inicial\n",
    "   - Aplique modelo grande apenas no top-k\n",
    "\n",
    "5. **Monitoramento de uso** ‚úÖ\n",
    "   - Configure alertas de gastos\n",
    "   - Revise logs de consumo mensalmente\n",
    "\n",
    "**‚ö†Ô∏è Importante:** Pre√ßos podem mudar. Sempre consulte documenta√ß√£o oficial antes de decis√µes de arquitetura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b44afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimativa de custos (usa pre√ßos p√∫blicos quando poss√≠vel)\n",
    "from math import ceil\n",
    "\n",
    "PRICING = {\n",
    "    'openai_text-embedding-3-small': {'per_1k_tokens_usd': 0.00002},\n",
    "    'openai_text-embedding-3-large': {'per_1k_tokens_usd': 0.00013},\n",
    "    'google_gemini-embedding-001': {'per_1k_tokens_usd': 0.00015}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed53ebb",
   "metadata": {},
   "source": [
    "## üßÆ Metodologia de C√°lculo de Custos\n",
    "\n",
    "### Como calculamos o custo EXATO:\n",
    "\n",
    "Diferente de muitos tutoriais que usam **estimativas**, este notebook obt√©m **tokens reais** diretamente das APIs oficiais.\n",
    "\n",
    "### Fontes de token count:\n",
    "\n",
    "#### OpenAI (oficial):\n",
    "```python\n",
    "response = client.embeddings.create(input=text, model=model)\n",
    "tokens = response.usage.total_tokens  # ‚Üê EXATO da API\n",
    "```\n",
    "\n",
    "**Campos dispon√≠veis:**\n",
    "- `prompt_tokens` - Tokens do input\n",
    "- `total_tokens` - Total processado\n",
    "- Retornado em **toda** chamada (sem custo adicional)\n",
    "\n",
    "#### Google (oficial via REST):\n",
    "```python\n",
    "# M√©todo 1: embedContent (retorna embedding + metadados)\n",
    "POST /v1beta/models/{model}:embedContent\n",
    "‚Üí response.metadata.tokenCount  # ‚Üê EXATO\n",
    "\n",
    "# M√©todo 2: countTokens (apenas contagem)\n",
    "POST /v1beta/models/{model}:countTokens\n",
    "‚Üí response.totalTokens  # ‚Üê EXATO\n",
    "```\n",
    "\n",
    "**Vantagens da abordagem REST:**\n",
    "- ‚úÖ Token count oficial (n√£o estimado)\n",
    "- ‚úÖ Sem custo adicional pela contagem\n",
    "- ‚úÖ Mesmo tokenizador usado internamente\n",
    "\n",
    "### F√≥rmula de custo:\n",
    "\n",
    "$$\n",
    "\\text{Custo (USD)} = \\frac{\\text{Tokens}}{1000} \\times \\text{Pre√ßo por 1K tokens}\n",
    "$$\n",
    "\n",
    "**Exemplo pr√°tico:**\n",
    "```python\n",
    "# Dados reais do notebook\n",
    "text = \"O gato √© um animal dom√©stico\"\n",
    "tokens = 8  # ‚Üê Retornado pela API OpenAI\n",
    "price_per_1k = 0.00002  # text-embedding-3-small\n",
    "\n",
    "cost = (8 / 1000) * 0.00002\n",
    "     = 0.008 * 0.00002\n",
    "     = $0.00000016\n",
    "```\n",
    "\n",
    "### Compara√ß√£o: Tokens Exatos vs Estimados\n",
    "\n",
    "| M√©todo | Precis√£o | Como funciona | Quando usar |\n",
    "|--------|----------|---------------|-------------|\n",
    "| **Exato (API)** | ‚úÖ 100% | Retornado pela API oficial | ‚úÖ Sempre preferir |\n",
    "| **Estimado (heur√≠stica)** | ‚ùå ~70-90% | 1 token ‚âà 4 chars ou 1.3 palavras | Fallback apenas |\n",
    "\n",
    "**Por que estimativas s√£o imprecisas:**\n",
    "\n",
    "```python\n",
    "Texto: \"OpenAI\"\n",
    "\n",
    "# Estimativa (1 palavra = 1.3 tokens)\n",
    "estimated = 1 * 1.3 = 1.3 tokens\n",
    "\n",
    "# Real (tokenizador BPE)\n",
    "real = 2 tokens  # [\"Open\", \"AI\"]\n",
    "\n",
    "# Erro: ~54% !\n",
    "```\n",
    "\n",
    "**Tokenizadores diferentes = contagens diferentes:**\n",
    "- OpenAI usa **BPE** (Byte Pair Encoding)\n",
    "- Google usa tokenizador pr√≥prio\n",
    "- Mesma frase pode ter contagens distintas!\n",
    "\n",
    "### Estrutura de dados do notebook:\n",
    "\n",
    "```python\n",
    "results = {\n",
    "    'openai_small': {\n",
    "        'embeddings': [[...], [...], [...]],  # 3 vetores\n",
    "        'tokens': 18,                          # ‚Üê EXATO\n",
    "        'dim': 1536\n",
    "    },\n",
    "    'google': {\n",
    "        'embeddings': [[...], [...], [...]],\n",
    "        'tokens': [7, 6, 8],  # ‚Üê EXATO (um por chamada)\n",
    "        'dim': 768\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Limita√ß√µes e recomenda√ß√µes:\n",
    "\n",
    "**Limita√ß√µes:**\n",
    "- ‚ö†Ô∏è Pre√ßos em `PRICING` dict devem ser **atualizados manualmente**\n",
    "- ‚ö†Ô∏è APIs podem mudar estrutura de resposta (raro, mas poss√≠vel)\n",
    "- ‚ö†Ô∏è Free tiers t√™m limites (verificar quotas)\n",
    "\n",
    "**Recomenda√ß√µes:**\n",
    "1. ‚úÖ **Use token count oficial** sempre que dispon√≠vel\n",
    "2. ‚úÖ **Valide pre√ßos** periodicamente (links na c√©lula anterior)\n",
    "3. ‚úÖ **Monitore consumo** com dashboards das plataformas:\n",
    "   - OpenAI: https://platform.openai.com/usage\n",
    "   - Google: https://console.cloud.google.com/billing\n",
    "4. ‚úÖ **Configure alertas** de gastos ($5, $10, $50)\n",
    "5. ‚úÖ **Documente custos** em produ√ß√£o para auditorias\n",
    "\n",
    "### Fallback para estimativa:\n",
    "\n",
    "```python\n",
    "# S√≥ usar se API n√£o retornar tokens\n",
    "def estimate_tokens_from_text(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Heur√≠stica: ~1.3 tokens por palavra\n",
    "    Imprecisa, usar apenas como fallback!\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    return max(1, int(ceil(len(words) * 1.3)))\n",
    "```\n",
    "\n",
    "**Quando o fallback √© acionado:**\n",
    "- ‚ùå Erro de rede (timeout, API offline)\n",
    "- ‚ùå API retorna resposta sem campo `usage` ou `tokenCount`\n",
    "- ‚ùå Chave de API inv√°lida (erro antes de retornar dados)\n",
    "\n",
    "üí° **Dica:** Se voc√™ v√™ \"usando estimativa\" nos logs, investigue! Pode indicar problema na integra√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bd57a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí∞ Custos por modelo (esta execu√ß√£o):\n",
      "==================================================\n",
      "openai_small         ‚Üí $0.00000064 USD\n",
      "openai_large         ‚Üí $0.00000416 USD\n",
      "google               ‚Üí $0.00000360 USD\n",
      "\n",
      "üìå Observa√ß√£o: Valores baseados em tokens REAIS das APIs.\n",
      "   Revise PRICING periodicamente para manter pre√ßos atualizados.\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para calcular custo baseado em tokens exatos\n",
    "\n",
    "def estimate_tokens_from_text(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Heur√≠stica para estimar tokens quando n√£o dispon√≠veis da API.\n",
    "    Assume ~1.3 tokens por palavra (aproxima√ß√£o).\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    return max(1, int(ceil(len(words) * 1.3)))\n",
    "\n",
    "\n",
    "def calculate_cost(model_key: str, tokens: int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula o custo baseado em tokens exatos e pre√ßos definidos em PRICING.\n",
    "    \n",
    "    Args:\n",
    "        model_key: Chave do modelo no dicion√°rio PRICING\n",
    "        tokens: N√∫mero exato de tokens processados\n",
    "    \n",
    "    Returns:\n",
    "        Custo em USD\n",
    "    \"\"\"\n",
    "    pricing = PRICING.get(model_key)\n",
    "    if pricing is None:\n",
    "        raise KeyError(f'Modelo {model_key} sem pre√ßo definido no PRICING dict')\n",
    "\n",
    "    if 'per_1k_tokens_usd' not in pricing:\n",
    "        raise KeyError(f'Modelo {model_key} sem estrutura de pre√ßo v√°lida')\n",
    "    \n",
    "    return (tokens / 1000.0) * pricing['per_1k_tokens_usd']\n",
    "\n",
    "\n",
    "# Calcular custo para os resultados do notebook (results dict)\n",
    "results_cost = {}\n",
    "\n",
    "for k, v in results.items():\n",
    "    # Mapear nome do resultado para chave do modelo\n",
    "    model_key: str | None = None\n",
    "    if k == 'openai_small':\n",
    "        model_key = 'openai_text-embedding-3-small'\n",
    "    elif k == 'openai_large':\n",
    "        model_key = 'openai_text-embedding-3-large'\n",
    "    elif k == 'google':\n",
    "        model_key = 'google_gemini-embedding-001'\n",
    "    \n",
    "    # Validar que temos o model_key antes de continuar\n",
    "    if model_key is None:\n",
    "        print(f'‚ö†Ô∏è  Modelo desconhecido: {k} - pulando c√°lculo de custo')\n",
    "        results_cost[k] = None\n",
    "        continue\n",
    "\n",
    "    tokens = v.get('tokens')\n",
    "    cost = None\n",
    "    \n",
    "    try:\n",
    "        if tokens is not None:\n",
    "            # Para Google, tokens √© uma lista (um por chamada); somar todos\n",
    "            if isinstance(tokens, list):\n",
    "                total_tokens = sum(t for t in tokens if t is not None)\n",
    "            else:\n",
    "                total_tokens = tokens\n",
    "            \n",
    "            # Calcular custo com tokens reais\n",
    "            if total_tokens > 0:\n",
    "                cost = calculate_cost(model_key, total_tokens)\n",
    "        else:\n",
    "            # Fallback APENAS se tokens n√£o dispon√≠vel (n√£o deveria acontecer)\n",
    "            print(f'‚ö†Ô∏è  Aviso: tokens n√£o dispon√≠vel para {k}, usando estimativa')\n",
    "            total_tokens = sum(estimate_tokens_from_text(t) for t in texts)\n",
    "            cost = calculate_cost(model_key, total_tokens)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Erro ao calcular custo para {k}: {e}')\n",
    "        cost = None\n",
    "    \n",
    "    results_cost[k] = cost\n",
    "\n",
    "# Mostrar custos calculados\n",
    "print('\\nüí∞ Custos por modelo (esta execu√ß√£o):')\n",
    "print('=' * 50)\n",
    "for k, c in results_cost.items():\n",
    "    if c is not None:\n",
    "        print(f'{k:20} ‚Üí ${c:.8f} USD')\n",
    "    else:\n",
    "        print(f'{k:20} ‚Üí [erro no c√°lculo]')\n",
    "\n",
    "print('\\nüìå Observa√ß√£o: Valores baseados em tokens REAIS das APIs.')\n",
    "print('   Revise PRICING periodicamente para manter pre√ßos atualizados.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18772b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>provider</th>\n",
       "      <th>method</th>\n",
       "      <th>dim</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sim_12</th>\n",
       "      <th>sim_13</th>\n",
       "      <th>est_cost_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai_small</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>SDK</td>\n",
       "      <td>1536</td>\n",
       "      <td>32</td>\n",
       "      <td>0.81346465</td>\n",
       "      <td>0.14203189</td>\n",
       "      <td>0.00000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai_large</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>SDK</td>\n",
       "      <td>3072</td>\n",
       "      <td>32</td>\n",
       "      <td>0.84903881</td>\n",
       "      <td>0.23315865</td>\n",
       "      <td>0.00000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google</td>\n",
       "      <td>Google</td>\n",
       "      <td>REST</td>\n",
       "      <td>3072</td>\n",
       "      <td>24</td>\n",
       "      <td>0.88463019</td>\n",
       "      <td>0.53127521</td>\n",
       "      <td>0.00000360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model provider method   dim  tokens     sim_12     sim_13  \\\n",
       "0  openai_small   OpenAI    SDK  1536      32 0.81346465 0.14203189   \n",
       "1  openai_large   OpenAI    SDK  3072      32 0.84903881 0.23315865   \n",
       "2        google   Google   REST  3072      24 0.88463019 0.53127521   \n",
       "\n",
       "   est_cost_usd  \n",
       "0    0.00000064  \n",
       "1    0.00000416  \n",
       "2    0.00000360  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to E:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\data\\embeddings\\similarity_comparison.png\n",
      "Saved plot to E:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\data\\embeddings\\cost_comparison.png\n",
      "\n",
      "Instru√ß√µes para exportar o notebook como slides (Reveal.js) ou PDF:\n",
      "1) Para gerar slides HTML:\n",
      "   jupyter nbconvert --to slides notebooks/quick_test_classroom.ipynb --reveal-prefix 'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/'\n",
      "2) Para gerar PDF (pode exigir LaTeX):\n",
      "   jupyter nbconvert --to pdf notebooks/quick_test_classroom.ipynb\n"
     ]
    }
   ],
   "source": [
    "# 6) Gerar relat√≥rio: CSV + gr√°ficos + instru√ß√µes para exportar slides/PDF\n",
    "\n",
    "\n",
    "# tentativas de import para pandas/matplotlib; se faltar, gerar CSV somente\n",
    "have_pandas = False\n",
    "have_matplotlib = False\n",
    "pd = None\n",
    "plt = None\n",
    "try:\n",
    "    import pandas as pd\n",
    "    have_pandas = True\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    have_matplotlib = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Criar pasta para salvar resultados\n",
    "out_dir = Path('../../data') / 'embeddings'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Montar linhas para CSV\n",
    "rows = []\n",
    "for k, v in results.items():\n",
    "    try:\n",
    "        sim_12 = cosine_sim(v['embeddings'][0], v['embeddings'][1])\n",
    "        sim_13 = cosine_sim(v['embeddings'][0], v['embeddings'][2])\n",
    "    except Exception:\n",
    "        sim_12 = None\n",
    "        sim_13 = None\n",
    "    \n",
    "    # Normalizar tokens (somar se for lista)\n",
    "    tokens_value = v.get('tokens')\n",
    "    if isinstance(tokens_value, list):\n",
    "        tokens_value = sum(t for t in tokens_value if t is not None)\n",
    "\n",
    "    # Mapear provider e m√©todo (para compara√ß√£o direta OpenAI/Google)\n",
    "    if k.startswith('openai'):\n",
    "        provider = 'OpenAI'\n",
    "        method = 'SDK'  # usamos o SDK OpenAI (openai python client)\n",
    "    elif k == 'google':\n",
    "        provider = 'Google'\n",
    "        method = 'REST'  # usamos REST API para token count\n",
    "    else:\n",
    "        provider = 'Other'\n",
    "        method = 'Unknown'\n",
    "    \n",
    "    rows.append({\n",
    "        'model': k,\n",
    "        'provider': provider,\n",
    "        'method': method,\n",
    "        'dim': v.get('dim'),\n",
    "        'tokens': tokens_value,\n",
    "        'sim_12': sim_12,\n",
    "        'sim_13': sim_13,\n",
    "        'est_cost_usd': results_cost.get(k)\n",
    "    })\n",
    "\n",
    "csv_path = out_dir / 'comparative_results.csv'\n",
    "fieldnames = ['model', 'provider', 'method', 'dim', 'tokens', 'sim_12', 'sim_13', 'est_cost_usd']\n",
    "with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for r in rows:\n",
    "        writer.writerow(r)\n",
    "# If pandas available, show DataFrame\n",
    "if have_pandas and pd is not None:\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Reorder columns to show provider/method first\n",
    "    df = df[fieldnames]\n",
    "    \n",
    "    # Configurar pandas para exibir n√∫meros com mais casas decimais sem nota√ß√£o cient√≠fica\n",
    "    pd.set_option('display.float_format', lambda x: f'{x:.8f}')\n",
    "    \n",
    "    print('\\nDataFrame summary:')\n",
    "    display(df)\n",
    "else:\n",
    "    print('\\nCSV content preview:')\n",
    "    for r in rows:\n",
    "        print(r)\n",
    "\n",
    "# Tentar criar plots se matplotlib estiver dispon√≠vel\n",
    "if have_matplotlib and plt is not None:\n",
    "    # Make arrays for plotting\n",
    "    models = [r['model'] for r in rows]\n",
    "    sim12 = [r['sim_12'] if r['sim_12'] is not None else 0 for r in rows]\n",
    "    sim13 = [r['sim_13'] if r['sim_13'] is not None else 0 for r in rows]\n",
    "    costs = [r['est_cost_usd'] if r['est_cost_usd'] is not None else 0 for r in rows]\n",
    "\n",
    "    # Similarity bar chart\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    x = range(len(models))\n",
    "    plt.bar(x, sim12, width=0.4, label='Sim 1-2')\n",
    "    plt.bar([i + 0.4 for i in x], sim13, width=0.4, label='Sim 1-3')\n",
    "    plt.title('Similaridade (cosine) por modelo')\n",
    "    plt.xticks([i + 0.2 for i in x], models)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plot1 = out_dir / 'similarity_comparison.png'\n",
    "    plt.savefig(plot1)\n",
    "    print(f'Saved plot to {plot1.resolve()}')\n",
    "    plt.close()\n",
    "\n",
    "    # Cost chart\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(models, costs, color='orange')\n",
    "    plt.title('Estimated cost per run (USD)')\n",
    "    plt.ylabel('USD')\n",
    "    plt.tight_layout()\n",
    "    plot2 = out_dir / 'cost_comparison.png'\n",
    "    plt.savefig(plot2)\n",
    "    print(f'Saved plot to {plot2.resolve()}')\n",
    "    plt.close()\n",
    "else:\n",
    "    print('\\nMatplotlib or pandas not installed; plots skipped. To enable plots: pip install pandas matplotlib')\n",
    "\n",
    "# Instru√ß√µes para exportar o notebook em slides/PDF\n",
    "print('\\nInstru√ß√µes para exportar o notebook como slides (Reveal.js) ou PDF:')\n",
    "print('1) Para gerar slides HTML:')\n",
    "print(\"   jupyter nbconvert --to slides notebooks/quick_test_classroom.ipynb --reveal-prefix 'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/'\")\n",
    "print('2) Para gerar PDF (pode exigir LaTeX):')\n",
    "print('   jupyter nbconvert --to pdf notebooks/quick_test_classroom.ipynb')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4067286",
   "metadata": {},
   "source": [
    "## üîç Novas colunas adicionadas (Provider, Method, Tokens, Est Cost USD)\n",
    "\n",
    "Para facilitar compara√ß√µes entre **uso direto de APIs (Google/OpenAI)** e outras abordagens, adicionamos as colunas abaixo ao relat√≥rio e ao CSV:\n",
    "\n",
    "- **Provider**: Provedor do embedding (ex: OpenAI, Google)  \n",
    "- **Method**: 'REST' para chamadas REST diretas, 'SDK' para clientes/SDKs, 'Other' para alternativos  \n",
    "- **Tokens**: Contagem exata de tokens retornada pela API (ou soma quando m√∫ltiplas chamadas)  \n",
    "- **Est Cost USD**: Estimativa de custo por execu√ß√£o com base em token count e pre√ßos configurados no `PRICING`\n",
    "\n",
    "Essas colunas ajudam a comparar n√£o s√≥ a qualidade do embedding (similaridade/diferen√ßa) mas tamb√©m o custo e a forma de integra√ß√£o (SDK vs REST).  \n",
    "\n",
    "> Observa√ß√£o: mantivemos todas as colunas existentes (`Modelo`, `Dimens√µes`, `Tempo M√©dio`, `Sim 1-2`, `Sim 1-3`, `Diferen√ßa`) ‚Äî apenas acrescentamos novos dados para an√°lise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11-34-engenharia-vetorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
