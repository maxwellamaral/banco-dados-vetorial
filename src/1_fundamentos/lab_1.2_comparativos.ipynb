{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2349cee0",
   "metadata": {},
   "source": [
    "### 1) Instalar depend√™ncias (opcional - rode no terminal ou em uma c√©lula do notebook)\n",
    "Em um notebook voc√™ pode executar (c√©lula de bash):\n",
    "```bash\n",
    "pip install -U openai google-generativeai numpy scikit-learn python-dotenv langchain-google-genai\n",
    "```\n",
    "*Na pr√°tica, instale apenas as libs que vai usar no ambiente do Jupyter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d2801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.5) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Tuple, Optional\n",
    "from openai import OpenAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580f850",
   "metadata": {},
   "source": [
    "### 2) Testar carregamento das vari√°veis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b5308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé .env carregado -> E:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\.env\n",
      "OPENAI_API_KEY set? -> True\n",
      "GOOGLE_API_KEY set? -> True\n"
     ]
    }
   ],
   "source": [
    "# 2) Configura√ß√£o e carregamento do .env (simplificado)\n",
    "env_path = Path.cwd().joinpath('..', '..', '.env').resolve()\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f'üîé .env carregado -> {env_path.resolve()}')\n",
    "else:\n",
    "    print('‚ö†Ô∏è  .env n√£o encontrado. Defina as vari√°veis de ambiente manualmente.')\n",
    "\n",
    "\n",
    "# Checar chaves (r√≥tulos simples)\n",
    "print('OPENAI_API_KEY set? ->', bool(os.getenv('OPENAI_API_KEY')))\n",
    "print('GOOGLE_API_KEY set? ->', bool(os.getenv('GOOGLE_API_KEY')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1de86d",
   "metadata": {},
   "source": [
    "### 3) Fun√ß√µes para gerar embeddings\n",
    "\n",
    "- Vamos criar fun√ß√µes pequenas e claras para OpenAI e para Google Gemini (com fallback pra LangChain).\n",
    "- Em sala de aula, foque no fluxo: obter texto, chamar API, receber vetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e3874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OpenAI embedding wrapper\n",
    "def openai_embedding(text: str, model: str = 'text-embedding-3-small', return_usage: bool = False) -> Tuple[List[float], Optional[int]]:\n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    resp = client.embeddings.create(input=text, model=model)\n",
    "    emb = resp.data[0].embedding\n",
    "    if return_usage:\n",
    "        usage = getattr(resp, 'usage', None)\n",
    "        total_tokens = getattr(usage, 'total_tokens', None) if usage is not None else None\n",
    "        return emb, total_tokens\n",
    "    return emb, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e48934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Google embedding wrapper com fallback (retorna apenas embedding)\n",
    "def google_embedding(text: str, model: str = 'models/text-embedding-004') -> List[float]:        \n",
    "    emb = GoogleGenerativeAIEmbeddings(model=model).embed_query(text)\n",
    "    return list(emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9d81c",
   "metadata": {},
   "source": [
    "### 4) Exemplo pr√°tico: gerar embeddings e comparar similaridade\n",
    "\n",
    "Vamos gerar embeddings para 3 frases e calcular a similaridade (cosine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca89e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo e compara√ß√£o: gerar embeddings e calcular similaridade\n",
    "\n",
    "def cosine_sim(v1, v2):\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "\n",
    "texts = [\n",
    "    'O gato √© um animal dom√©stico',\n",
    "    'O gato √© um felino de estima√ß√£o',\n",
    "    'A programa√ß√£o √© importante para engenheiros de software'\n",
    "]\n",
    "\n",
    "emb1 = emb2 = emb3 = None\n",
    "backend = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2147ae",
   "metadata": {},
   "source": [
    "### Como a similaridade √© calculada (cosine similarity)\n",
    "\n",
    "A similaridade coseno (cosine similarity) mede o qu√£o semelhantes s√£o dois vetores de embeddings em termos de orienta√ß√£o no espa√ßo vetorial, independentemente do seu comprimento. A f√≥rmula usada no notebook √©:\n",
    "\n",
    "cosine_sim(v1, v2) = dot(v1, v2) / (||v1|| * ||v2||)\n",
    "\n",
    "- dot(v1, v2) √© o produto escalar entre os vetores.\n",
    "- ||v|| √© a norma L2 do vetor (sqrt(soma dos quadrados)).\n",
    "- O resultado varia entre -1 e 1: valores pr√≥ximos a 1 indicam alta similaridade, 0 indica aus√™ncia de rela√ß√£o linear, e -1 indica dire√ß√£o oposta.\n",
    "\n",
    "Observa√ß√µes pr√°ticas:\n",
    "- Mesmo sem normalizar explicitamente, dividir pelo produto das normas L2 normaliza o c√°lculo, tornando-o independente da magnitude absoluta dos vetores.\n",
    "- A normaliza√ß√£o L2 (v / ||v||) √© frequentemente aplicada antes do armazenamento/√≠ndice de embeddings para acelerar e padronizar compara√ß√µes (a compara√ß√£o ent√£o se reduz ao produto escalar entre vetores normalizados).\n",
    "- Modelos diferentes geram dimens√µes (dim) diferentes; a normaliza√ß√£o evita que a dimens√£o afete a similaridade diretamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471a8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tentar OpenAI (pequeno) -> OpenAI (large) -> Google -> Erro amig√°vel\n",
    "openai_small_available = bool(os.getenv('OPENAI_API_KEY'))\n",
    "openai_large_available = bool(os.getenv('OPENAI_API_KEY'))\n",
    "google_available = bool(os.getenv('GOOGLE_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06abbe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fun√ß√£o helper para rodar OpenAI e obter uso\n",
    "\n",
    "def get_openai_embeddings(texts_list, model_name):\n",
    "    embeddings = []\n",
    "    total_tokens = 0\n",
    "    for t in texts_list:\n",
    "        emb, usage = openai_embedding(t, model=model_name, return_usage=True)\n",
    "        embeddings.append(emb)\n",
    "        if usage is not None:\n",
    "            try:\n",
    "                total_tokens += int(usage)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return embeddings, total_tokens if total_tokens else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f4a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "\n",
    "# OpenAI small\n",
    "if openai_small_available:\n",
    "    try:\n",
    "        emb_small, tokens_small = get_openai_embeddings(texts, 'text-embedding-3-small')\n",
    "        results['openai_small'] = {'embeddings': emb_small, 'tokens': tokens_small, 'dim': len(emb_small[0])}\n",
    "    except Exception as e:\n",
    "        print('Falha ao gerar embeddings OpenAI small:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e8d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OpenAI large\n",
    "if openai_large_available:\n",
    "    try:\n",
    "        emb_large, tokens_large = get_openai_embeddings(texts, 'text-embedding-3-large')\n",
    "        results['openai_large'] = {'embeddings': emb_large, 'tokens': tokens_large, 'dim': len(emb_large[0])}\n",
    "    except Exception as e:\n",
    "        print('Falha ao gerar embeddings OpenAI large:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401f49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Google embeddings\n",
    "if google_available:\n",
    "    try:\n",
    "        emb_google = [google_embedding(t) for t in texts]\n",
    "        results['google'] = {'embeddings': emb_google, 'tokens': None, 'dim': len(emb_google[0])}\n",
    "    except Exception as e:\n",
    "        print('Falha ao gerar embeddings Google:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebd670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backend: openai_small\n",
      "Dimens√£o: 1536\n",
      "Tokens (se dispon√≠vel): 32\n",
      " Embedding 1 primeiros 5: [0.0014218955766409636, -0.0044931466691195965, -0.040188223123550415, 0.04201652854681015, 0.015540596097707748]\n",
      " Embedding 2 primeiros 5: [-0.012964113615453243, 0.009385946206748486, -0.061422210186719894, 0.0561358705163002, 0.017261510714888573]\n",
      " Embedding 3 primeiros 5: [0.019509999081492424, 0.027966845780611038, -0.003894458757713437, -0.009701134636998177, 0.04860801622271538]\n",
      " Similaridade 1-2: 0.8135\n",
      " Similaridade 1-3: 0.1421\n",
      "\n",
      "Backend: openai_large\n",
      "Dimens√£o: 3072\n",
      "Tokens (se dispon√≠vel): 32\n",
      " Embedding 1 primeiros 5: [-0.021825000643730164, 0.03996645659208298, -0.0028245302382856607, 0.0035684334579855204, 0.010693789459764957]\n",
      " Embedding 2 primeiros 5: [-0.016434069722890854, 0.02808525785803795, -0.002878795610740781, -0.02375573106110096, 0.024798443540930748]\n",
      " Embedding 3 primeiros 5: [0.00042473155190236866, 0.0036773430183529854, -0.023540019989013672, 0.039040759205818176, -0.002575082238763571]\n",
      " Similaridade 1-2: 0.8490\n",
      " Similaridade 1-3: 0.2333\n",
      "\n",
      "Backend: google\n",
      "Dimens√£o: 768\n",
      "Tokens (se dispon√≠vel): None\n",
      " Embedding 1 primeiros 5: [-0.03717346116900444, 0.039104245603084564, 0.03194810450077057, 0.01872444525361061, 0.028032803907990456]\n",
      " Embedding 2 primeiros 5: [-0.007043433841317892, -0.0034578817430883646, 0.04423297569155693, 0.00344060524366796, -0.023989398032426834]\n",
      " Embedding 3 primeiros 5: [0.012518281117081642, -0.012970996089279652, -0.03129762411117554, 0.014595143496990204, -0.0020304142963141203]\n",
      " Similaridade 1-2: 0.8029\n",
      " Similaridade 1-3: 0.3914\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mostrar resultados: dimens√£o, primeiros 5 valores e similaridades por backend\n",
    "for k, v in results.items():\n",
    "    print('\\nBackend:', k)\n",
    "    print('Dimens√£o:', v['dim'])\n",
    "    print('Tokens (se dispon√≠vel):', v['tokens'])\n",
    "    for i, e in enumerate(v['embeddings']):\n",
    "        print(f' Embedding {i+1} primeiros 5:', e[:5])\n",
    "    # calcular similaridade\n",
    "    sim_12 = cosine_sim(v['embeddings'][0], v['embeddings'][1])\n",
    "    sim_13 = cosine_sim(v['embeddings'][0], v['embeddings'][2])\n",
    "    print(f' Similaridade 1-2: {sim_12:.4f}')\n",
    "    print(f' Similaridade 1-3: {sim_13:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b540a82",
   "metadata": {},
   "source": [
    "### Como interpretar os resultados e o que estamos comparando\n",
    "\n",
    "Nesta se√ß√£o comparamos **tr√™s modelos** de embeddings: OpenAI (text-embedding-3-small), OpenAI (text-embedding-3-large) e Google (text-embedding-004). Para cada um comparamos:\n",
    "\n",
    "- Dimens√£o (dim): n√∫mero de componentes no vetor de embedding. Modelos maiores normalmente representam mais informa√ß√µes, mas s√£o mais caros e custam mais em armazenamento/consulta.\n",
    "- Tokens (quando dispon√≠vel): n√∫mero total de tokens usados nas chamadas (dispon√≠vel para OpenAI via response.usage.total_tokens). √ötil para estimativa de custo.\n",
    "- Primeiros 5 valores do embedding: r√°pido ‚Äúcheck‚Äù para ver distribui√ß√£o/escala dos vetores.\n",
    "- Similaridade 1-2 vs 1-3: comparamos a similaridade entre a frase 1 e 2 (sem√¢ntica pr√≥xima) e entre 1 e 3 (sem√¢ntica diferente). O **esperado** √© que 1-2 tenha similaridade maior que 1-3.\n",
    "\n",
    "Interpreta√ß√£o:\n",
    "- Se a similaridade 1-2 > 1-3, o modelo est√° capturando corretamente sem√¢ntica local entre as frases; quanto maior a diferen√ßa, maior a separa√ß√£o sem√¢ntica observada.\n",
    "- Uma similaridade muito alta entre 1 e 3 sugere que o modelo n√£o distingue bem os dois conceitos ou que as frases compartilham termos/estruturas que influenciam a representa√ß√£o.\n",
    "- Use a dimens√£o e tokens para equilibrar custo vs qualidade: modelos com maior dimens√£o costumam retornar maior qualidade sem√¢ntica, mas com custo e lat√™ncia maiores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8da26514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimativa de custos (usa pre√ßos p√∫blicos quando poss√≠vel)\n",
    "import re\n",
    "import requests\n",
    "from math import ceil\n",
    "\n",
    "# Valores padr√£o baseados em informa√ß√µes p√∫blicas (revisar e atualizar conforme o site oficial):\n",
    "# - OpenAI text-embedding-3-small: $0.002 por 1K tokens\n",
    "# - OpenAI text-embedding-3-large: $0.006 por 1K tokens\n",
    "# - Google text-embedding-004: $0.0006 por 1K caracteres (estimativa; confirmar doc)\n",
    "PRICING = {\n",
    "    'openai_text-embedding-3-small': {'per_1k_tokens_usd': 0.002},\n",
    "    'openai_text-embedding-3-large': {'per_1k_tokens_usd': 0.006},\n",
    "    'google_text-embedding-004': {'per_1k_chars_usd': 0.0006}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed53ebb",
   "metadata": {},
   "source": [
    "### Metodologia de estimativa de custos\n",
    "\n",
    "Explica√ß√£o de como calculamos o custo estimado por execu√ß√£o:\n",
    "\n",
    "- Para modelos OpenAI (text-embedding-3-small e -large) usamos *tokens* (quando retornados no campo usage.total_tokens) e aplicamos o custo por 1K tokens: custo = (tokens / 1000) * price_per_1k_tokens.\n",
    "- Para modelos Google (text-embedding-004) usamos o comprimento do texto (characters) como proxy ‚Äî o Google pode cobrar por caracteres ou por modelo, portanto usamos uma heur√≠stica de `per_1k_chars_usd` quando n√£o h√° metadados mais espec√≠ficos.\n",
    "- `PRICING` √© um dicion√°rio edit√°vel que cont√©m tarifas por 1k tokens ou por 1k caracteres. Esse dicion√°rio pode ser atualizado manualmente com valores oficiais.\n",
    "- Se `usage.total_tokens` n√£o estiver dispon√≠vel para um modelo, estimamos tokens com uma heur√≠stica simples (ex.: 1.3 tokens por palavra) quando necess√°rio.\n",
    "\n",
    "Limita√ß√µes e recomenda√ß√µes:\n",
    "- Os valores s√£o estimativas e dependem de como cada fornecedor conta tokens/characters e do seu plano de tarifa√ß√£o espec√≠fico.\n",
    "- Para custos de produ√ß√£o, valide com a documenta√ß√£o de pre√ßos atualizada (links: OpenAI pricing e Google Vertex AI pricing) e/ou use as APIs oficiais de faturamento, quando dispon√≠veis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c76e3931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√£o foi poss√≠vel recuperar pre√ßos da OpenAI automaticamente. Usando valores padr√µes no dict PRICING\n",
      "N√£o foi poss√≠vel recuperar pre√ßos do Google automaticamente. Usando valores padr√µes no dict PRICING\n"
     ]
    }
   ],
   "source": [
    "# Tenta buscar pre√ßos atualizados automaticamente\n",
    "\n",
    "def try_fetch_openai_prices():\n",
    "    \"\"\"Tenta buscar pre√ßo de embeddings do site da OpenAI. Retorna None em caso de falha.\"\"\"\n",
    "    try:\n",
    "        url = 'https://platform.openai.com/docs/guides/embeddings/pricing'\n",
    "        r = requests.get(url, timeout=6)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        text = r.text\n",
    "        # encontrar pre√ßo com padr√£o $X.XXXX / 1K\n",
    "        m_small = re.search(r\"text-embedding-3-small\\D*\\$([0-9]*\\.?[0-9]+)\\s*/\\s*1K\", text, re.IGNORECASE)\n",
    "        m_large = re.search(r\"text-embedding-3-large\\D*\\$([0-9]*\\.?[0-9]+)\\s*/\\s*1K\", text, re.IGNORECASE)\n",
    "        if m_small or m_large:\n",
    "            result = {}\n",
    "            if m_small:\n",
    "                result['openai_text-embedding-3-small'] = {'per_1k_tokens_usd': float(m_small.group(1))}\n",
    "            if m_large:\n",
    "                result['openai_text-embedding-3-large'] = {'per_1k_tokens_usd': float(m_large.group(1))}\n",
    "            return result\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def try_fetch_google_prices():\n",
    "    \"\"\"Tenta buscar pre√ßos da Google (Vertex AI). Retorna None se falhar.\"\"\"\n",
    "    try:\n",
    "        url = 'https://cloud.google.com/vertex-ai/generative-ai/pricing'\n",
    "        r = requests.get(url, timeout=6)\n",
    "        if r.status_code != 200:\n",
    "            url2 = 'https://cloud.google.com/vertex-ai/pricing'\n",
    "            r = requests.get(url2, timeout=6)\n",
    "            if r.status_code != 200:\n",
    "                return None\n",
    "        text = r.text\n",
    "        # Procurar padr√µes tipo $X.XXXX / 1K chars\n",
    "        m = re.search(r\"text-embedding-004\\D*\\$([0-9]*\\.?[0-9]+)\\s*/\\s*1K\", text, re.IGNORECASE)\n",
    "        if m:\n",
    "            return {'google_text-embedding-004': {'per_1k_chars_usd': float(m.group(1))}}\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Tentar atualizar PRICING automaticamente\n",
    "fopenai = try_fetch_openai_prices()\n",
    "if fopenai:\n",
    "    PRICING.update(fopenai)\n",
    "    print('PRICING atualizado com valores OpenAI recuperados automaticamente')\n",
    "else:\n",
    "    print('N√£o foi poss√≠vel recuperar pre√ßos da OpenAI automaticamente. Usando valores padr√µes no dict PRICING')\n",
    "\n",
    "fgoogle = try_fetch_google_prices()\n",
    "if fgoogle:\n",
    "    PRICING.update(fgoogle)\n",
    "    print('PRICING atualizado com valores Google recuperados automaticamente')\n",
    "else:\n",
    "    print('N√£o foi poss√≠vel recuperar pre√ßos do Google automaticamente. Usando valores padr√µes no dict PRICING')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bd57a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: openai_small ‚Äî Estimativa de custo desta execu√ß√£o: $0.000064\n",
      "Modelo: openai_large ‚Äî Estimativa de custo desta execu√ß√£o: $0.000192\n",
      "Modelo: google ‚Äî Estimativa de custo desta execu√ß√£o: $0.000068\n",
      "\n",
      "Observa√ß√£o: revise os valores em PRICING e atualize para os pre√ßos p√∫blicos mais recentes quando necess√°rio.\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para estimar custo baseado em tokens ou caracteres\n",
    "\n",
    "def estimate_tokens_from_text(text: str) -> int:\n",
    "    # heur√≠stica simples: assume ~1.3 tokens por palavra\n",
    "    words = text.split()\n",
    "    return max(1, int(ceil(len(words) * 1.3)))\n",
    "\n",
    "\n",
    "def estimate_cost(model_key: str, tokens: int = None, text: str = None, chars: int = None) -> float:\n",
    "    pricing = PRICING.get(model_key)\n",
    "    if pricing is None:\n",
    "        raise KeyError(f'Modelo {model_key} sem pre√ßo definido no PRICING dict')\n",
    "\n",
    "    if tokens is None and text is not None:\n",
    "        tokens = estimate_tokens_from_text(text)\n",
    "    if chars is None and text is not None:\n",
    "        chars = len(text)\n",
    "\n",
    "    if 'per_1k_tokens_usd' in pricing:\n",
    "        if tokens is None:\n",
    "            raise ValueError('tokens required for token-based pricing')\n",
    "        return (tokens / 1000.0) * pricing['per_1k_tokens_usd']\n",
    "    elif 'per_1k_chars_usd' in pricing:\n",
    "        if chars is None:\n",
    "            raise ValueError('chars required for char-based pricing')\n",
    "        return (chars / 1000.0) * pricing['per_1k_chars_usd']\n",
    "    else:\n",
    "        raise KeyError('Modelo com tipo de pre√ßo desconhecido')\n",
    "\n",
    "# Calcular custo estimado para os resultados existentes no notebook (results dict)\n",
    "results_cost = {}\n",
    "for k, v in results.items():\n",
    "    model_key = None\n",
    "    if k == 'openai_small':\n",
    "        model_key = 'openai_text-embedding-3-small'\n",
    "    elif k == 'openai_large':\n",
    "        model_key = 'openai_text-embedding-3-large'\n",
    "    elif k == 'google':\n",
    "        model_key = 'google_text-embedding-004'\n",
    "\n",
    "    tokens = v.get('tokens')\n",
    "    estimated_cost = None\n",
    "    try:\n",
    "        if tokens:\n",
    "            estimated_cost = estimate_cost(model_key, tokens=tokens)\n",
    "        else:\n",
    "            total_chars = sum(len(t) for t in texts)\n",
    "            estimated_cost = estimate_cost(model_key, chars=total_chars)\n",
    "    except Exception as e:\n",
    "        estimated_cost = None\n",
    "    results_cost[k] = estimated_cost\n",
    "\n",
    "# Mostrar estimativas\n",
    "for k, c in results_cost.items():\n",
    "    print(f'Modelo: {k} ‚Äî Estimativa de custo desta execu√ß√£o: ${c:.6f}' if c is not None else f'Modelo: {k} ‚Äî custo n√£o calculado (falta de info)')\n",
    "\n",
    "print('\\nObserva√ß√£o: revise os valores em PRICING e atualize para os pre√ßos p√∫blicos mais recentes quando necess√°rio.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18772b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV report to E:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\data\\embeddings\\comparative_results.csv\n",
      "\n",
      "DataFrame summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dim</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sim_12</th>\n",
       "      <th>sim_13</th>\n",
       "      <th>est_cost_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai_small</td>\n",
       "      <td>1536</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.813467</td>\n",
       "      <td>0.142096</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai_large</td>\n",
       "      <td>3072</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.848981</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google</td>\n",
       "      <td>768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.802875</td>\n",
       "      <td>0.391370</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model   dim  tokens    sim_12    sim_13  est_cost_usd\n",
       "0  openai_small  1536    32.0  0.813467  0.142096      0.000064\n",
       "1  openai_large  3072    32.0  0.848981  0.233285      0.000192\n",
       "2        google   768     NaN  0.802875  0.391370      0.000068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to E:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\data\\embeddings\\similarity_comparison.png\n",
      "Saved plot to E:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\data\\embeddings\\cost_comparison.png\n",
      "\n",
      "Instru√ß√µes para exportar o notebook como slides (Reveal.js) ou PDF:\n",
      "1) Para gerar slides HTML:\n",
      "   jupyter nbconvert --to slides notebooks/quick_test_classroom.ipynb --reveal-prefix 'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/'\n",
      "2) Para gerar PDF (pode exigir LaTeX):\n",
      "   jupyter nbconvert --to pdf notebooks/quick_test_classroom.ipynb\n"
     ]
    }
   ],
   "source": [
    "# 6) Gerar relat√≥rio: CSV + gr√°ficos + instru√ß√µes para exportar slides/PDF\n",
    "\n",
    "\n",
    "# tentativas de import para pandas/matplotlib; se faltar, gerar CSV somente\n",
    "have_pandas = True\n",
    "have_matplotlib = True\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception:\n",
    "    have_pandas = False\n",
    "    pd = None\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception:\n",
    "    have_matplotlib = False\n",
    "    plt = None\n",
    "\n",
    "# Criar pasta para salvar resultados\n",
    "out_dir = Path('../../data') / 'embeddings'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Montar linhas para CSV\n",
    "rows = []\n",
    "for k, v in results.items():\n",
    "    try:\n",
    "        sim_12 = cosine_sim(v['embeddings'][0], v['embeddings'][1])\n",
    "        sim_13 = cosine_sim(v['embeddings'][0], v['embeddings'][2])\n",
    "    except Exception:\n",
    "        sim_12 = None\n",
    "        sim_13 = None\n",
    "    rows.append({\n",
    "        'model': k,\n",
    "        'dim': v.get('dim'),\n",
    "        'tokens': v.get('tokens'),\n",
    "        'sim_12': sim_12,\n",
    "        'sim_13': sim_13,\n",
    "        'est_cost_usd': results_cost.get(k)\n",
    "    })\n",
    "\n",
    "csv_path = out_dir / 'comparative_results.csv'\n",
    "with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['model', 'dim', 'tokens', 'sim_12', 'sim_13', 'est_cost_usd'])\n",
    "    writer.writeheader()\n",
    "    for r in rows:\n",
    "        writer.writerow(r)\n",
    "print(f'Saved CSV report to {csv_path.resolve()}')\n",
    "\n",
    "# If pandas available, show DataFrame\n",
    "if have_pandas:\n",
    "    df = pd.DataFrame(rows)\n",
    "    print('\\nDataFrame summary:')\n",
    "    display(df)\n",
    "else:\n",
    "    print('\\nCSV content preview:')\n",
    "    for r in rows:\n",
    "        print(r)\n",
    "\n",
    "# Tentar criar plots se matplotlib estiver dispon√≠vel\n",
    "if have_matplotlib and plt is not None:\n",
    "    df = pd.DataFrame(rows) if have_pandas else None\n",
    "    # Make arrays for plotting\n",
    "    models = [r['model'] for r in rows]\n",
    "    sim12 = [r['sim_12'] if r['sim_12'] is not None else 0 for r in rows]\n",
    "    sim13 = [r['sim_13'] if r['sim_13'] is not None else 0 for r in rows]\n",
    "    costs = [r['est_cost_usd'] if r['est_cost_usd'] is not None else 0 for r in rows]\n",
    "\n",
    "    # Similarity bar chart\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    x = range(len(models))\n",
    "    plt.bar(x, sim12, width=0.4, label='Sim 1-2')\n",
    "    plt.bar([i + 0.4 for i in x], sim13, width=0.4, label='Sim 1-3')\n",
    "    plt.title('Similaridade (cosine) por modelo')\n",
    "    plt.xticks([i + 0.2 for i in x], models)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plot1 = out_dir / 'similarity_comparison.png'\n",
    "    plt.savefig(plot1)\n",
    "    print(f'Saved plot to {plot1.resolve()}')\n",
    "    plt.close()\n",
    "\n",
    "    # Cost chart\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(models, costs, color='orange')\n",
    "    plt.title('Estimated cost per run (USD)')\n",
    "    plt.ylabel('USD')\n",
    "    plt.tight_layout()\n",
    "    plot2 = out_dir / 'cost_comparison.png'\n",
    "    plt.savefig(plot2)\n",
    "    print(f'Saved plot to {plot2.resolve()}')\n",
    "    plt.close()\n",
    "else:\n",
    "    print('\\nMatplotlib or pandas not installed; plots skipped. To enable plots: pip install pandas matplotlib')\n",
    "\n",
    "# Instru√ß√µes para exportar o notebook em slides/PDF\n",
    "print('\\nInstru√ß√µes para exportar o notebook como slides (Reveal.js) ou PDF:')\n",
    "print('1) Para gerar slides HTML:')\n",
    "print(\"   jupyter nbconvert --to slides notebooks/quick_test_classroom.ipynb --reveal-prefix 'https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/'\")\n",
    "print('2) Para gerar PDF (pode exigir LaTeX):')\n",
    "print('   jupyter nbconvert --to pdf notebooks/quick_test_classroom.ipynb')\n",
    "\n",
    "# Tamb√©m posso gerar esses arquivos automaticamente se preferir (recomendo usar o terminal)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11-34-engenharia-vetorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
