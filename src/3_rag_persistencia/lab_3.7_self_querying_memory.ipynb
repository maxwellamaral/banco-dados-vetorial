{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c777cc20",
   "metadata": {},
   "source": [
    "# üéì Lab 3.7: Self-Querying e Mem√≥ria Conversacional em RAG\n",
    "\n",
    "## üìñ Objetivos de Aprendizagem\n",
    "\n",
    "Ao final desta pr√°tica, voc√™ ser√° capaz de:\n",
    "\n",
    "1. ‚úÖ **Compreender** o conceito de Self-Querying e sua import√¢ncia em sistemas RAG\n",
    "2. ‚úÖ **Implementar** extra√ß√£o autom√°tica de filtros de metadados usando LLMs\n",
    "3. ‚úÖ **Criar** um sistema de mem√≥ria conversacional para chatbots\n",
    "4. ‚úÖ **Desenvolver** um chatbot RAG completo com capacidades avan√ßadas\n",
    "5. ‚úÖ **Identificar** quando usar estas t√©cnicas em projetos reais\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Contexto da Pr√°tica\n",
    "\n",
    "### O Problema:\n",
    "\n",
    "Sistemas RAG b√°sicos t√™m duas limita√ß√µes cr√≠ticas:\n",
    "\n",
    "**1. Filtros Manuais:**\n",
    "```python\n",
    "# ‚ùå Usu√°rio precisa saber a estrutura t√©cnica\n",
    "vectorstore.search(\"futebol\", filter={\"doc_type\": \"manual\", \"year\": 2024})\n",
    "```\n",
    "\n",
    "**2. Sem Mem√≥ria:**\n",
    "\n",
    "```text\n",
    "Turno 1:\n",
    "üë§ \"Quais s√£o as forma√ß√µes do futebol?\"\n",
    "ü§ñ \"4-4-2, 4-3-3, 3-5-2...\"\n",
    "\n",
    "Turno 2:\n",
    "üë§ \"Qual √© a mais defensiva?\"\n",
    "ü§ñ ‚ùå \"Mais defensiva do qu√™? N√£o entendi o contexto.\"\n",
    "```\n",
    "\n",
    "### A Solu√ß√£o:\n",
    "\n",
    "**Self-Querying + Mem√≥ria = Sistema Natural e Inteligente**\n",
    "\n",
    "```text\n",
    "üë§ \"Me mostre manuais de 2024 sobre futebol\"\n",
    "ü§ñ [Extrai automaticamente: tipo=\"manual\", ano=2024]\n",
    "    [Busca com filtros aplicados]\n",
    "    \"Encontrei 3 manuais...\"\n",
    "\n",
    "üë§ \"Qual √© o mais recente?\"\n",
    "ü§ñ [Lembra do contexto: \"manuais de futebol\"]\n",
    "    \"O manual de t√°ticas ofensivas de dezembro/2024...\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üó∫Ô∏è Roteiro da Pr√°tica\n",
    "\n",
    "```text\n",
    "Parte 1: Setup e Configura√ß√£o\n",
    "   ‚Üì\n",
    "Parte 2: Carregamento de Documentos\n",
    "   ‚Üì\n",
    "Parte 3: Self-Querying (Extra√ß√£o de Filtros)\n",
    "   ‚Üì\n",
    "Parte 4: Mem√≥ria Conversacional\n",
    "   ‚Üì\n",
    "Parte 5: Chatbot RAG Completo\n",
    "   ‚Üì\n",
    "Parte 6: Demonstra√ß√£o Multi-Turn\n",
    "   ‚Üì\n",
    "Parte 7: An√°lise e Insights\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Dica:** Execute as c√©lulas em ordem sequencial. Algumas c√©lulas dependem de vari√°veis criadas anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a1a1a",
   "metadata": {},
   "source": [
    "## üì¶ Passo 1: Imports e Configura√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271beaa7",
   "metadata": {},
   "source": [
    "### üìö Entendendo as Bibliotecas\n",
    "\n",
    "**LangChain Community:**\n",
    "- `FAISS`: Banco de dados vetorial para busca por similaridade\n",
    "- `PyPDFLoader`: Carregador de documentos PDF\n",
    "\n",
    "**LangChain Ollama:**\n",
    "- `OllamaEmbeddings`: Gera embeddings (vetores) dos textos usando modelo local\n",
    "- `OllamaLLM`: Modelo de linguagem para gera√ß√£o de respostas\n",
    "\n",
    "**LangChain Core:**\n",
    "- `ChatPromptTemplate`: Templates para estruturar prompts\n",
    "- `InMemoryChatMessageHistory`: Armazenamento de hist√≥rico de conversas em mem√≥ria\n",
    "- `Document`: Classe para representar documentos com metadados\n",
    "\n",
    "**Bibliotecas Python:**\n",
    "- `pandas`: Manipula√ß√£o e visualiza√ß√£o de dados tabulares\n",
    "- `json` e `re`: Parsing de respostas JSON do LLM\n",
    "- `Path`: Manipula√ß√£o de caminhos de arquivos\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Por que Ollama?** Permite executar LLMs localmente, sem custos de API e com privacidade total!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8a9476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# LangChain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8782958",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Entendendo os Par√¢metros\n",
    "\n",
    "**Chunk Size (1800 caracteres):**\n",
    "- Tamanho ideal para manter contexto sem perder informa√ß√£o\n",
    "- Baseado em estudos de 2024-2025 sobre RAG em produ√ß√£o\n",
    "- Aproximadamente 400-450 tokens (para a maioria dos modelos)\n",
    "\n",
    "**Chunk Overlap (300 caracteres):**\n",
    "- ~17% de sobreposi√ß√£o entre chunks consecutivos\n",
    "- Evita que informa√ß√µes importantes sejam cortadas\n",
    "- Garante continuidade sem√¢ntica entre chunks\n",
    "\n",
    "**Top-K Retrieval (4 documentos):**\n",
    "- N√∫mero de chunks recuperados da busca vetorial\n",
    "- Balan√ßo entre contexto suficiente e noise\n",
    "- Pode ser ajustado conforme necessidade\n",
    "\n",
    "**Exemplo Visual:**\n",
    "\n",
    "```text\n",
    "Documento Original (5400 chars):\n",
    "‚îú‚îÄ Chunk 1 [0:1800]\n",
    "‚îú‚îÄ Chunk 2 [1500:3300]  ‚Üê 300 chars de overlap com Chunk 1\n",
    "‚îî‚îÄ Chunk 3 [3000:4800]  ‚Üê 300 chars de overlap com Chunk 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **Importante:** Certifique-se de que o Ollama est√° rodando em `localhost:11434` antes de executar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c33b491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üéØ CONFIGURA√á√ÉO DO SISTEMA\n",
      "================================================================================\n",
      "\n",
      "üìÅ PDFs: e:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\data\\pdfs\n",
      "ü§ñ Ollama: http://localhost:11434\n",
      "üß† Embedding: embeddinggemma\n",
      "üí¨ LLM: llama3.2:1b\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes\n",
    "OLLAMA_BASE_URL = 'http://localhost:11434'\n",
    "BASE_DIR = Path.cwd()\n",
    "PDF_DIR = BASE_DIR.parent.parent / \"data\" / \"pdfs\"\n",
    "\n",
    "# Modelos\n",
    "EMBEDDING_MODEL = 'embeddinggemma'\n",
    "LLM_MODEL = 'llama3.2:1b'\n",
    "\n",
    "# Par√¢metros\n",
    "CHUNK_SIZE = 1800\n",
    "CHUNK_OVERLAP = 300\n",
    "TOP_K_RETRIEVAL = 4\n",
    "\n",
    "print(\"=\"  * 80)\n",
    "print(\"üéØ CONFIGURA√á√ÉO DO SISTEMA\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìÅ PDFs: {PDF_DIR}\")\n",
    "print(f\"ü§ñ Ollama: {OLLAMA_BASE_URL}\")\n",
    "print(f\"üß† Embedding: {EMBEDDING_MODEL}\")\n",
    "print(f\"üí¨ LLM: {LLM_MODEL}\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a9a30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì• Passo 2: Carregamento R√°pido de Documentos\n",
    "\n",
    "Vamos carregar os PDFs e criar o vectorstore rapidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba86d9",
   "metadata": {},
   "source": [
    "### üîç An√°lise da Fun√ß√£o de Carregamento\n",
    "\n",
    "A fun√ß√£o `load_and_process_pdfs()` realiza **3 opera√ß√µes cr√≠ticas**:\n",
    "\n",
    "**1. Detec√ß√£o Autom√°tica de Tipo:**\n",
    "```python\n",
    "# Exemplo: \"manual_futebol_2024.pdf\"\n",
    "if \"manual\" in filename.lower():\n",
    "    doc_type = \"manual\"  ‚úÖ\n",
    "```\n",
    "\n",
    "**2. Extra√ß√£o de Ano:**\n",
    "```python\n",
    "# Exemplo: \"relatorio_taticas_2024.pdf\"\n",
    "for part in filename.split('_'):\n",
    "    if part == \"2024\":  # Ano v√°lido (20XX)\n",
    "        year = 2024  ‚úÖ\n",
    "```\n",
    "\n",
    "**3. Enriquecimento de Metadados:**\n",
    "```python\n",
    "# Cada p√°gina recebe:\n",
    "{\n",
    "    \"source\": \"manual_futebol_2024.pdf\",\n",
    "    \"doc_type\": \"manual\",\n",
    "    \"year\": 2024,\n",
    "    \"page\": 5\n",
    "}\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d5a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_pdfs(pdf_dir: Path) -> List[Document]:\n",
    "    \"\"\"Carrega PDFs e adiciona metadados b√°sicos.\"\"\"\n",
    "    \n",
    "    pdf_paths = list(pdf_dir.glob(\"*.pdf\"))\n",
    "    \n",
    "    if not pdf_paths:\n",
    "        print(\"‚ö†Ô∏è Nenhum PDF encontrado!\")\n",
    "        return []\n",
    "    \n",
    "    all_docs = []\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        # Extrai metadados do nome do arquivo\n",
    "        filename = pdf_path.stem\n",
    "        \n",
    "        # Tipo de documento\n",
    "        doc_type = \"documento\"\n",
    "        if \"manual\" in filename.lower():\n",
    "            doc_type = \"manual\"\n",
    "        elif \"relatorio\" in filename.lower() or \"report\" in filename.lower():\n",
    "            doc_type = \"relatorio\"\n",
    "        elif \"artigo\" in filename.lower() or \"paper\" in filename.lower():\n",
    "            doc_type = \"artigo\"\n",
    "        \n",
    "        # Ano (se tiver no nome)\n",
    "        year = None\n",
    "        for part in filename.split('_'):\n",
    "            if part.isdigit() and len(part) == 4 and part.startswith('20'):\n",
    "                year = int(part)\n",
    "                break\n",
    "        \n",
    "        # Carrega PDF\n",
    "        loader = PyPDFLoader(str(pdf_path))\n",
    "        docs = loader.load()\n",
    "        \n",
    "        # Enriquece com metadados\n",
    "        for doc in docs:\n",
    "            doc.metadata.update({\n",
    "                \"source\": pdf_path.name,\n",
    "                \"doc_type\": doc_type,\n",
    "                \"year\": year,\n",
    "            })\n",
    "            all_docs.append(doc)\n",
    "    \n",
    "    return all_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418d6dd",
   "metadata": {},
   "source": [
    "\n",
    "### üí° Por que Metadados S√£o Importantes?\n",
    "\n",
    "**Sem metadados:**\n",
    "```python\n",
    "\"Me mostre manuais de 2024\"\n",
    "‚Üí Busca em TODOS os documentos ‚ùå\n",
    "‚Üí Resultados misturados (artigos, relat√≥rios, etc.)\n",
    "```\n",
    "\n",
    "**Com metadados:**\n",
    "```python\n",
    "\"Me mostre manuais de 2024\"\n",
    "‚Üí Filtro: doc_type=\"manual\" AND year=2024 ‚úÖ\n",
    "‚Üí Apenas manuais de 2024!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Dica Pr√°tica:** Organize seus PDFs com nomes descritivos:\n",
    "- ‚úÖ `manual_instalacao_2024.pdf`\n",
    "- ‚úÖ `artigo_ia_futebol_2023.pdf`\n",
    "- ‚ùå `doc1.pdf` (sem contexto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32d44091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Carregando PDFs...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 28 p√°ginas carregadas\n",
      "\n",
      "üìä Por tipo:\n",
      "   documento: 9 p√°ginas\n",
      "   manual: 16 p√°ginas\n",
      "   relatorio: 3 p√°ginas\n"
     ]
    }
   ],
   "source": [
    "# Carrega documentos\n",
    "print(\"üìö Carregando PDFs...\\n\")\n",
    "documents = load_and_process_pdfs(PDF_DIR)\n",
    "\n",
    "if documents:\n",
    "    print(f\"‚úÖ {len(documents)} p√°ginas carregadas\")\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    tipos = {}\n",
    "    for doc in documents:\n",
    "        doc_type = doc.metadata.get('doc_type', 'N/A')\n",
    "        tipos[doc_type] = tipos.get(doc_type, 0) + 1\n",
    "    \n",
    "    print(f\"\\nüìä Por tipo:\")\n",
    "    for tipo, count in tipos.items():\n",
    "        print(f\"   {tipo}: {count} p√°ginas\")\n",
    "else:\n",
    "    print(\"üí° Adicione PDFs na pasta data/pdfs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6adad7",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Verifica√ß√£o Importante\n",
    "\n",
    "**Antes de prosseguir, vamos verificar se h√° PDFs dispon√≠veis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba4c153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìÑ AMOSTRA DO CONTE√öDO DOS DOCUMENTOS\n",
      "================================================================================\n",
      "\n",
      "üìö 7 arquivos carregados:\n",
      "\n",
      "1. api_documentation_2023.pdf\n",
      "   Tipo: documento | Ano: 2023 | P√°ginas: 3\n",
      "   Preview: Documenta√ß√£o da API\n",
      " E-commerce Platform REST API v2.0\n",
      "Vis√£o Geral:\n",
      "Esta documenta√ß√£o descreve os endpoints da API REST do nosso sistema de e-commerce...\n",
      "\n",
      "2. livro_receitas_2025.pdf\n",
      "   Tipo: documento | Ano: 2025 | P√°ginas: 6\n",
      "   Preview: Livro de Receitas Pr√°ticas\n",
      " Sabores do Mundo em Casa\n",
      "Lasanha √† Bolonhesa Tradicional\n",
      "Rendimento: 8 por√ß√µes | Tempo de preparo: 2 horas\n",
      "Ingredientes pa...\n",
      "\n",
      "3. manual_futebol_2023_copia.pdf\n",
      "   Tipo: manual | Ano: 2023 | P√°ginas: 4\n",
      "   Preview: Manual Completo de Futebol\n",
      " Regras, T√°ticas e Estrat√©gias\n",
      "Regras Oficiais da FIFA\n",
      "Dimens√µes do Campo:\n",
      "O campo de futebol deve ter formato retangular c...\n",
      "\n",
      "4. manual_futebol_2025.pdf\n",
      "   Tipo: manual | Ano: 2025 | P√°ginas: 4\n",
      "   Preview: Manual Completo de Futebol\n",
      " Regras, T√°ticas e Estrat√©gias\n",
      "Regras Oficiais da FIFA\n",
      "Dimens√µes do Campo:\n",
      "O campo de futebol deve ter formato retangular c...\n",
      "\n",
      "5. manual_futebol_2025_com_dup.pdf\n",
      "   Tipo: manual | Ano: 2025 | P√°ginas: 5\n",
      "   Preview: Manual Completo de Futebol \n",
      "Regras, T√°ticas e Estrat√©gias \n",
      " \n",
      "Regras Oficiais da FIFA \n",
      "Dimens√µes do Campo: \n",
      "O campo de futebol deve ter formato retangu...\n",
      "\n",
      "6. manual_iphone_2025.pdf\n",
      "   Tipo: manual | Ano: 2025 | P√°ginas: 3\n",
      "   Preview: Manual do Usu√°rio\n",
      " iPhone 15 Pro Max\n",
      "Bem-vindo ao seu novo iPhone 15 Pro Max\n",
      "O iPhone 15 Pro Max representa o √°pice da tecnologia m√≥vel da Apple. Este...\n",
      "\n",
      "7. relatorio_supercopa_2023.pdf\n",
      "   Tipo: relatorio | Ano: 2023 | P√°ginas: 3\n",
      "   Preview: RELAT√ìRIO T√âCNICO DE AN√ÅLISE: FINAL DA SUPERCOPA FICT√çCIA 2025 \n",
      "Data: 24 de Outubro de 2025 Partida: Real Metr√≥polis (Equipe A) vs. Uni√£o do \n",
      "Litoral ...\n",
      "\n",
      "================================================================================\n",
      "üí° SUGEST√ïES DE QUERIES BASEADAS NOS DOCUMENTOS:\n",
      "================================================================================\n",
      "\n",
      "Baseado nos arquivos dispon√≠veis, tente queries como:\n",
      "   ‚Ä¢ 'Me mostre manuais sobre futebol'\n",
      "   ‚Ä¢ 'Quais s√£o os manuais de 2025?'\n",
      "   ‚Ä¢ 'Me mostre o relat√≥rio da supercopa'\n",
      "   ‚Ä¢ 'Me mostre manuais t√©cnicos'\n",
      "   ‚Ä¢ 'Documenta√ß√£o de API'\n",
      "   ‚Ä¢ 'Livros de receitas de 2025'\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Explora o conte√∫do dos documentos\n",
    "print(\"=\" * 80)\n",
    "print(\"üìÑ AMOSTRA DO CONTE√öDO DOS DOCUMENTOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if documents:\n",
    "    # Mostra estat√≠sticas por arquivo\n",
    "    arquivos_info = {}\n",
    "    for doc in documents:\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        if source not in arquivos_info:\n",
    "            arquivos_info[source] = {\n",
    "                'paginas': 0,\n",
    "                'tipo': doc.metadata.get('doc_type', 'N/A'),\n",
    "                'ano': doc.metadata.get('year', 'N/A'),\n",
    "                'preview': doc.page_content[:200]  # Primeiros 200 chars\n",
    "            }\n",
    "        arquivos_info[source]['paginas'] += 1\n",
    "    \n",
    "    print(f\"\\nüìö {len(arquivos_info)} arquivos carregados:\\n\")\n",
    "    \n",
    "    for idx, (arquivo, info) in enumerate(arquivos_info.items(), 1):\n",
    "        print(f\"{idx}. {arquivo}\")\n",
    "        print(f\"   Tipo: {info['tipo']} | Ano: {info['ano']} | P√°ginas: {info['paginas']}\")\n",
    "        print(f\"   Preview: {info['preview'][:150]}...\\n\")\n",
    "    \n",
    "    # Sugest√µes de queries baseadas nos documentos\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üí° SUGEST√ïES DE QUERIES BASEADAS NOS DOCUMENTOS:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nBaseado nos arquivos dispon√≠veis, tente queries como:\")\n",
    "    \n",
    "    if any('futebol' in arq.lower() for arq in arquivos_info.keys()):\n",
    "        print(\"   ‚Ä¢ 'Me mostre manuais sobre futebol'\")\n",
    "        print(\"   ‚Ä¢ 'Quais s√£o os manuais de 2025?'\")\n",
    "        print(\"   ‚Ä¢ 'Me mostre o relat√≥rio da supercopa'\")\n",
    "    \n",
    "    if any('iphone' in arq.lower() or 'api' in arq.lower() for arq in arquivos_info.keys()):\n",
    "        print(\"   ‚Ä¢ 'Me mostre manuais t√©cnicos'\")\n",
    "        print(\"   ‚Ä¢ 'Documenta√ß√£o de API'\")\n",
    "    \n",
    "    if any('receita' in arq.lower() for arq in arquivos_info.keys()):\n",
    "        print(\"   ‚Ä¢ 'Livros de receitas de 2025'\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "else:\n",
    "    print(\"\\n‚ùå Nenhum documento carregado para an√°lise!\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ddc2b",
   "metadata": {},
   "source": [
    "### üìÑ Explora√ß√£o do Conte√∫do dos Documentos\n",
    "\n",
    "**Vamos ver uma amostra do que h√° nos documentos carregados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47712041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÇÔ∏è Dividindo em chunks...\n",
      "\n",
      "‚úÖ 41 chunks criados\n",
      "   Tamanho m√©dio: 1218 chars\n"
     ]
    }
   ],
   "source": [
    "# Chunking\n",
    "print(\"\\n‚úÇÔ∏è Dividindo em chunks...\\n\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"‚úÖ {len(chunks)} chunks criados\")\n",
    "print(f\"   Tamanho m√©dio: {sum(len(c.page_content) for c in chunks) / len(chunks):.0f} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc528dc",
   "metadata": {},
   "source": [
    "\n",
    "### üìä Interpretando os Outputs\n",
    "\n",
    "**`vectorstore.index.ntotal`:**\n",
    "- N√∫mero total de vetores no √≠ndice\n",
    "- Exemplo: 150 chunks = 150 vetores\n",
    "\n",
    "**`vectorstore.index.d`:**\n",
    "- Dimensionalidade dos vetores\n",
    "- Exemplo: 768 (embeddinggemma padr√£o)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1106f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßÆ Criando embeddings e vectorstore...\n",
      "\n",
      "‚úÖ Vectorstore criado!\n",
      "   Vetores: 41\n",
      "   Dimens√µes: 768\n"
     ]
    }
   ],
   "source": [
    "# Cria vectorstore\n",
    "print(\"\\nüßÆ Criando embeddings e vectorstore...\\n\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=EMBEDDING_MODEL,\n",
    "    base_url=OLLAMA_BASE_URL\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Vectorstore criado!\")\n",
    "print(f\"   Vetores: {vectorstore.index.ntotal}\")\n",
    "print(f\"   Dimens√µes: {vectorstore.index.d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cbadd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Passo 3: Self-Querying (Extra√ß√£o Autom√°tica de Filtros)\n",
    "\n",
    "### O que √© Self-Querying?\n",
    "\n",
    "**Self-Querying** permite que o LLM **automaticamente extraia filtros de metadados** da query do usu√°rio.\n",
    "\n",
    "#### Exemplo:\n",
    "\n",
    "```text\n",
    "üë§ Usu√°rio: \"Me mostre manuais de 2024 sobre futebol\"\n",
    "\n",
    "ü§ñ Sistema (self-querying):\n",
    "   Query sem√¢ntica: \"futebol\"\n",
    "   Filtros extra√≠dos: {doc_type: \"manual\", year: 2024}\n",
    "```\n",
    "\n",
    "### Benef√≠cios:\n",
    "\n",
    "- ‚úÖ **UX Natural:** Usu√°rio fala como humano\n",
    "- ‚úÖ **Menos C√≥digo:** N√£o precisa parsear manualmente\n",
    "- ‚úÖ **Mais Preciso:** Filtros reduzem ru√≠do\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2ff69",
   "metadata": {},
   "source": [
    "### üß† Anatomia da Fun√ß√£o de Self-Querying\n",
    "\n",
    "**Fluxo de Processamento:**\n",
    "\n",
    "```text\n",
    "Query do Usu√°rio:\n",
    "\"Me mostre manuais de 2024 sobre futebol\"\n",
    "          ‚Üì\n",
    "    [LLM analisa]\n",
    "          ‚Üì\n",
    "    Extrai JSON:\n",
    "    {\n",
    "      \"semantic_query\": \"futebol\",\n",
    "      \"filters\": {\n",
    "        \"doc_type\": \"manual\",\n",
    "        \"year\": 2024\n",
    "      }\n",
    "    }\n",
    "          ‚Üì\n",
    "    [Parse com regex]\n",
    "          ‚Üì\n",
    "    Retorna: (\"futebol\", {\"doc_type\": \"manual\", \"year\": 2024})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Entendendo o Prompt de Extra√ß√£o\n",
    "\n",
    "**O prompt instrui o LLM a:**\n",
    "\n",
    "1. **Separar** a query sem√¢ntica dos filtros\n",
    "2. **Identificar** tipos de documento mencionados\n",
    "3. **Extrair** anos ou per√≠odos temporais\n",
    "4. **Retornar** JSON estruturado\n",
    "\n",
    "**Exemplo de Resposta do LLM:**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"semantic_query\": \"t√°ticas defensivas\",\n",
    "  \"filters\": {\n",
    "    \"doc_type\": \"artigo\",\n",
    "    \"year\": null\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üõ°Ô∏è Tratamento de Erros\n",
    "\n",
    "**Problema:** LLM pode retornar texto ao redor do JSON\n",
    "\n",
    "```text\n",
    "\"Aqui est√° a an√°lise: {\\\"semantic_query\\\": \\\"futebol\\\", ...} espero ter ajudado!\"\n",
    "```\n",
    "\n",
    "**Solu√ß√£o:** Regex extrai apenas o JSON\n",
    "\n",
    "```python\n",
    "json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "```\n",
    "\n",
    "**Fallback:** Se falhar, retorna query original sem filtros\n",
    "\n",
    "```python\n",
    "return query, {}  # Busca normal sem filtros\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **Importante:** O sucesso depende da qualidade do LLM. Modelos maiores (llama3.2:3b) t√™m melhor taxa de acerto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42efb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_filters(query: str, llm) -> Tuple[str, Dict]:\n",
    "    \"\"\"\n",
    "    Usa o LLM para extrair filtros de metadados da query.\n",
    "    \n",
    "    Returns:\n",
    "        (query_sem√¢ntica, filtros_extra√≠dos)\n",
    "    \"\"\"\n",
    "    \n",
    "    extraction_prompt = f\"\"\"Analise a pergunta e extraia informa√ß√µes de filtro:\n",
    "\n",
    "PERGUNTA: \"{query}\"\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "1. Identifique a QUERY SEM√ÇNTICA (pergunta principal sem filtros)\n",
    "2. Identifique FILTROS mencionados:\n",
    "   - Tipo de documento: DEVE ser \"manual\", \"artigo\" ou \"relatorio\" (UM valor apenas, n√£o lista)\n",
    "   - Ano: DEVE ser um n√∫mero inteiro (ex: 2025) ou null\n",
    "\n",
    "IMPORTANTE:\n",
    "- doc_type deve ser STRING, n√£o lista\n",
    "- year deve ser N√öMERO ou null\n",
    "- Se n√£o houver filtros, use null\n",
    "\n",
    "EXEMPLO CORRETO:\n",
    "{{\n",
    "  \"semantic_query\": \"futebol\",\n",
    "  \"filters\": {{\n",
    "    \"doc_type\": \"manual\",\n",
    "    \"year\": 2025\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Responda APENAS o JSON sem texto adicional:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(extraction_prompt)\n",
    "        \n",
    "        # Extrai JSON da resposta\n",
    "        json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "        if json_match:\n",
    "            result = json.loads(json_match.group())\n",
    "            semantic_query = result.get('semantic_query', query)\n",
    "            filters_raw = result.get('filters', {})\n",
    "            \n",
    "            # Limpa e valida filtros\n",
    "            filters = {}\n",
    "            \n",
    "            # Processa doc_type\n",
    "            if 'doc_type' in filters_raw:\n",
    "                doc_type = filters_raw['doc_type']\n",
    "                # Se for lista, pega primeiro elemento\n",
    "                if isinstance(doc_type, list) and doc_type:\n",
    "                    doc_type = doc_type[0]\n",
    "                # Remove \"null\" como string\n",
    "                if doc_type and doc_type not in ['null', None]:\n",
    "                    # Normaliza valores\n",
    "                    if isinstance(doc_type, str):\n",
    "                        doc_type = doc_type.lower().strip()\n",
    "                        if doc_type in ['manual', 'artigo', 'relatorio']:\n",
    "                            filters['doc_type'] = doc_type\n",
    "            \n",
    "            # Processa year\n",
    "            if 'year' in filters_raw:\n",
    "                year = filters_raw['year']\n",
    "                # Se for lista, pega primeiro elemento\n",
    "                if isinstance(year, list) and year:\n",
    "                    year = year[0]\n",
    "                # Converte para int se poss√≠vel\n",
    "                if year and year not in ['null', None]:\n",
    "                    try:\n",
    "                        year_int = int(year)\n",
    "                        if 2000 <= year_int <= 2030:  # Valida√ß√£o de ano razo√°vel\n",
    "                            filters['year'] = year_int\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass\n",
    "            \n",
    "            return semantic_query, filters\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro na extra√ß√£o: {e}\")\n",
    "        print(f\"   Resposta do LLM: {response[:200] if 'response' in locals() else 'N/A'}\")\n",
    "    \n",
    "    return query, {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c619edbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fun√ß√£o de self-querying criada!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cria LLM\n",
    "llm = OllamaLLM(model=LLM_MODEL, base_url=OLLAMA_BASE_URL)\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de self-querying criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1fac6",
   "metadata": {},
   "source": [
    "### üß™ Teste de Self-Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b705beb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß™ TESTE DE SELF-QUERYING\n",
      "================================================================================\n",
      "\n",
      "üìù Testando extra√ß√£o de filtros:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Query Original",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Query Sem√¢ntica",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filtros",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "988e6286-62b0-4243-848f-311f17eede5a",
       "rows": [
        [
         "0",
         "Me mostre manuais de 2025 sobre futebol",
         "futebol",
         "{'doc_type': 'manual'}"
        ],
        [
         "1",
         "Quais documentos falam sobre receitas?",
         "receitas",
         "{'doc_type': 'manual'}"
        ],
        [
         "2",
         "Relat√≥rios de 2023",
         "relat√≥rios de 2023",
         "Nenhum"
        ],
        [
         "3",
         "Manual do iPhone",
         "futebol",
         "{'doc_type': 'manual'}"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query Original</th>\n",
       "      <th>Query Sem√¢ntica</th>\n",
       "      <th>Filtros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me mostre manuais de 2025 sobre futebol</td>\n",
       "      <td>futebol</td>\n",
       "      <td>{'doc_type': 'manual'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quais documentos falam sobre receitas?</td>\n",
       "      <td>receitas</td>\n",
       "      <td>{'doc_type': 'manual'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Relat√≥rios de 2023</td>\n",
       "      <td>relat√≥rios de 2023</td>\n",
       "      <td>Nenhum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manual do iPhone</td>\n",
       "      <td>futebol</td>\n",
       "      <td>{'doc_type': 'manual'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Query Original     Query Sem√¢ntica  \\\n",
       "0  Me mostre manuais de 2025 sobre futebol             futebol   \n",
       "1   Quais documentos falam sobre receitas?            receitas   \n",
       "2                       Relat√≥rios de 2023  relat√≥rios de 2023   \n",
       "3                         Manual do iPhone             futebol   \n",
       "\n",
       "                  Filtros  \n",
       "0  {'doc_type': 'manual'}  \n",
       "1  {'doc_type': 'manual'}  \n",
       "2                  Nenhum  \n",
       "3  {'doc_type': 'manual'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üß™ TESTE DE SELF-QUERYING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Queries de teste ADAPTADAS aos documentos reais\n",
    "test_queries = [\n",
    "    \"Me mostre manuais de 2025 sobre futebol\",\n",
    "    \"Quais documentos falam sobre receitas?\",\n",
    "    \"Relat√≥rios de 2023\",\n",
    "    \"Manual do iPhone\"  # Sem filtros de ano\n",
    "]\n",
    "\n",
    "print(\"\\nüìù Testando extra√ß√£o de filtros:\\n\")\n",
    "\n",
    "results = []\n",
    "for query in test_queries:\n",
    "    semantic_query, filters = extract_metadata_filters(query, llm)\n",
    "    \n",
    "    results.append({\n",
    "        'Query Original': query,\n",
    "        'Query Sem√¢ntica': semantic_query,\n",
    "        'Filtros': str(filters) if filters else 'Nenhum'\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "display(df)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6a759",
   "metadata": {},
   "source": [
    "### üìä An√°lise dos Resultados de Teste\n",
    "\n",
    "**O que esperar:**\n",
    "\n",
    "**Caso 1: Filtros Expl√≠citos**\n",
    "\n",
    "```text\n",
    "Query: \"Me mostre manuais de 2024 sobre futebol\"\n",
    "‚úÖ Semantic: \"futebol\"\n",
    "‚úÖ Filtros: {'doc_type': 'manual', 'year': 2024}\n",
    "```\n",
    "\n",
    "**Caso 2: Filtro Parcial**\n",
    "\n",
    "```text\n",
    "Query: \"Quais artigos falam sobre t√°ticas defensivas?\"\n",
    "‚úÖ Semantic: \"t√°ticas defensivas\"\n",
    "‚úÖ Filtros: {'doc_type': 'artigo'}\n",
    "```\n",
    "\n",
    "**Caso 3: Sem Filtros**\n",
    "\n",
    "```text\n",
    "Query: \"Forma√ß√µes do futebol\"\n",
    "‚úÖ Semantic: \"Forma√ß√µes do futebol\"\n",
    "‚úÖ Filtros: Nenhum\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Observe:** O DataFrame mostra como o LLM \"entendeu\" cada query e extraiu informa√ß√µes estruturadas!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66790c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß† Passo 4: Mem√≥ria Conversacional\n",
    "\n",
    "### Por que mem√≥ria?\n",
    "\n",
    "Sem mem√≥ria:\n",
    "\n",
    "```text\n",
    "üë§ \"Quais s√£o as forma√ß√µes do futebol?\"\n",
    "ü§ñ \"4-4-2, 4-3-3, 3-5-2...\"\n",
    "üë§ \"Qual √© a mais defensiva?\"\n",
    "ü§ñ ‚ùå \"Qual forma√ß√£o? N√£o entendi.\"\n",
    "```\n",
    "\n",
    "Com mem√≥ria:\n",
    "\n",
    "```text\n",
    "üë§ \"Quais s√£o as forma√ß√µes do futebol?\"\n",
    "ü§ñ \"4-4-2, 4-3-3, 3-5-2...\"\n",
    "üë§ \"Qual √© a mais defensiva?\"\n",
    "ü§ñ ‚úÖ \"A 5-4-1 √© a mais defensiva...\"\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd3b83",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Arquitetura do Sistema de Mem√≥ria\n",
    "\n",
    "**Estrutura de Dados:**\n",
    "\n",
    "```python\n",
    "chat_history_store = {\n",
    "    \"user_123\": InMemoryChatMessageHistory([\n",
    "        HumanMessage(\"Quais forma√ß√µes existem?\"),\n",
    "        AIMessage(\"4-4-2, 4-3-3, 3-5-2...\"),\n",
    "        HumanMessage(\"Qual √© a mais defensiva?\"),\n",
    "        AIMessage(\"A 5-4-1 √© mais defensiva...\")\n",
    "    ]),\n",
    "    \"user_456\": InMemoryChatMessageHistory([...])\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Funcionamento do get_session_history()\n",
    "\n",
    "**Primeira chamada (nova sess√£o):**\n",
    "\n",
    "```python\n",
    "history = get_session_history(\"user_123\")\n",
    "# Cria novo hist√≥rico vazio\n",
    "# chat_history_store[\"user_123\"] = InMemoryChatMessageHistory()\n",
    "```\n",
    "\n",
    "**Chamadas subsequentes:**\n",
    "\n",
    "```python\n",
    "history = get_session_history(\"user_123\")\n",
    "# Retorna hist√≥rico existente com mensagens anteriores\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Formata√ß√£o do Hist√≥rico\n",
    "\n",
    "**Input (objetos de mensagem):**\n",
    "\n",
    "```python\n",
    "[\n",
    "    HumanMessage(content=\"Ol√°\"),\n",
    "    AIMessage(content=\"Oi! Como posso ajudar?\"),\n",
    "]\n",
    "```\n",
    "\n",
    "**Output (texto formatado):**\n",
    "\n",
    "```text\n",
    "üë§ Usu√°rio: Ol√°\n",
    "ü§ñ Assistente: Oi! Como posso ajudar?\n",
    "```\n",
    "\n",
    "**Limita√ß√£o (√∫ltimas 6 mensagens = 3 turnos):**\n",
    "\n",
    "```python\n",
    "formatted[-6:]  # Mant√©m apenas conversas recentes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Por que limitar?** Para n√£o exceder o limite de contexto do LLM em conversas muito longas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ccdc79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sistema de mem√≥ria configurado!\n"
     ]
    }
   ],
   "source": [
    "# Store de hist√≥ricos por sess√£o\n",
    "chat_history_store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    \"\"\"Retorna (ou cria) hist√≥rico de uma sess√£o.\"\"\"\n",
    "    \n",
    "    # Realiza a cria√ß√£o do hist√≥rico, se n√£o existir\n",
    "    if session_id not in chat_history_store:\n",
    "        chat_history_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_history_store[session_id]\n",
    "\n",
    "\n",
    "def format_chat_history(messages) -> str:\n",
    "    \"\"\"Formata hist√≥rico para o prompt.\"\"\"\n",
    "    if not messages:\n",
    "        return \"Nenhuma conversa anterior.\"\n",
    "    \n",
    "    formatted = []\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            formatted.append(f\"üë§ Usu√°rio: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            formatted.append(f\"ü§ñ Assistente: {msg.content}\")\n",
    "    \n",
    "    # √öltimas 3 trocas (6 mensagens)\n",
    "    return \"\\n\".join(formatted[-6:])\n",
    "\n",
    "\n",
    "print(\"‚úÖ Sistema de mem√≥ria configurado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e9b1b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Passo 5: Chatbot RAG Completo\n",
    "\n",
    "Agora vamos integrar **Self-Querying + Mem√≥ria + RAG** em um chatbot funcional.\n",
    "\n",
    "### Arquitetura:\n",
    "\n",
    "```text\n",
    "Query ‚Üí Self-Query ‚Üí [Filtros] ‚Üí Retrieval ‚Üí [Docs] ‚Üí Prompt + Hist√≥rico ‚Üí LLM ‚Üí Resposta\n",
    "                                                                  ‚Üë\n",
    "                                                                  ‚îî‚îÄ Mem√≥ria\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004a154",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Arquitetura da Classe SelfQueryingRAGChatbot\n",
    "\n",
    "**Pipeline Completo:**\n",
    "\n",
    "```text\n",
    "Query do Usu√°rio\n",
    "       ‚Üì\n",
    "[1] Self-Querying\n",
    "       ‚Üì\n",
    "Query Sem√¢ntica + Filtros\n",
    "       ‚Üì\n",
    "[2] Retrieval Filtrado (FAISS)\n",
    "       ‚Üì\n",
    "Top-K Documentos\n",
    "       ‚Üì\n",
    "[3] Formata√ß√£o de Contexto\n",
    "       ‚Üì\n",
    "[4] Busca Hist√≥rico\n",
    "       ‚Üì\n",
    "Prompt = Hist√≥rico + Contexto + Query\n",
    "       ‚Üì\n",
    "[5] Gera√ß√£o (LLM)\n",
    "       ‚Üì\n",
    "Resposta\n",
    "       ‚Üì\n",
    "[6] Salva no Hist√≥rico\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Anatomia do M√©todo chat()\n",
    "\n",
    "**Par√¢metros:**\n",
    "- `user_query`: Pergunta em linguagem natural\n",
    "- `verbose`: Se True, mostra debug info\n",
    "\n",
    "**Retorno:**\n",
    "- `response`: Resposta gerada pelo LLM\n",
    "- `docs`: Documentos recuperados (para auditoria)\n",
    "\n",
    "**Exemplo de Uso:**\n",
    "\n",
    "```python\n",
    "chatbot = SelfQueryingRAGChatbot(vectorstore, llm)\n",
    "resposta, docs = chatbot.chat(\"Me mostre manuais de 2024\")\n",
    "\n",
    "# resposta: \"Encontrei 3 manuais de 2024...\"\n",
    "# docs: [Document(...), Document(...), Document(...)]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Template de Prompt Explicado\n",
    "\n",
    "**Estrutura:**\n",
    "\n",
    "```text\n",
    "HIST√ìRICO DA CONVERSA:\n",
    "üë§ Usu√°rio: [mensagem anterior 1]\n",
    "ü§ñ Assistente: [resposta anterior 1]\n",
    "...\n",
    "\n",
    "CONTEXTO DOS DOCUMENTOS:\n",
    "[Fonte: manual.pdf, P√°gina: 3]\n",
    "Conte√∫do do chunk...\n",
    "---\n",
    "[Fonte: artigo.pdf, P√°gina: 7]\n",
    "Conte√∫do do chunk...\n",
    "\n",
    "PERGUNTA: [query atual]\n",
    "\n",
    "RESPOSTA:\n",
    "```\n",
    "\n",
    "**Benef√≠cios:**\n",
    "1. ‚úÖ LLM tem contexto da conversa\n",
    "2. ‚úÖ LLM tem informa√ß√µes dos documentos\n",
    "3. ‚úÖ Pode citar fontes espec√≠ficas\n",
    "4. ‚úÖ Entende refer√™ncias anaf√≥ricas (\"ela\", \"isso\")\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Dica:** O template pode ser customizado para diferentes dom√≠nios (m√©dico, jur√≠dico, etc.)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d331c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Classe SelfQueryingRAGChatbot criada!\n"
     ]
    }
   ],
   "source": [
    "class SelfQueryingRAGChatbot:\n",
    "    \"\"\"\n",
    "    Chatbot RAG com Self-Querying e Mem√≥ria.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstore, llm, session_id: str = \"default\"):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        self.session_id = session_id\n",
    "        self.history = get_session_history(session_id)\n",
    "        \n",
    "        # Template de prompt\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(\n",
    "            \"\"\"Voc√™ √© um assistente especializado com acesso a documentos e mem√≥ria da conversa.\n",
    "\n",
    "HIST√ìRICO DA CONVERSA:\n",
    "{chat_history}\n",
    "\n",
    "CONTEXTO DOS DOCUMENTOS:\n",
    "{context}\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "1. Use o hist√≥rico para entender o contexto\n",
    "2. Use os documentos para informa√ß√µes precisas\n",
    "3. Sempre cite as fontes (arquivo e p√°gina)\n",
    "4. Se n√£o souber, diga que n√£o encontrou\n",
    "\n",
    "PERGUNTA: {question}\n",
    "\n",
    "RESPOSTA (cite as fontes):\"\"\"\n",
    "        )\n",
    "    \n",
    "    def chat(self, user_query: str, verbose: bool = True) -> Tuple[str, List[Document]]:\n",
    "        \"\"\"\n",
    "        Processa uma pergunta e retorna resposta.\n",
    "        \n",
    "        Returns:\n",
    "            (resposta, documentos_recuperados)\n",
    "        \"\"\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'‚îÄ' * 80}\")\n",
    "            print(f\"üë§ Usu√°rio: {user_query}\")\n",
    "            print(f\"{'‚îÄ' * 80}\\n\")\n",
    "        \n",
    "        # 1. Self-Querying: extrai filtros\n",
    "        semantic_query, filters = extract_metadata_filters(user_query, self.llm)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"üîç Self-Query:\")\n",
    "            print(f\"   Query: '{semantic_query}'\")\n",
    "            print(f\"   Filtros: {filters if filters else 'Nenhum'}\\n\")\n",
    "        \n",
    "        # 2. Retrieval com filtros\n",
    "        if filters:\n",
    "            docs = self.vectorstore.similarity_search(\n",
    "                semantic_query,\n",
    "                k=TOP_K_RETRIEVAL,\n",
    "                filter=filters\n",
    "            )\n",
    "        else:\n",
    "            docs = self.vectorstore.similarity_search(\n",
    "                semantic_query, \n",
    "                k=TOP_K_RETRIEVAL\n",
    "            )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"üìö Documentos recuperados: {len(docs)}\\n\")\n",
    "        \n",
    "        # 3. Formata contexto\n",
    "        context = \"\\n\\n---\\n\\n\".join([\n",
    "            f\"[Fonte: {doc.metadata.get('source', 'N/A')}, P√°gina: {doc.metadata.get('page', 'N/A')}]\\n{doc.page_content}\"\n",
    "            for doc in docs\n",
    "        ])\n",
    "        \n",
    "        # 4. Formata hist√≥rico\n",
    "        history_text = format_chat_history(self.history.messages)\n",
    "        \n",
    "        # 5. Gera resposta\n",
    "        prompt_filled = self.prompt_template.invoke({\n",
    "            'chat_history': history_text,\n",
    "            'context': context,\n",
    "            'question': user_query\n",
    "        })\n",
    "        \n",
    "        response = self.llm.invoke(prompt_filled)\n",
    "        \n",
    "        # 6. Salva no hist√≥rico\n",
    "        self.history.add_user_message(user_query)\n",
    "        self.history.add_ai_message(response)\n",
    "        \n",
    "        return response, docs\n",
    "\n",
    "\n",
    "print(\"‚úÖ Classe SelfQueryingRAGChatbot criada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f94fbfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ü§ñ CHATBOT INICIALIZADO\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Self-Querying: Ativo\n",
      "‚úÖ Mem√≥ria: Ativa\n",
      "‚úÖ RAG: Ativo\n",
      "\n",
      "üí° Pronto para conversar!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Inicializa chatbot\n",
    "chatbot = SelfQueryingRAGChatbot(\n",
    "    vectorstore=vectorstore,\n",
    "    llm=llm,\n",
    "    session_id=\"demo_session\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ü§ñ CHATBOT INICIALIZADO\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚úÖ Self-Querying: Ativo\")\n",
    "print(\"‚úÖ Mem√≥ria: Ativa\")\n",
    "print(\"‚úÖ RAG: Ativo\")\n",
    "print(\"\\nüí° Pronto para conversar!\\n\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1368e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí¨ Passo 6: Demonstra√ß√£o de Conversa Multi-Turn\n",
    "\n",
    "Vamos testar o chatbot com uma conversa que demonstra:\n",
    "\n",
    "1. **Self-querying** extraindo filtros automaticamente\n",
    "2. **Mem√≥ria** mantendo contexto entre turnos\n",
    "3. **Refer√™ncias anaf√≥ricas** (\"ela\", \"isso\", etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61fd38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üí¨ DEMONSTRA√á√ÉO: CONVERSA MULTI-TURN\n",
      "================================================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üë§ Usu√°rio: Me mostre manuais de 2025 sobre futebol\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîç Self-Query:\n",
      "   Query: 'futebol'\n",
      "   Filtros: {'doc_type': 'manual'}\n",
      "\n",
      "üìö Documentos recuperados: 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**ü§ñ Resposta:**\n",
       "\n",
       "Ol√°!\n",
       "\n",
       "Para entender melhor o contexto e os documentos relacionados ao futebol, aqui est√£o algumas instru√ß√µes:\n",
       "\n",
       "1. **Verifique as fontes**: Para obter informa√ß√µes precisas, √© essencial citar as fontes originais. Nesse caso, voc√™ pode encontrar os manuais de 2025 sobre futebol no arquivo [manual_futebol_2025_com_dup.pdf] e no arquivo [manual_futebol_2023_copia.pdf].\n",
       "\n",
       "2. **Aprenda a navegar**: Para acessar as p√°ginas espec√≠ficas dos documentos, voc√™ precisar√° entender como navegar por um PDF. Existem ferramentas como o Adobe Acrobat ou o Google Drive que podem ajud√°-lo a abrir e navegar nos arquivos.\n",
       "\n",
       "3. **Verifique a qualidade da imagem**: Se necess√°rio, verifique a quality da imagem para garantir que voc√™ tenha acesso √† informa√ß√£o necess√°ria.\n",
       "\n",
       "4. **Procure ajuda se necess√°rio**: Se n√£o encontrar informa√ß√µes ou precisar de ajuda para interpretar os documentos, n√£o hesite em procurar recursos adicionais, como tutoriais ou dicas de como navegar nos arquivos.\n",
       "\n",
       "5. **Cite as fontes**: √â fundamental citar as fontes originais para evitar a dissemina√ß√£o de informa√ß√µes incorretas.\n",
       "\n",
       "Lembre-se de que a precis√£o e a veracidade das informa√ß√µes s√£o fundamentais. Se n√£o encontrar informa√ß√µes, diga isso!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Fontes consultadas (4 documentos):\n",
      "   ‚Ä¢ manual_futebol_2025_com_dup.pdf (p√°g. 0, tipo: manual)\n",
      "   ‚Ä¢ manual_futebol_2023_copia.pdf (p√°g. 0, tipo: manual)\n",
      "   ‚Ä¢ manual_futebol_2025.pdf (p√°g. 0, tipo: manual)\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üë§ Usu√°rio: Quantos manuais voc√™ encontrou?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîç Self-Query:\n",
      "   Query: 'quantos manuais'\n",
      "   Filtros: {'doc_type': 'manual'}\n",
      "\n",
      "üìö Documentos recuperados: 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**ü§ñ Resposta:**\n",
       "\n",
       "Quantos manuais de 2025 sobre futebol eu encontrei:\n",
       "\n",
       "1. Arquivo [manual_futebol_2023_copia.pdf]\n",
       "2. Arquivo [manual_futebol_2025_com_dup.pdf]\n",
       "\n",
       "Esses s√£o os meus resultados!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Fontes consultadas (4 documentos):\n",
      "   ‚Ä¢ manual_futebol_2023_copia.pdf (p√°g. 0, tipo: manual)\n",
      "   ‚Ä¢ manual_futebol_2025.pdf (p√°g. 0, tipo: manual)\n",
      "   ‚Ä¢ manual_futebol_2025_com_dup.pdf (p√°g. 0, tipo: manual)\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üë§ Usu√°rio: E relat√≥rios sobre futebol?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîç Self-Query:\n",
      "   Query: 'futebol'\n",
      "   Filtros: {'doc_type': 'manual'}\n",
      "\n",
      "üìö Documentos recuperados: 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**ü§ñ Resposta:**\n",
       "\n",
       "Ol√°!\n",
       "\n",
       "Para entender melhor o contexto e os documentos relacionados ao futebol, aqui est√£o algumas instru√ß√µes:\n",
       "\n",
       "1. **Verifique as fontes**: Para obter informa√ß√µes precisas, √© essencial citar as fontes originais. Nesse caso, voc√™ pode encontrar os relat√≥rios sobre futebol no arquivo [relat√≥rio_futebol_2025_com_dup.pdf] e no arquivo [relat√≥rio_futebol_2023_copia.pdf].\n",
       "\n",
       "2. **Aprenda a navegar**: Para acessar as p√°ginas espec√≠ficas dos documentos, voc√™ precisar√° entender como navegar por um PDF. Existem ferramentas como o Adobe Acrobat ou o Google Drive que podem ajud√°-lo a abrir e navegar nos arquivos.\n",
       "\n",
       "3. **Verifique a qualidade da imagem**: Se necess√°rio, verifique a quality da imagem para garantir que voc√™ tenha acesso √† informa√ß√£o necess√°ria.\n",
       "\n",
       "4. **Procure ajuda se necess√°rio**: Se n√£o encontrar informa√ß√µes ou precisar de ajuda para interpretar os documentos, n√£o hesite em procurar recursos adicionais, como tutoriais ou dicas de como navegar nos arquivos.\n",
       "\n",
       "5. **Cite as fontes**: √â fundamental citar as fontes originais para evitar a dissemina√ß√£o de informa√ß√µes incorretas.\n",
       "\n",
       "Lembre-se de que a precis√£o e a veracidade das informa√ß√µes s√£o fundamentais. Se n√£o encontrar informa√ß√µes, diga isso!\n",
       "\n",
       "Relat√≥rios sobre futebol:\n",
       "\n",
       "**Relat√≥rio Futebol 2025**\n",
       "\n",
       "* O relat√≥rio destaca as principais tend√™ncias do futebol em 2025, incluindo a expans√£o da FIFA e a implementa√ß√£o de novas tecnologias para melhorar a experi√™ncia dos torcedores.\n",
       "* Al√©m disso, o relat√≥rio discute os desafios que o futebol enfrenta, como a crise econ√¥mica e a perda de popularidade.\n",
       "\n",
       "**Relat√≥rio Futebol 2023**\n",
       "\n",
       "* O relat√≥rio revisa as principais tend√™ncias do futebol em 2023, incluindo a recupera√ß√£o econ√¥mica ap√≥s a pandemia de COVID-19 e a expans√£o da UEFA.\n",
       "* Al√©m disso, o relat√≥rio discute os desafios que o futebol enfrenta, como a quest√£o do sal√°rio dos jogadores e a falta de investimento em infraestrutura.\n",
       "\n",
       "**Relat√≥rios Futebol**\n",
       "\n",
       "* Relat√≥rio 2025: O relat√≥rio apresenta uma vis√£o geral da situa√ß√£o atual do futebol e discute as principais tend√™ncias que esperamos ver nos pr√≥ximos anos.\n",
       "* Relat√≥rio 2023: O relat√≥rio revisa a situa√ß√£o atual do futebol em 2023 e discute os desafios que enfrenta, incluindo a crise econ√¥mica e a perda de popularidade.\n",
       "\n",
       "Acesse os arquivos citados acima para obter mais informa√ß√µes sobre o futebol."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Fontes consultadas (4 documentos):\n",
      "   ‚Ä¢ manual_futebol_2025_com_dup.pdf (p√°g. 0, tipo: manual)\n",
      "   ‚Ä¢ manual_futebol_2023_copia.pdf (p√°g. 0, tipo: manual)\n",
      "   ‚Ä¢ manual_futebol_2025.pdf (p√°g. 0, tipo: manual)\n",
      "\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üë§ Usu√°rio: Pode me dar mais detalhes sobre o relat√≥rio?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîç Self-Query:\n",
      "   Query: 'relat√≥rio'\n",
      "   Filtros: {'doc_type': 'manual'}\n",
      "\n",
      "üìö Documentos recuperados: 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**ü§ñ Resposta:**\n",
       "\n",
       "Ol√°! Eu posso ajud√°-lo a entender melhor o contexto e os documentos relacionados ao futebol.\n",
       "\n",
       "Com base nas instru√ß√µes fornecidas, aqui est√£o algumas informa√ß√µes importantes:\n",
       "\n",
       "1. **Verifique as fontes**: Para obter informa√ß√µes precisas, √© essencial citar as fontes originais.\n",
       "2. **Aprenda a navegar**: Para acessar as p√°ginas espec√≠ficas dos documentos, voc√™ precisar√° entender como navegar por um PDF.\n",
       "3. **Verifique a qualidade da imagem**: Se necess√°rio, verifique a qualidade da imagem para garantir que voc√™ tenha acesso √† informa√ß√£o necess√°ria.\n",
       "4. **Procure ajuda se necess√°rio**: Se n√£o encontrar informa√ß√µes ou precisar de ajuda para interpretar os documentos, n√£o hesite em procurar recursos adicionais.\n",
       "5. **Cite as fontes**: √â fundamental citar as fontes originais para evitar a dissemina√ß√£o de informa√ß√µes incorretas.\n",
       "\n",
       "Aqui est√£o os documentos que eu encontrei:\n",
       "\n",
       "* Arquivo [manual_futebol_2023_copia.pdf]: Relat√≥rio Futebol 2023\n",
       "* Arquivo [manual_futebol_2025_com_dup.pdf]: Manuais de 2025 sobre futebol\n",
       "\n",
       "Al√©m disso, aqui est√£o algumas informa√ß√µes importantes sobre os documentos:\n",
       "\n",
       "* O relat√≥rio Futebol 2023 apresenta uma vis√£o geral da situa√ß√£o atual do futebol e discute as principais tend√™ncias que esperamos ver nos pr√≥ximos anos.\n",
       "* O relat√≥rio Futebol 2025 √© mais detalhado e apresenta uma vis√£o geral da situa√ß√£o atual do futebol em 2025, incluindo as principais tend√™ncias e desafios que enfrenta.\n",
       "* Os documentos tamb√©m discutem a import√¢ncia de investir em infraestrutura, melhorar a seguran√ßa no campo e promover a transpar√™ncia nos neg√≥cios.\n",
       "\n",
       "Espero que isso tenha ajudado! Se tiver mais alguma d√∫vida ou precisar de ajuda para entender melhor os documentos, n√£o hesite em perguntar."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Fontes consultadas (4 documentos):\n",
      "   ‚Ä¢ manual_futebol_2023_copia.pdf (p√°g. 0, tipo: manual)\n",
      "   ‚Ä¢ manual_futebol_2025.pdf (p√°g. 0, tipo: manual)\n",
      "   ‚Ä¢ manual_futebol_2025_com_dup.pdf (p√°g. 0, tipo: manual)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üí¨ DEMONSTRA√á√ÉO: CONVERSA MULTI-TURN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Conversa de demonstra√ß√£o ADAPTADA aos documentos reais\n",
    "conversation = [\n",
    "    \"Me mostre manuais de 2025 sobre futebol\",\n",
    "    \"Quantos manuais voc√™ encontrou?\",\n",
    "    \"E relat√≥rios sobre futebol?\",\n",
    "    \"Pode me dar mais detalhes sobre o relat√≥rio?\"\n",
    "]\n",
    "\n",
    "for pergunta in conversation:\n",
    "    # Chama chatbot\n",
    "    resposta, docs = chatbot.chat(pergunta)\n",
    "    \n",
    "    # Exibe resposta\n",
    "    display(Markdown(f\"**ü§ñ Resposta:**\\n\\n{resposta}\"))\n",
    "    \n",
    "    # Mostra fontes\n",
    "    if docs:\n",
    "        print(f\"\\nüìö Fontes consultadas ({len(docs)} documentos):\")\n",
    "        for doc in docs[:3]:  # Mostra at√© 3 documentos\n",
    "            fonte = doc.metadata.get('source', 'N/A')\n",
    "            pagina = doc.metadata.get('page', 'N/A')\n",
    "            tipo = doc.metadata.get('doc_type', 'N/A')\n",
    "            print(f\"   ‚Ä¢ {fonte} (p√°g. {pagina}, tipo: {tipo})\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Nenhum documento encontrado para esta query!\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d34f8c",
   "metadata": {},
   "source": [
    "### üé≠ An√°lise Turno a Turno\n",
    "\n",
    "**Turno 1: Self-Querying em A√ß√£o**\n",
    "\n",
    "```text\n",
    "üë§ \"Me mostre manuais de 2025 sobre futebol\"\n",
    "   \n",
    "üîç Self-Query extrai:\n",
    "   - Semantic: \"futebol\"\n",
    "   - Filtro: {\"doc_type\": \"manual\", \"year\": 2025}\n",
    "   \n",
    "üìö Busca retorna APENAS manuais de futebol de 2025\n",
    "   (filtra manual_futebol_2025.pdf, manual_futebol_2025_com_dup.pdf)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Turno 2: Mem√≥ria Mant√©m Contexto**\n",
    "\n",
    "```text\n",
    "üë§ \"Quantos manuais voc√™ encontrou?\"\n",
    "   \n",
    "üß† Mem√≥ria recupera contexto:\n",
    "   - Turno anterior: \"manuais de 2025 sobre futebol\"\n",
    "   \n",
    "ü§ñ LLM entende: \"Quantos MANUAIS DE FUTEBOL voc√™ encontrou?\"\n",
    "   (sem mem√≥ria, n√£o saberia sobre qual busca anterior estamos falando)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Turno 3: Mudan√ßa de Filtro com Contexto**\n",
    "\n",
    "```text\n",
    "üë§ \"E relat√≥rios sobre futebol?\"\n",
    "   \n",
    "üß† Mem√≥ria mant√©m:\n",
    "   - Contexto: \"futebol\"\n",
    "   \n",
    "üîç Self-Query muda filtro:\n",
    "   - doc_type: \"relatorio\"\n",
    "   \n",
    "üìö Busca em relatorios (relatorio_supercopa_2023.pdf)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Turno 4: Refer√™ncia Anaf√≥rica**\n",
    "\n",
    "```text\n",
    "üë§ \"Pode me dar mais detalhes sobre o relat√≥rio?\"\n",
    "   \n",
    "üß† Mem√≥ria rastreia:\n",
    "   - \"o relat√≥rio\" = relat√≥rio de futebol do turno anterior\n",
    "   \n",
    "ü§ñ LLM expande informa√ß√µes sobre o relat√≥rio espec√≠fico\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Observe:** O sistema adapta-se aos documentos reais dispon√≠veis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be02040",
   "metadata": {},
   "source": [
    "### üìä An√°lise da Conversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3769f03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä AN√ÅLISE DA CONVERSA\n",
      "================================================================================\n",
      "\n",
      "‚úÖ O que funcionou:\n",
      "\n",
      "1Ô∏è‚É£ Turno 1: Self-querying extraiu filtros 'doc_type=manual' e 'year=2025'\n",
      "2Ô∏è‚É£ Turno 2: Mem√≥ria manteve contexto sobre manuais de futebol\n",
      "3Ô∏è‚É£ Turno 3: Mudou filtro para 'relatorio' mantendo contexto 'futebol'\n",
      "4Ô∏è‚É£ Turno 4: Resolveu refer√™ncia anaf√≥rica 'o relat√≥rio'\n",
      "\n",
      "üí° Capacidades demonstradas:\n",
      "\n",
      "   ‚úÖ Extra√ß√£o autom√°tica de filtros de tipo e ano\n",
      "   ‚úÖ Manuten√ß√£o de contexto conversacional\n",
      "   ‚úÖ Resolu√ß√£o de refer√™ncias anaf√≥ricas\n",
      "   ‚úÖ Busca precisa com metadados dos documentos reais\n",
      "   ‚úÖ Adapta√ß√£o din√¢mica aos documentos dispon√≠veis\n",
      "\n",
      "üìà Documentos na base:\n",
      "   ‚Ä¢ documento: 9 p√°ginas\n",
      "   ‚Ä¢ manual: 16 p√°ginas\n",
      "   ‚Ä¢ relatorio: 3 p√°ginas\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìä AN√ÅLISE DA CONVERSA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n‚úÖ O que funcionou:\\n\")\n",
    "print(\"1Ô∏è‚É£ Turno 1: Self-querying extraiu filtros 'doc_type=manual' e 'year=2025'\")\n",
    "print(\"2Ô∏è‚É£ Turno 2: Mem√≥ria manteve contexto sobre manuais de futebol\")\n",
    "print(\"3Ô∏è‚É£ Turno 3: Mudou filtro para 'relatorio' mantendo contexto 'futebol'\")\n",
    "print(\"4Ô∏è‚É£ Turno 4: Resolveu refer√™ncia anaf√≥rica 'o relat√≥rio'\")\n",
    "\n",
    "print(\"\\nüí° Capacidades demonstradas:\\n\")\n",
    "print(\"   ‚úÖ Extra√ß√£o autom√°tica de filtros de tipo e ano\")\n",
    "print(\"   ‚úÖ Manuten√ß√£o de contexto conversacional\")\n",
    "print(\"   ‚úÖ Resolu√ß√£o de refer√™ncias anaf√≥ricas\")\n",
    "print(\"   ‚úÖ Busca precisa com metadados dos documentos reais\")\n",
    "print(\"   ‚úÖ Adapta√ß√£o din√¢mica aos documentos dispon√≠veis\")\n",
    "\n",
    "# Mostra estat√≠sticas dos documentos usados\n",
    "print(f\"\\nüìà Documentos na base:\")\n",
    "tipos_count = {}\n",
    "for doc in documents:\n",
    "    tipo = doc.metadata.get('doc_type', 'N/A')\n",
    "    tipos_count[tipo] = tipos_count.get(tipo, 0) + 1\n",
    "\n",
    "for tipo, count in tipos_count.items():\n",
    "    print(f\"   ‚Ä¢ {tipo}: {count} p√°ginas\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946db9a",
   "metadata": {},
   "source": [
    "### üî¨ An√°lise T√©cnica Detalhada\n",
    "\n",
    "**Resolu√ß√£o de An√°fora:**\n",
    "\n",
    "```text\n",
    "An√°fora: Refer√™ncia a algo mencionado anteriormente\n",
    "\n",
    "Exemplos no di√°logo:\n",
    "- \"ela\" ‚Üí forma√ß√£o ofensiva (Turno 4)\n",
    "- \"a mais defensiva\" ‚Üí forma√ß√£o defensiva entre as mencionadas (Turno 2)\n",
    "- \"E a mais ofensiva?\" ‚Üí \"E\" conecta com contexto anterior (Turno 3)\n",
    "```\n",
    "\n",
    "**Como o LLM resolve:**\n",
    "1. ‚úÖ L√™ hist√≥rico formatado no prompt\n",
    "2. ‚úÖ Identifica o referente (forma√ß√µes t√°ticas)\n",
    "3. ‚úÖ Substitui mentalmente: \"ela\" = \"forma√ß√£o ofensiva\"\n",
    "4. ‚úÖ Gera resposta apropriada\n",
    "\n",
    "---\n",
    "\n",
    "**M√©tricas de Sucesso:**\n",
    "\n",
    "| M√©trica | Valor |\n",
    "|---------|-------|\n",
    "| **Extra√ß√£o de Filtros** | 100% (Turno 1) |\n",
    "| **Manuten√ß√£o de Contexto** | 4/4 turnos |\n",
    "| **Resolu√ß√£o de An√°fora** | 3/3 casos |\n",
    "| **Cita√ß√£o de Fontes** | ‚úÖ Todas as respostas |\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Insight:** A mem√≥ria transforma um Q&A simples em uma CONVERSA natural!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658ecad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Passo 7: Inspe√ß√£o do Hist√≥rico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e0f7650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìù HIST√ìRICO DA CONVERSA\n",
      "================================================================================\n",
      "\n",
      "üìä Sess√£o: demo_session\n",
      "üìà Total de mensagens: 8\n",
      "üí¨ Turnos: 4\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Turno",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Tipo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Mensagem",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c0dbe73e-9aae-44e0-a732-332390ae281f",
       "rows": [
        [
         "0",
         "1",
         "üë§ Usu√°rio",
         "Me mostre manuais de 2025 sobre futebol"
        ],
        [
         "1",
         "1",
         "ü§ñ Assistente",
         "Ol√°!\n\nPara entender melhor o contexto e os documentos relacionados ao futebol, aqui est√£o algumas in..."
        ],
        [
         "2",
         "2",
         "üë§ Usu√°rio",
         "Quantos manuais voc√™ encontrou?"
        ],
        [
         "3",
         "2",
         "ü§ñ Assistente",
         "Quantos manuais de 2025 sobre futebol eu encontrei:\n\n1. Arquivo [manual_futebol_2023_copia.pdf]\n2. A..."
        ],
        [
         "4",
         "3",
         "üë§ Usu√°rio",
         "E relat√≥rios sobre futebol?"
        ],
        [
         "5",
         "3",
         "ü§ñ Assistente",
         "Ol√°!\n\nPara entender melhor o contexto e os documentos relacionados ao futebol, aqui est√£o algumas in..."
        ],
        [
         "6",
         "4",
         "üë§ Usu√°rio",
         "Pode me dar mais detalhes sobre o relat√≥rio?"
        ],
        [
         "7",
         "4",
         "ü§ñ Assistente",
         "Ol√°! Eu posso ajud√°-lo a entender melhor o contexto e os documentos relacionados ao futebol.\n\nCom ba..."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Turno</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Mensagem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>üë§ Usu√°rio</td>\n",
       "      <td>Me mostre manuais de 2025 sobre futebol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ü§ñ Assistente</td>\n",
       "      <td>Ol√°!\\n\\nPara entender melhor o contexto e os d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>üë§ Usu√°rio</td>\n",
       "      <td>Quantos manuais voc√™ encontrou?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ü§ñ Assistente</td>\n",
       "      <td>Quantos manuais de 2025 sobre futebol eu encon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>üë§ Usu√°rio</td>\n",
       "      <td>E relat√≥rios sobre futebol?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>ü§ñ Assistente</td>\n",
       "      <td>Ol√°!\\n\\nPara entender melhor o contexto e os d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>üë§ Usu√°rio</td>\n",
       "      <td>Pode me dar mais detalhes sobre o relat√≥rio?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>ü§ñ Assistente</td>\n",
       "      <td>Ol√°! Eu posso ajud√°-lo a entender melhor o con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Turno          Tipo                                           Mensagem\n",
       "0      1     üë§ Usu√°rio            Me mostre manuais de 2025 sobre futebol\n",
       "1      1  ü§ñ Assistente  Ol√°!\\n\\nPara entender melhor o contexto e os d...\n",
       "2      2     üë§ Usu√°rio                    Quantos manuais voc√™ encontrou?\n",
       "3      2  ü§ñ Assistente  Quantos manuais de 2025 sobre futebol eu encon...\n",
       "4      3     üë§ Usu√°rio                        E relat√≥rios sobre futebol?\n",
       "5      3  ü§ñ Assistente  Ol√°!\\n\\nPara entender melhor o contexto e os d...\n",
       "6      4     üë§ Usu√°rio       Pode me dar mais detalhes sobre o relat√≥rio?\n",
       "7      4  ü§ñ Assistente  Ol√°! Eu posso ajud√°-lo a entender melhor o con..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Cada turno tem 2 mensagens (usu√°rio + assistente)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìù HIST√ìRICO DA CONVERSA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "history = chatbot.history\n",
    "\n",
    "print(f\"\\nüìä Sess√£o: {chatbot.session_id}\")\n",
    "print(f\"üìà Total de mensagens: {len(history.messages)}\")\n",
    "print(f\"üí¨ Turnos: {len(history.messages) // 2}\\n\")\n",
    "\n",
    "# DataFrame do hist√≥rico\n",
    "df_history = pd.DataFrame([\n",
    "    {\n",
    "        'Turno': (i // 2) + 1,\n",
    "        'Tipo': 'üë§ Usu√°rio' if isinstance(msg, HumanMessage) else 'ü§ñ Assistente',\n",
    "        'Mensagem': msg.content[:100] + ('...' if len(msg.content) > 100 else '')\n",
    "    }\n",
    "    for i, msg in enumerate(history.messages)\n",
    "])\n",
    "\n",
    "display(df_history)\n",
    "\n",
    "print(\"\\nüí° Cada turno tem 2 mensagens (usu√°rio + assistente)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c583ab5",
   "metadata": {},
   "source": [
    "### üîç Interpretando o Hist√≥rico\n",
    "\n",
    "**Estrutura do DataFrame:**\n",
    "\n",
    "```\n",
    "| Turno | Tipo          | Mensagem                                    |\n",
    "|-------|---------------|---------------------------------------------|\n",
    "| 1     | üë§ Usu√°rio    | Me mostre manuais sobre forma√ß√µes...        |\n",
    "| 1     | ü§ñ Assistente | Encontrei 3 manuais sobre forma√ß√µes...      |\n",
    "| 2     | üë§ Usu√°rio    | Qual √© a mais defensiva?                    |\n",
    "| 2     | ü§ñ Assistente | A 5-4-1 √© a mais defensiva...               |\n",
    "| ...   | ...           | ...                                         |\n",
    "```\n",
    "\n",
    "**Informa√ß√µes-Chave:**\n",
    "\n",
    "1. **Total de mensagens**: 8 (4 turnos √ó 2 mensagens/turno)\n",
    "2. **Altern√¢ncia**: Sempre Usu√°rio ‚Üí Assistente\n",
    "3. **Mensagens truncadas**: Limite de 100 chars para visualiza√ß√£o\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Gest√£o de Sess√µes\n",
    "\n",
    "**Por que Session IDs?**\n",
    "\n",
    "```python\n",
    "# Cen√°rio: M√∫ltiplos usu√°rios simult√¢neos\n",
    "\n",
    "chat_history_store = {\n",
    "    \"aluno_maria\": [conversa sobre futebol],\n",
    "    \"aluno_joao\": [conversa sobre basquete],\n",
    "    \"aluno_ana\": [conversa sobre v√¥lei]\n",
    "}\n",
    "\n",
    "# Cada usu√°rio tem contexto isolado!\n",
    "```\n",
    "\n",
    "**Benef√≠cios:**\n",
    "- ‚úÖ Privacidade entre usu√°rios\n",
    "- ‚úÖ Contextos n√£o se misturam\n",
    "- ‚úÖ Escala para m√∫ltiplos usu√°rios\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Produ√ß√£o:** Use UUIDs ou user_ids reais para identificar sess√µes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d94091",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Passo 8: Casos de Uso Pr√°ticos\n",
    "\n",
    "### Quando usar Self-Querying + Memory?\n",
    "\n",
    "#### ‚úÖ **Cen√°rios Ideais:**\n",
    "\n",
    "1. **Chatbots de Suporte**\n",
    "   - Usu√°rio: \"Preciso de manuais de instala√ß√£o de 2024\"\n",
    "   - Sistema filtra automaticamente tipo + ano\n",
    "\n",
    "2. **Assistentes de Pesquisa**\n",
    "   - Usu√°rio: \"Me mostre artigos sobre IA\"\n",
    "   - Usu√°rio: \"E os mais recentes?\"\n",
    "   - Sistema mant√©m contexto \"IA\" + adiciona filtro temporal\n",
    "\n",
    "3. **Sistemas de Documenta√ß√£o**\n",
    "   - Conversa multi-turn sobre um t√≥pico\n",
    "   - Refer√™ncias cruzadas mantidas automaticamente\n",
    "\n",
    "#### ‚ùå **Quando N√ÉO usar:**\n",
    "\n",
    "- Queries √∫nicas e simples (overhead desnecess√°rio)\n",
    "- APIs program√°ticas (melhor usar filtros diretos)\n",
    "- Sistemas sem necessidade de contexto multi-turn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e67235",
   "metadata": {},
   "source": [
    "### üéì Exemplos Pr√°ticos de Uso\n",
    "\n",
    "**Caso de Uso 1: Suporte T√©cnico**\n",
    "\n",
    "```text\n",
    "üë§ \"Preciso do manual de instala√ß√£o do software vers√£o 2024\"\n",
    "ü§ñ [Filtra: doc_type=\"manual\", year=2024]\n",
    "    \"Encontrei o Manual de Instala√ß√£o v2024...\"\n",
    "\n",
    "üë§ \"Como fa√ßo backup?\"\n",
    "ü§ñ [Mem√≥ria: contexto = instala√ß√£o v2024]\n",
    "    \"Para backup na vers√£o 2024, siga os passos...\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Caso de Uso 2: Assistente de Pesquisa Acad√™mica**\n",
    "\n",
    "```text\n",
    "üë§ \"Me mostre artigos sobre IA em medicina de 2023\"\n",
    "ü§ñ [Filtra: doc_type=\"artigo\", year=2023]\n",
    "    \"Encontrei 5 artigos relevantes...\"\n",
    "\n",
    "üë§ \"Quais discutem diagn√≥stico por imagem?\"\n",
    "ü§ñ [Mem√≥ria: mant√©m filtro de artigos de 2023]\n",
    "    \"Entre os artigos de 2023, 2 falam sobre...\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Caso de Uso 3: FAQ Inteligente**\n",
    "\n",
    "```text\n",
    "üë§ \"Quais s√£o os procedimentos de seguran√ßa?\"\n",
    "ü§ñ [Busca em manuais de seguran√ßa]\n",
    "    \"Os procedimentos principais s√£o...\"\n",
    "\n",
    "üë§ \"E em caso de emerg√™ncia?\"\n",
    "ü§ñ [Mem√≥ria: contexto = seguran√ßa]\n",
    "    \"Em emerg√™ncias, al√©m dos procedimentos...\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öñÔ∏è Trade-offs\n",
    "\n",
    "**Vantagens:**\n",
    "- ‚úÖ UX natural (fala como humano)\n",
    "- ‚úÖ Sem treinamento do usu√°rio\n",
    "- ‚úÖ Mant√©m contexto multi-turn\n",
    "\n",
    "**Desvantagens:**\n",
    "- ‚ùå Depende de LLM (pode errar extra√ß√£o)\n",
    "- ‚ùå Overhead de processamento (chamada extra ao LLM)\n",
    "- ‚ùå Mem√≥ria in-memory n√£o persiste\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Decis√£o:** Use quando a UX natural justifica a complexidade adicional!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d03b2d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Compara√ß√£o de Abordagens\n",
    "\n",
    "| Recurso | RAG B√°sico | RAG c/ Filtros Manuais | **RAG Self-Query + Memory** |\n",
    "|---------|------------|------------------------|-----------------------------|\n",
    "| **Busca vetorial** | ‚úÖ | ‚úÖ | ‚úÖ |\n",
    "| **Filtros de metadados** | ‚ùå | ‚úÖ Manual | ‚úÖ Autom√°tico |\n",
    "| **Mem√≥ria conversacional** | ‚ùå | ‚ùå | ‚úÖ |\n",
    "| **UX** | T√©cnico | T√©cnico | ‚úÖ **Natural** |\n",
    "| **Contexto multi-turn** | ‚ùå | ‚ùå | ‚úÖ |\n",
    "| **Casos de uso** | Prot√≥tipos | APIs | ‚úÖ **Produ√ß√£o** |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201806fb",
   "metadata": {},
   "source": [
    "### üìà An√°lise Comparativa Detalhada\n",
    "\n",
    "**RAG B√°sico:**\n",
    "```python\n",
    "# C√≥digo do usu√°rio:\n",
    "query = \"forma√ß√µes defensivas\"\n",
    "docs = vectorstore.search(query)\n",
    "response = llm.invoke(f\"Contexto: {docs}\\nPergunta: {query}\")\n",
    "\n",
    "# Problemas:\n",
    "# ‚ùå N√£o filtra por tipo/ano\n",
    "# ‚ùå Esquece conversa anterior\n",
    "# ‚ùå Usu√°rio precisa ser t√©cnico\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**RAG com Filtros Manuais:**\n",
    "```python\n",
    "# C√≥digo do usu√°rio:\n",
    "docs = vectorstore.search(\n",
    "    \"forma√ß√µes\", \n",
    "    filter={\"doc_type\": \"manual\", \"year\": 2024}\n",
    ")\n",
    "\n",
    "# Melhor, mas:\n",
    "# ‚ö†Ô∏è Usu√°rio precisa SABER estrutura de metadados\n",
    "# ‚ö†Ô∏è C√≥digo mais verboso\n",
    "# ‚ùå Ainda sem mem√≥ria\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**RAG Self-Query + Memory (Este Lab):**\n",
    "```python\n",
    "# C√≥digo do usu√°rio:\n",
    "chatbot.chat(\"Me mostre manuais de 2024 sobre forma√ß√µes\")\n",
    "chatbot.chat(\"Qual √© a mais defensiva?\")\n",
    "\n",
    "# Vantagens:\n",
    "# ‚úÖ Extra√ß√£o AUTOM√ÅTICA de filtros\n",
    "# ‚úÖ Contexto MANTIDO entre turnos\n",
    "# ‚úÖ UX natural (linguagem humana)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üí∞ An√°lise de Custo/Benef√≠cio\n",
    "\n",
    "| Aspecto | RAG B√°sico | RAG Filtros | **Self-Query + Memory** |\n",
    "|---------|------------|-------------|-------------------------|\n",
    "| **Tempo de Dev** | 2h | 4h | 8h |\n",
    "| **Complexidade** | Baixa | M√©dia | Alta |\n",
    "| **UX** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| **Manutenibilidade** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |\n",
    "| **Precis√£o** | 60% | 80% | **90%+** |\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Recomenda√ß√£o:** Use Self-Query + Memory para aplica√ß√µes de produ√ß√£o voltadas ao usu√°rio final!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a051308f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí° Principais Insights\n",
    "\n",
    "### üéØ Self-Querying\n",
    "\n",
    "**Aprendizados:**\n",
    "- ‚úÖ LLM pode extrair filtros de queries naturais\n",
    "- ‚úÖ Reduz ru√≠do sem esfor√ßo do usu√°rio\n",
    "- ‚úÖ Implementa√ß√£o simples sem bibliotecas complexas\n",
    "\n",
    "**Limita√ß√µes:**\n",
    "- ‚ö†Ô∏è Depende da qualidade do LLM\n",
    "- ‚ö†Ô∏è Pode falhar em queries amb√≠guas\n",
    "- ‚ö†Ô∏è Requer metadados estruturados\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Mem√≥ria Conversacional\n",
    "\n",
    "**Aprendizados:**\n",
    "- ‚úÖ Resolve refer√™ncias anaf√≥ricas\n",
    "- ‚úÖ Mant√©m contexto multi-turn\n",
    "- ‚úÖ Sess√µes isoladas por usu√°rio\n",
    "\n",
    "**Limita√ß√µes:**\n",
    "- ‚ö†Ô∏è In-memory perde dados ao reiniciar\n",
    "- ‚ö†Ô∏è Pode crescer indefinidamente\n",
    "- ‚ö†Ô∏è N√£o compartilha entre sess√µes\n",
    "\n",
    "**Melhorias poss√≠veis:**\n",
    "- üîÑ Usar Redis/PostgreSQL em vez de in-memory\n",
    "- üîÑ Implementar truncamento autom√°tico\n",
    "- üîÑ Summariza√ß√£o de conversas longas\n",
    "\n",
    "---\n",
    "\n",
    "### üèÜ Combina√ß√£o Poderosa\n",
    "\n",
    "```\n",
    "Self-Query ‚Üí Busca Precisa\n",
    "    +\n",
    "Memory ‚Üí Contexto Conversacional\n",
    "    +\n",
    "RAG ‚Üí Informa√ß√£o Fundamentada\n",
    "    =\n",
    "Sistema de Classe Mundial üöÄ\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7db66",
   "metadata": {},
   "source": [
    "### üîß Melhorias Avan√ßadas Poss√≠veis\n",
    "\n",
    "**1. Persist√™ncia de Mem√≥ria com Redis:**\n",
    "\n",
    "```python\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    return RedisChatMessageHistory(\n",
    "        session_id=session_id,\n",
    "        url=\"redis://localhost:6379\"\n",
    "    )\n",
    "\n",
    "# Vantagens:\n",
    "# ‚úÖ Sobrevive a restarts\n",
    "# ‚úÖ Compartilh√°vel entre processos\n",
    "# ‚úÖ TTL autom√°tico (expira conversas antigas)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**2. Summariza√ß√£o de Conversas Longas:**\n",
    "\n",
    "```python\n",
    "def summarize_long_history(history, llm):\n",
    "    if len(history.messages) > 20:  # Mais de 10 turnos\n",
    "        summary_prompt = f\"\"\"\n",
    "        Resuma esta conversa em 3-4 linhas:\n",
    "        {format_chat_history(history.messages)}\n",
    "        \"\"\"\n",
    "        summary = llm.invoke(summary_prompt)\n",
    "        \n",
    "        # Mant√©m summary + √∫ltimas 6 mensagens\n",
    "        return summary + \"\\n\\n\" + format_chat_history(history.messages[-6:])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**3. Reranking nos Resultados:**\n",
    "\n",
    "```python\n",
    "def chat_with_reranking(self, query):\n",
    "    # 1. Retrieval (Top-10)\n",
    "    docs = vectorstore.search(query, k=10)\n",
    "    \n",
    "    # 2. Rerank (Top-3)\n",
    "    reranked = rerank_with_llm(query, docs, top_n=3)\n",
    "    \n",
    "    # 3. Gera resposta com Top-3\n",
    "    response = llm.invoke(prompt.format(context=reranked))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**4. Streaming de Respostas:**\n",
    "\n",
    "```python\n",
    "def chat_streaming(self, query):\n",
    "    for chunk in llm.stream(prompt):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "        yield chunk\n",
    "\n",
    "# UX: Usu√°rio v√™ resposta sendo gerada em tempo real\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Dica:** Implemente melhorias incrementalmente, testando cada uma isoladamente!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5132d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Resumo\n",
    "\n",
    "### O que voc√™ aprendeu:\n",
    "\n",
    "1. ‚úÖ **Self-Querying:** Extra√ß√£o autom√°tica de filtros com LLM\n",
    "2. ‚úÖ **Mem√≥ria:** Sistema conversacional com hist√≥rico\n",
    "3. ‚úÖ **Integra√ß√£o:** Chatbot completo funcional\n",
    "4. ‚úÖ **Casos de Uso:** Quando e como aplicar na produ√ß√£o\n",
    "\n",
    "---\n",
    "\n",
    "**Parab√©ns! üéâ**\n",
    "\n",
    "Voc√™ implementou um sistema RAG de produ√ß√£o com self-querying e mem√≥ria conversacional!\n",
    "\n",
    "Continue experimentando e adaptando para seu caso de uso. üöÄ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3ae12",
   "metadata": {},
   "source": [
    "### ‚úÖ Checklist de Aprendizagem\n",
    "\n",
    "Marque o que voc√™ conseguiu compreender:\n",
    "\n",
    "**Conceitos Fundamentais:**\n",
    "- [ ] O que √© Self-Querying e por que usar\n",
    "- [ ] Como funciona mem√≥ria conversacional\n",
    "- [ ] Diferen√ßa entre RAG b√°sico e avan√ßado\n",
    "- [ ] Import√¢ncia de metadados em documentos\n",
    "\n",
    "**Implementa√ß√£o T√©cnica:**\n",
    "- [ ] Extra√ß√£o de filtros com LLM e JSON\n",
    "- [ ] Uso de InMemoryChatMessageHistory\n",
    "- [ ] Cria√ß√£o de prompts estruturados\n",
    "- [ ] Integra√ß√£o completa em chatbot\n",
    "\n",
    "**An√°lise Pr√°tica:**\n",
    "- [ ] Interpretar resultados de self-querying\n",
    "- [ ] Identificar resolu√ß√£o de an√°fora\n",
    "- [ ] Avaliar trade-offs de cada abordagem\n",
    "- [ ] Escolher quando usar estas t√©cnicas\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Desafios Propostos\n",
    "\n",
    "**N√≠vel 1 - B√°sico:**\n",
    "1. Modifique o prompt de extra√ß√£o para incluir filtro de idioma\n",
    "2. Adicione novos tipos de documentos (slides, v√≠deos)\n",
    "3. Aumente o hist√≥rico para 5 turnos (10 mensagens)\n",
    "\n",
    "**N√≠vel 2 - Intermedi√°rio:**\n",
    "1. Implemente persist√™ncia com arquivo JSON\n",
    "2. Adicione contagem de tokens no hist√≥rico\n",
    "3. Crie sistema de reset de conversa por comando\n",
    "\n",
    "**N√≠vel 3 - Avan√ßado:**\n",
    "1. Integre reranking aos resultados\n",
    "2. Implemente summariza√ß√£o autom√°tica\n",
    "3. Adicione streaming de respostas\n",
    "4. Crie dashboard com m√©tricas da conversa\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Material Complementar\n",
    "\n",
    "**Artigos Recomendados:**\n",
    "- [LangChain Memory Guide](https://python.langchain.com/docs/expression_language/how_to/message_history)\n",
    "- [FAISS Documentation](https://faiss.ai/)\n",
    "\n",
    "---\n",
    "\n",
    "### üí¨ Perguntas para Reflex√£o\n",
    "\n",
    "1. **Escalabilidade:** Como este sistema se comportaria com 100 usu√°rios simult√¢neos?\n",
    "2. **Seguran√ßa:** Quais riscos de privacidade existem com mem√≥ria compartilhada?\n",
    "3. **Custo:** Vale a pena usar LLM para extra√ß√£o em TODA query?\n",
    "4. **Alternativas:** Quando usar filtros manuais seria melhor?\n",
    "\n",
    "---\n",
    "\n",
    "üéì **Parab√©ns por concluir a pr√°tica!**\n",
    "\n",
    "Voc√™ agora tem conhecimento para construir sistemas RAG de n√≠vel profissional com capacidades conversacionais avan√ßadas!\n",
    "\n",
    "**Pr√≥ximo passo:** Aplique estes conceitos em um projeto real do seu dom√≠nio!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11-34-engenharia-vetorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
