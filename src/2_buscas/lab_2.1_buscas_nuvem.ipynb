{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b325f0f",
   "metadata": {},
   "source": [
    "# üåê Laborat√≥rio: Busca Sem√¢ntica com APIs em Nuvem\n",
    "\n",
    "## O que vamos aprender?\n",
    "\n",
    "Neste notebook, voc√™ vai construir um **sistema de busca inteligente** usando modelos de embeddings hospedados na **nuvem** (OpenAI ou Google) e comparar diferentes **m√©tricas de similaridade**.\n",
    "\n",
    "### Diferen√ßa entre Busca Tradicional vs. Busca Sem√¢ntica\n",
    "\n",
    "**Busca Tradicional (palavras-chave):**\n",
    "\n",
    "```text\n",
    "Query: \"hardware celular\"\n",
    "Resultado: S√≥ encontra documentos com as palavras exatas \"hardware\" e \"celular\"\n",
    "```\n",
    "\n",
    "**Busca Sem√¢ntica (significado):**\n",
    "\n",
    "```text\n",
    "Query: \"hardware celular\"\n",
    "Resultado: Encontra \"iPhone\", \"smartphone\", \"processador mobile\" \n",
    "           mesmo sem as palavras exatas!\n",
    "```\n",
    "\n",
    "### Objetivos deste Lab\n",
    "\n",
    "1. ‚úÖ Criar embeddings usando OpenAI API\n",
    "2. ‚úÖ Indexar documentos com FAISS\n",
    "3. ‚úÖ Comparar **Dist√¢ncia L2 (Euclidiana)** vs **Similaridade de Cosseno**\n",
    "4. ‚úÖ Visualizar e interpretar resultados\n",
    "5. ‚úÖ Entender quando usar cada m√©trica\n",
    "\n",
    "### Por que usar APIs em Nuvem?\n",
    "\n",
    "‚úÖ **Qualidade superior** - Modelos treinados com bilh√µes de documentos  \n",
    "‚úÖ **Sem instala√ß√£o** - N√£o precisa configurar nada localmente  \n",
    "‚úÖ **Sempre atualizado** - Melhorias autom√°ticas pela empresa  \n",
    "‚ö†Ô∏è **Custo** - Paga por uso (mas h√° tiers gratuitos)  \n",
    "‚ö†Ô∏è **Privacidade** - Dados trafegam pela internet\n",
    "\n",
    "üí° **Compara√ß√£o:** Se voc√™ precisa de m√°xima qualidade e tem or√ßamento, use nuvem. Se precisa de privacidade/gratuidade, use Ollama local (veja `lab_2.2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b34f0e4",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Ferramentas que Vamos Usar\n",
    "\n",
    "### 1. LangChain ü¶úüîó\n",
    "**O que √©:** Framework Python que simplifica a integra√ß√£o com APIs de IA  \n",
    "**Por que usar:** C√≥digo padronizado que funciona com OpenAI, Google, Anthropic, etc.  \n",
    "**Analogia:** √â como usar um adaptador universal - voc√™ troca de API mudando 1 linha de c√≥digo\n",
    "\n",
    "### 2. OpenAI Embeddings ‚òÅÔ∏è\n",
    "**O que √©:** API da empresa criadora do ChatGPT para gerar embeddings  \n",
    "**Modelo:** `text-embedding-3-small` - 1536 dimens√µes  \n",
    "**Qualidade:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Estado da arte (SOTA)  \n",
    "**Custo:** ~$0.02 por 1 milh√£o de tokens (muito barato)\n",
    "\n",
    "**Alternativa:** Google Generative AI Embeddings\n",
    "- Modelo: `text-embedding-004` - 768 dimens√µes\n",
    "- Tamb√©m de alta qualidade e com tier gratuito generoso\n",
    "\n",
    "### 3. FAISS üöÄ\n",
    "**O que √©:** Biblioteca do Facebook/Meta para busca vetorial ultrarr√°pida  \n",
    "**Por que usar:** Milh√µes de buscas por segundo, roda em mem√≥ria  \n",
    "**Ideal para:** Prot√≥tipos, aplica√ß√µes com poucos documentos (< 100k)\n",
    "\n",
    "**Fluxo completo:**\n",
    "```\n",
    "Texto ‚Üí OpenAI API ‚Üí Vetor [1536 n√∫meros] ‚Üí FAISS ‚Üí Busca instant√¢nea\n",
    "```\n",
    "\n",
    "### Compara√ß√£o: Nuvem vs. Local\n",
    "\n",
    "| Aspecto | OpenAI (Nuvem) | Ollama (Local) |\n",
    "|---------|----------------|----------------|\n",
    "| **Qualidade** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |\n",
    "| **Velocidade** | ~100ms (lat√™ncia rede) | ~10ms |\n",
    "| **Custo** | $0.02/1M tokens | Gratuito |\n",
    "| **Privacidade** | Dados na nuvem | 100% local |\n",
    "| **Setup** | S√≥ precisa API key | Instalar Ollama |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618018e7",
   "metadata": {},
   "source": [
    "## üéØ Cen√°rio do Experimento\n",
    "\n",
    "Vamos criar um **\"mini Google\"** com documentos de 3 categorias completamente diferentes:\n",
    "\n",
    "| Categoria | Documentos |\n",
    "|-----------|------------|\n",
    "| üñ•Ô∏è **Tecnologia** | iPhone 15, RTX 4090 |\n",
    "| üç∞ **Culin√°ria** | Receita de bolo, Lasanha |\n",
    "| ‚öΩ **Esportes** | Gol de futebol |\n",
    "\n",
    "### O Desafio\n",
    "\n",
    "Faremos uma pergunta que **n√£o cont√©m palavras exatas** dos documentos:\n",
    "\n",
    "**Pergunta:** \"Quero sugest√µes de hardware para computador ou celular\"\n",
    "\n",
    "**Expectativa:**\n",
    "- ‚úÖ Deve retornar: iPhone e RTX 4090 (s√£o hardware!)\n",
    "- ‚ùå N√ÉO deve retornar: Bolo, Lasanha, Gol (n√£o s√£o hardware)\n",
    "\n",
    "### Por que isso √© dif√≠cil?\n",
    "\n",
    "Um sistema de busca tradicional (Ctrl+F) falharia porque:\n",
    "- A palavra \"iPhone\" n√£o aparece na pergunta\n",
    "- A palavra \"RTX 4090\" n√£o aparece na pergunta\n",
    "- Mas a API da OpenAI **entende** que ambos s√£o hardware!\n",
    "\n",
    "üí° **Isso √© Intelig√™ncia Artificial em a√ß√£o!** O modelo GPT aprendeu que \"iPhone = celular = hardware\" e \"RTX 4090 = placa de v√≠deo = hardware\" durante seu treinamento massivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da2c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Se for usar OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings as CloudEmbeddings\n",
    "\n",
    "# Se for usar Google Generative AI\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings as CloudEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b287df5f",
   "metadata": {},
   "source": [
    "## üîå Imports e Configura√ß√£o\n",
    "\n",
    "Bibliotecas que vamos usar:\n",
    "- `os`: Para ler vari√°veis de ambiente (API keys)\n",
    "- `Path` e `load_dotenv`: Para carregar configura√ß√µes do `.env`\n",
    "- `FAISS`: Banco de dados vetorial\n",
    "- `OpenAIEmbeddings`: Modelo de embeddings da OpenAI\n",
    "\n",
    "‚ö†Ô∏è **Importante:** Voc√™ precisa ter uma API key da OpenAI ou do Google no arquivo `.env`:\n",
    "\n",
    "```ini\n",
    "OPENAI_API_KEY=sk-proj-...\n",
    "# GOOGLE_API_KEY=AIza...\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Como obter API key:**\n",
    "1. Crie conta em [platform.openai.com](https://platform.openai.com)\n",
    "2. V√° em \"API Keys\" e clique \"Create new secret key\"\n",
    "3. Copie e cole no arquivo `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf197ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé .env carregado -> E:\\01-projetos\\11-work\\11.34-engenharia-vetorial\\.env\n"
     ]
    }
   ],
   "source": [
    "# 2) Configura√ß√£o e carregamento do .env (simplificado)\n",
    "env_path = Path.cwd().joinpath('..', '..', '.env').resolve()\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f'üîé .env carregado -> {env_path.resolve()}')\n",
    "else:\n",
    "    print('‚ö†Ô∏è  .env n√£o encontrado. Defina as vari√°veis de ambiente manualmente.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd98623",
   "metadata": {},
   "source": [
    "## üîê Carregando Vari√°veis de Ambiente\n",
    "\n",
    "O arquivo `.env` cont√©m informa√ß√µes sens√≠veis:\n",
    "- `OPENAI_API_KEY`: Sua chave de API da OpenAI\n",
    "- `GOOGLE_API_KEY`: (Opcional) Sua chave do Google AI\n",
    "\n",
    "**Por que usar `.env`?**\n",
    "- ‚úÖ Seguran√ßa: N√£o expor chaves no c√≥digo\n",
    "- ‚úÖ Portabilidade: Funciona em dev e produ√ß√£o\n",
    "- ‚úÖ Controle: F√°cil trocar entre contas\n",
    "\n",
    "**Estrutura do `.env`:**\n",
    "```bash\n",
    "OPENAI_API_KEY=sk-proj-abc123...\n",
    "# GOOGLE_API_KEY=AIza...  # Descomente se usar Google\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbaf26e",
   "metadata": {},
   "source": [
    "## üìÑ Passo 1: Preparando os Documentos\n",
    "\n",
    "Aqui temos nosso **dataset de teste** ‚Äî 5 documentos de categorias bem distintas.\n",
    "\n",
    "**Por que categorias diferentes?**\n",
    "Queremos testar se a IA consegue distinguir contextos. Um bom modelo de embedding deve:\n",
    "- Colocar \"iPhone\" e \"RTX 4090\" pr√≥ximos (ambos s√£o tecnologia/hardware)\n",
    "- Colocar \"bolo\" e \"lasanha\" pr√≥ximos (ambos s√£o culin√°ria)\n",
    "- Manter \"gol\" distante de receitas e hardware (esporte √© outro contexto)\n",
    "\n",
    "### Estrutura dos Dados\n",
    "\n",
    "```python\n",
    "meus_textos = [\n",
    "    \"Documento sobre tecnologia...\",  # Categoria: Tech\n",
    "    \"Documento sobre culin√°ria...\",   # Categoria: Food\n",
    "    \"Documento sobre esporte...\",     # Categoria: Sport\n",
    "]\n",
    "```\n",
    "\n",
    "üí° **Conceito importante:** Esses textos s√£o chamados de **corpus** (conjunto de documentos que queremos buscar).\n",
    "\n",
    "### Em Produ√ß√£o\n",
    "\n",
    "Em uma aplica√ß√£o real, esses textos viriam de:\n",
    "- üìÑ PDFs extra√≠dos\n",
    "- üåê P√°ginas web (scraping)\n",
    "- üí¨ Hist√≥rico de conversas\n",
    "- üìä Documenta√ß√£o t√©cnica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da63cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meus_textos = [\n",
    "    \"O novo iPhone 15 tem uma lente perisc√≥pica incr√≠vel.\",    # Tecnologia\n",
    "    \"Para fazer um bolo macio, bata as claras em neve.\",       # Culin√°ria\n",
    "    \"O atacante chutou a bola no √¢ngulo e foi gol.\",           # Esporte\n",
    "    \"A placa de v√≠deo RTX 4090 roda jogos em 4K.\",             # Tecnologia\n",
    "    \"Receita de lasanha √† bolonhesa com muito queijo.\"         # Culin√°ria\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aecab4d",
   "metadata": {},
   "source": [
    "## üß† Passo 2: Inicializando o Modelo de Embeddings\n",
    "\n",
    "Este √© o **\"c√©rebro\"** que transforma texto em vetores num√©ricos via API!\n",
    "\n",
    "### O que s√£o Embeddings?\n",
    "\n",
    "**Embedding** = Representa√ß√£o num√©rica de um texto\n",
    "\n",
    "Exemplo com OpenAI:\n",
    "\n",
    "```text\n",
    "Texto: \"gato\"\n",
    "‚Üì (envia para API da OpenAI)\n",
    "Embedding: [0.12, -0.34, 0.56, 0.89, ..., 0.23]\n",
    "           ‚Üë vetor com 1536 n√∫meros!\n",
    "```\n",
    "\n",
    "### Como funciona?\n",
    "\n",
    "1. Seu texto √© enviado para os servidores da OpenAI.\n",
    "2. O modelo GPT (treinado em trilh√µes de palavras) processa os textos.\n",
    "3. Retorna um vetor que \"captura\" o significado.\n",
    "4. Textos similares t√™m vetores pr√≥ximos.\n",
    "\n",
    "**Visualiza√ß√£o conceitual:**\n",
    "\n",
    "```text\n",
    "Espa√ßo vetorial (imagine em 3D, mas √© 1536D!)\n",
    "\n",
    "  gato ‚Ä¢ ‚Üê pr√≥ximo de ‚Üí ‚Ä¢ felino\n",
    "  \n",
    "  carro ‚Ä¢ ‚Üê DISTANTE de ‚Üí ‚Ä¢ felino\n",
    "```\n",
    "\n",
    "### Modelos Dispon√≠veis\n",
    "\n",
    "**OpenAI:**\n",
    "| Modelo | Dimens√µes | Custo/1M tokens | Qualidade |\n",
    "|--------|-----------|-----------------|-----------|\n",
    "| `text-embedding-3-small` | 1536 | $0.02 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| `text-embedding-3-large` | 3072 | $0.13 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| `text-embedding-ada-002` | 1536 | $0.10 | ‚≠ê‚≠ê‚≠ê‚≠ê (legado) |\n",
    "\n",
    "**Google AI:**\n",
    "| Modelo | Dimens√µes | Custo/1M tokens | Qualidade |\n",
    "|--------|-----------|-------|-----------|\n",
    "| `text-embedding-004` | 768 | Gr√°tis (limite) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| `gemini-embedding-001` | 3072 | Gr√°tis (limite), depois $0.15  | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "\n",
    "### Qual escolher?\n",
    "\n",
    "- **Prot√≥tipo/teste:** `text-embedding-3-small` (OpenAI) - barato e excelente\n",
    "- **M√°xima qualidade:** `text-embedding-3-large` (OpenAI)\n",
    "- **Gr√°tis:** `text-embedding-004` (Google) - tier gratuito generoso\n",
    "\n",
    "üí° **Dica:** O modelo `-small` da OpenAI j√° √© melhor que a maioria dos modelos open-source!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f41cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se for usar OpenAI\n",
    "embeddings = CloudEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Se for usar Google Generative AI\n",
    "# embeddings = CloudEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce7ba2f",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Passo 3: Criando o Banco de Dados Vetorial (Indexa√ß√£o)\n",
    "\n",
    "Aqui acontece a **m√°gica**! Vamos transformar todos os textos em vetores e armazen√°-los no FAISS.\n",
    "\n",
    "### O que acontece nesta linha de c√≥digo?\n",
    "\n",
    "```python\n",
    "vector_store = FAISS.from_texts(meus_textos, embeddings)\n",
    "```\n",
    "\n",
    "**Passo a passo interno:**\n",
    "\n",
    "1. **Para cada texto**, LangChain faz uma chamada √† API:\n",
    "   ```text\n",
    "   \"O novo iPhone 15...\" \n",
    "   ‚Üí üåê API OpenAI \n",
    "   ‚Üí [0.2, -0.5, 0.8, ..., 0.15] (1536 n√∫meros)\n",
    "   \n",
    "   \"Para fazer um bolo...\" \n",
    "   ‚Üí üåê API OpenAI \n",
    "   ‚Üí [0.1, 0.3, -0.4, ..., -0.22] (1536 n√∫meros)\n",
    "   ```\n",
    "\n",
    "2. **FAISS armazena** todos esses vetores em mem√≥ria:\n",
    "   ```text\n",
    "   √çndice FAISS (RAM):\n",
    "   [0] ‚Üí [0.2, -0.5, ...] (iPhone)\n",
    "   [1] ‚Üí [0.1, 0.3, ...] (bolo)\n",
    "   [2] ‚Üí [-0.3, 0.7, ...] (gol)\n",
    "   [3] ‚Üí [0.25, -0.48, ...] (RTX 4090)\n",
    "   [4] ‚Üí [0.12, 0.28, ...] (lasanha)\n",
    "   ```\n",
    "\n",
    "3. **Pronto!** Agora podemos fazer buscas instant√¢neas\n",
    "\n",
    "### Custo desta opera√ß√£o\n",
    "\n",
    "Com OpenAI `text-embedding-3-small`:\n",
    "```text\n",
    "5 documentos √ó ~20 tokens cada = 100 tokens\n",
    "Custo: 100 / 1.000.000 √ó $0.02 = $0.000002 (neglig√≠vel!)\n",
    "```\n",
    "\n",
    "### Analogia\n",
    "\n",
    "Imagine uma biblioteca com milh√µes de livros:\n",
    "- **Sem √≠ndice:** Ler cada livro at√© achar o certo üò∞\n",
    "- **Com FAISS:** Sistema Dewey Decimal turbinado que te leva direto ao livro! üìö‚ú®\n",
    "\n",
    "### üìè M√©tricas de Similaridade: L2 vs Cosseno\n",
    "\n",
    "FAISS suporta diferentes formas de medir \"proximidade\" entre vetores. Vamos criar **dois √≠ndices** e comparar:\n",
    "\n",
    "#### 1. Dist√¢ncia L2 (Euclidiana)\n",
    "\n",
    "**O que mede:** A dist√¢ncia \"em linha reta\" entre dois pontos no espa√ßo vetorial.\n",
    "\n",
    "**F√≥rmula matem√°tica:**\n",
    "$$d_{L2}(v_1, v_2) = \\sqrt{\\sum_{i=1}^{n}(v_{1i} - v_{2i})^2}$$\n",
    "\n",
    "**Analogia:** Dist√¢ncia entre duas cidades no mapa (linha reta).\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- ‚úÖ Simples e intuitiva\n",
    "- ‚úÖ Considera magnitude dos vetores\n",
    "- ‚ö†Ô∏è Sens√≠vel √† escala (vetores maiores t√™m dist√¢ncias maiores)\n",
    "- **Interpreta√ß√£o:** Menor = mais similar (0 = id√™ntico)\n",
    "\n",
    "\n",
    "#### 2. Similaridade Cosseno\n",
    "\n",
    "**O que mede:** O √¢ngulo entre dois vetores (ignora magnitude).\n",
    "\n",
    "**F√≥rmula matem√°tica:**\n",
    "$$\\text{cosine}(v_1, v_2) = \\frac{v_1 \\cdot v_2}{\\|v_1\\| \\times \\|v_2\\|}$$\n",
    "\n",
    "**Analogia:** Dire√ß√£o de duas setas, independente do tamanho.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- ‚úÖ Normalizado entre -1 e 1\n",
    "- ‚úÖ Invariante √† magnitude (s√≥ dire√ß√£o importa)\n",
    "- ‚úÖ Muito usado em NLP e embeddings\n",
    "- **Interpreta√ß√£o:** Maior (cosine) = mais similar (1 = id√™ntico, 0 = perpendicular, -1 = oposto)\n",
    "\n",
    "N√£o confundir maioridade do cosseno com a abertura do √¢ngulo!\n",
    "\n",
    "#### Quando usar cada uma?\n",
    "\n",
    "| Aspecto | L2 (Euclidiana) | Cosseno |\n",
    "|---------|-----------------|---------|\n",
    "| **Sens√≠vel √† magnitude** | ‚úÖ Sim | ‚ùå N√£o |\n",
    "| **Normaliza√ß√£o necess√°ria** | ‚ùå N√£o | ‚úÖ Sim (FAISS faz automaticamente) |\n",
    "| **Uso comum em NLP** | üü° M√©dio | üü¢ Alto |\n",
    "| **Embeddings OpenAI** | üü¢ Funciona bem | üü¢ Funciona bem (recomendado) |\n",
    "| **Interpreta√ß√£o** | Dist√¢ncia (menor = melhor) | Similaridade (maior = melhor) |\n",
    "\n",
    "**üí° Curiosidade:** OpenAI recomenda similaridade de cosseno para seus embeddings, mas ambas funcionam bem na pr√°tica!\n",
    "\n",
    "### FAISS: Tipos de √çndice\n",
    "\n",
    "Vamos criar dois √≠ndices diferentes:\n",
    "\n",
    "1. **IndexFlatL2** - Dist√¢ncia Euclidiana\n",
    "   ```python\n",
    "   FAISS.from_texts(..., distance_strategy=\"EUCLIDEAN_DISTANCE\")\n",
    "   ```\n",
    "\n",
    "2. **IndexFlatIP** - Inner Product (Produto Interno)\n",
    "   ```python\n",
    "   FAISS.from_texts(..., distance_strategy=\"MAX_INNER_PRODUCT\")\n",
    "   ```\n",
    "   - Para vetores normalizados, IP √© equivalente a similaridade de cosseno\n",
    "   - OpenAI j√° normaliza os embeddings automaticamente!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231e1b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Criando √≠ndice com Dist√¢ncia L2 (Euclidiana)...\n",
      "‚úÖ √çndice L2 criado!\n",
      "\n",
      "üìä Criando √≠ndice com Similaridade de Cosseno...\n",
      "‚úÖ √çndice Cosseno criado!\n",
      "\n",
      "üéØ Dois √≠ndices prontos para compara√ß√£o!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "# Criar √≠ndice com Dist√¢ncia L2 (Euclidiana)\n",
    "print(\"üìä Criando √≠ndice com Dist√¢ncia L2 (Euclidiana)...\")\n",
    "vector_store_l2 = FAISS.from_texts(\n",
    "    meus_textos, \n",
    "    embeddings,\n",
    "    distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE\n",
    ")\n",
    "print(\"‚úÖ √çndice L2 criado!\\n\")\n",
    "\n",
    "# Criar √≠ndice com Similaridade de Cosseno (Inner Product para vetores normalizados)\n",
    "print(\"üìä Criando √≠ndice com Similaridade de Cosseno...\")\n",
    "vector_store_cosine = FAISS.from_texts(\n",
    "    meus_textos, \n",
    "    embeddings,\n",
    "    distance_strategy=DistanceStrategy.MAX_INNER_PRODUCT\n",
    ")\n",
    "print(\"‚úÖ √çndice Cosseno criado!\\n\")\n",
    "\n",
    "print(\"üéØ Dois √≠ndices prontos para compara√ß√£o!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846679db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Hora de Testar! Vamos Fazer Buscas\n",
    "\n",
    "Configura√ß√£o conclu√≠da! ‚úÖ  \n",
    "Agora vamos usar nosso sistema de busca sem√¢ntica com a qualidade da OpenAI.\n",
    "\n",
    "**O que fizemos at√© agora:**\n",
    "1. ‚úÖ Carregamos a API key da OpenAI\n",
    "2. ‚úÖ Criamos um modelo de embeddings (1536 dimens√µes)\n",
    "3. ‚úÖ Indexamos 5 documentos no FAISS \n",
    "4. ‚úÖ FAISS est√° pronto para buscas instant√¢neas\n",
    "\n",
    "**Pr√≥ximo passo:** Fazer perguntas e ver a IA encontrar as respostas! üéØ\n",
    "\n",
    "üí∞ **Custo at√© agora:** ~$0.000002 (menos que um centavo de centavo!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8910e95e",
   "metadata": {},
   "source": [
    "## üîç Passo 4: Definindo a Pergunta (Query)\n",
    "\n",
    "Aqui est√° o **teste de fogo** para a API da OpenAI!\n",
    "\n",
    "### A Pergunta\n",
    "\n",
    "```python\n",
    "\"Quero sugest√µes de hardware para computador ou celular\"\n",
    "```\n",
    "\n",
    "### Por que esta pergunta √© desafiadora?\n",
    "\n",
    "**Palavras que N√ÉO aparecem na pergunta:**\n",
    "- ‚ùå \"iPhone\"\n",
    "- ‚ùå \"RTX\"\n",
    "- ‚ùå \"4090\"\n",
    "- ‚ùå \"placa de v√≠deo\"\n",
    "- ‚ùå \"lente perisc√≥pica\"\n",
    "\n",
    "**Palavras que SIM aparecem:**\n",
    "- ‚úÖ \"hardware\"\n",
    "- ‚úÖ \"computador\"\n",
    "- ‚úÖ \"celular\"\n",
    "\n",
    "### O Desafio\n",
    "\n",
    "Um sistema de busca tradicional (Ctrl+F) **falharia** porque:\n",
    "\n",
    "```text\n",
    "Busca por \"hardware\" ‚Üí N√£o encontra nada (palavra n√£o est√° nos docs)\n",
    "Busca por \"celular\" ‚Üí N√£o encontra \"iPhone\" (palavra diferente)\n",
    "Busca por \"computador\" ‚Üí N√£o encontra \"RTX 4090\" (palavra diferente)\n",
    "```\n",
    "\n",
    "### A Intelig√™ncia da OpenAI\n",
    "\n",
    "A API vai **entender** que:\n",
    "\n",
    "```text\n",
    "\"celular\" ‚âà \"iPhone\" ‚âà \"smartphone\" ‚âà \"telefone m√≥vel\"\n",
    "\"computador\" ‚âà \"PC\" ‚âà \"placa de v√≠deo\" ‚âà \"hardware desktop\"\n",
    "\"hardware\" ‚âà \"equipamento\" ‚âà \"dispositivo eletr√¥nico\"\n",
    "```\n",
    "\n",
    "üí° **Isso √© aprendizado sem√¢ntico!** O modelo GPT foi treinado em uma quantidade massiva de texto da internet e aprendeu rela√ß√µes complexas entre conceitos.\n",
    "\n",
    "### O que acontece nos bastidores?\n",
    "\n",
    "1. Sua pergunta √© enviada para a API da OpenAI\n",
    "2. GPT transforma em vetor: `[0.22, -0.48, 0.79, ..., 0.31]`\n",
    "3. FAISS compara com todos os vetores armazenados\n",
    "4. Retorna os mais pr√≥ximos (mesmo sem palavras iguais!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946d3ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Quero sugest√µes de hardware para computador ou celular\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb8374",
   "metadata": {},
   "source": [
    "## üéØ Passo 5: Comparando M√©tricas de Similaridade\n",
    "\n",
    "Agora vamos **comparar** os resultados usando as duas m√©tricas diferentes!\n",
    "\n",
    "### O que significa `k=2`?\n",
    "\n",
    "```python\n",
    "vector_store.similarity_search(pergunta, k=2)\n",
    "```\n",
    "\n",
    "O par√¢metro `k` define quantos resultados queremos:\n",
    "- `k=1` ‚Üí Retorna apenas o documento mais similar\n",
    "- `k=2` ‚Üí Retorna os 2 documentos mais similares\n",
    "- `k=5` ‚Üí Retorna os 5 documentos mais similares\n",
    "\n",
    "### Fluxo de busca com cada m√©trica\n",
    "\n",
    "#### üîµ Dist√¢ncia L2 (Euclidiana)\n",
    "\n",
    "1. **Sua pergunta vira um vetor (via API OpenAI):**\n",
    "   ```text\n",
    "   \"Quero sugest√µes de hardware...\" \n",
    "   ‚Üí üåê API call\n",
    "   ‚Üí [0.22, -0.48, 0.79, ..., 0.31] (1536 n√∫meros)\n",
    "   ```\n",
    "\n",
    "2. **FAISS calcula dist√¢ncias L2 (local, sem API):**\n",
    "   ```text\n",
    "   d_L2(query, iPhone) = 0.45      ‚Üê Menor dist√¢ncia = mais pr√≥ximo!\n",
    "   d_L2(query, bolo) = 2.89        ‚Üê Distante\n",
    "   d_L2(query, gol) = 3.12         ‚Üê Muito distante\n",
    "   d_L2(query, RTX 4090) = 0.52    ‚Üê Pr√≥ximo!\n",
    "   d_L2(query, lasanha) = 2.76     ‚Üê Distante\n",
    "   ```\n",
    "\n",
    "3. **Ordena por dist√¢ncia (menor = melhor):**\n",
    "   ```text\n",
    "   1¬∫ lugar: iPhone (0.45) ‚Üê Menor dist√¢ncia!\n",
    "   2¬∫ lugar: RTX 4090 (0.52)\n",
    "   ...\n",
    "   ```\n",
    "\n",
    "#### üü¢ Similaridade de Cosseno\n",
    "\n",
    "1. **Mesmo vetor da query** (reutilizado do cache)\n",
    "\n",
    "2. **FAISS calcula produto interno (= cosseno para vetores normalizados):**\n",
    "   ```text\n",
    "   cosine(query, iPhone) = 0.95      ‚Üê Alto = muito similar!\n",
    "   cosine(query, bolo) = 0.23        ‚Üê Baixo = pouco similar\n",
    "   cosine(query, gol) = 0.15         ‚Üê Muito baixo\n",
    "   cosine(query, RTX 4090) = 0.92    ‚Üê Alto = similar!\n",
    "   cosine(query, lasanha) = 0.28     ‚Üê Baixo\n",
    "   ```\n",
    "\n",
    "3. **Calcula o √¢ngulo correspondente:**\n",
    "   ```text\n",
    "   √¢ngulo = arccos(cosine)\n",
    "   \n",
    "   √¢ngulo(query, iPhone) = arccos(0.95) ‚âà 18¬∞     ‚Üê Pequeno √¢ngulo!\n",
    "   √¢ngulo(query, bolo) = arccos(0.23) ‚âà 77¬∞       ‚Üê Grande √¢ngulo\n",
    "   √¢ngulo(query, RTX) = arccos(0.92) ‚âà 23¬∞        ‚Üê Pequeno √¢ngulo!\n",
    "   ```\n",
    "\n",
    "4. **Ordena por similaridade (maior = melhor) ou por √¢ngulo (menor = melhor):**\n",
    "   ```text\n",
    "   1¬∫ lugar: iPhone (0.95 / 18¬∞) ‚Üê Maior similaridade / Menor √¢ngulo!\n",
    "   2¬∫ lugar: RTX 4090 (0.92 / 23¬∞)\n",
    "   ...\n",
    "   ```\n",
    "\n",
    "### Diferen√ßas na pr√°tica\n",
    "\n",
    "| Aspecto | L2 (Euclidiana) | Cosseno | \n",
    "|---------|-----------------|---------|\n",
    "| **M√©trica** | Dist√¢ncia | Fator Similaridade ou √Çngulo | \n",
    "| **Escala** | 0 a ‚àû (menor = melhor) | -1 a 1 (maior = melhor) ou 0¬∞ a 180¬∞ (menor = melhor) |\n",
    "| **Sensibilidade** | Magnitude + dire√ß√£o | Apenas dire√ß√£o | \n",
    "| **Normaliza√ß√£o** | N√£o requer | Autom√°tica no FAISS | \n",
    "| **Uso t√≠pico** | Dados n√£o-normalizados | Embeddings de texto | \n",
    "| **Interpreta√ß√£o** | Dist√¢ncia geom√©trica | Produto escalar | \n",
    "\n",
    "### O que esperar?\n",
    "\n",
    "‚úÖ **Ambas devem retornar:** iPhone e RTX 4090 (s√£o hardware!)  \n",
    "‚úÖ **√Çngulos pequenos (<30¬∞)** para documentos relevantes  \n",
    "‚ùå **Nenhuma deve retornar:** Bolo, Lasanha, Gol (n√£o s√£o hardware)  \n",
    "‚ùå **√Çngulos grandes (>60¬∞)** para documentos irrelevantes  \n",
    "\n",
    "**Diferen√ßa esperada:** A **ordem** pode variar ligeiramente, mas os top-k geralmente s√£o os mesmos!\n",
    "\n",
    "**Por qu√™?** OpenAI j√° normaliza os embeddings, ent√£o L2 e Cosseno tendem a concordar na pr√°tica.\n",
    "\n",
    "### Visualiza√ß√£o conceitual (2D, mas √© 1536D!)\n",
    "\n",
    "![calculo similaridade](similaridades.png)\n",
    "\n",
    "Vamos executar e comparar! üëá\n",
    "\n",
    "üí∞ **Custo:** ~$0.000001 por query (uma busca no cache, sem nova API call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2110a5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç COMPARA√á√ÉO DE M√âTRICAS DE SIMILARIDADE - TOP 2 RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "üìù Pergunta: 'Quero sugest√µes de hardware para computador ou celular'\n",
      "\n",
      "\n",
      "üìä COMPARA√á√ÉO LADO A LADO:\n",
      "\n",
      " Rank                                      Doc L2 Score L2 Score Cosseno √Çngulo (¬∞)\n",
      "    1 A placa de v√≠deo RTX 4090 roda jogos em ...   1.4026        0.2983      72.65\n",
      "    2 O novo iPhone 15 tem uma lente perisc√≥pi...   1.4345        0.2828      73.57\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üí° INTERPRETA√á√ÉO:\n",
      "  ‚Ä¢ L2: Menor score = maior similaridade\n",
      "  ‚Ä¢ Cosseno: Maior score = maior similaridade\n",
      "  ‚Ä¢ √Çngulo: Menor √¢ngulo = maior similaridade (0¬∞ = id√™ntico)\n",
      "\n",
      "‚úÖ Ambas m√©tricas concordam no documento mais relevante!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîç COMPARA√á√ÉO DE M√âTRICAS DE SIMILARIDADE - TOP 2 RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìù Pergunta: '{query}'\\n\")\n",
    "\n",
    "# Buscar resultados com ambas m√©tricas\n",
    "resultados_l2 = vector_store_l2.similarity_search_with_score(query, k=2)\n",
    "resultados_cosine = vector_store_cosine.similarity_search_with_score(query, k=2)\n",
    "\n",
    "# Preparar dados para tabela comparativa\n",
    "dados_tabela = []\n",
    "\n",
    "# Processar resultados L2\n",
    "for i, (doc, score) in enumerate(resultados_l2, 1):\n",
    "    dados_tabela.append({\n",
    "        'Rank': i,\n",
    "        'M√©trica': 'üîµ L2 (Euclidiana)',\n",
    "        'Score': f\"{score:.4f}\",\n",
    "        'Interpreta√ß√£o': 'Menor = melhor',\n",
    "        '√Çngulo (¬∞)': '-',\n",
    "        'Documento': doc.page_content[:60] + \"...\" if len(doc.page_content) > 60 else doc.page_content\n",
    "    })\n",
    "\n",
    "# Processar resultados Cosseno\n",
    "for i, (doc, score) in enumerate(resultados_cosine, 1):\n",
    "    # Calcular √¢ngulo\n",
    "    similarity_clamped = np.clip(score, -1.0, 1.0)\n",
    "    angulo_radianos = np.arccos(similarity_clamped)\n",
    "    angulo_graus = np.degrees(angulo_radianos)\n",
    "    \n",
    "    dados_tabela.append({\n",
    "        'Rank': i,\n",
    "        'M√©trica': 'üü¢ Cosseno',\n",
    "        'Score': f\"{score:.4f}\",\n",
    "        'Interpreta√ß√£o': 'Maior = melhor',\n",
    "        '√Çngulo (¬∞)': f\"{angulo_graus:.2f}\",\n",
    "        'Documento': doc.page_content[:60] + \"...\" if len(doc.page_content) > 60 else doc.page_content\n",
    "    })\n",
    "\n",
    "# Criar DataFrame\n",
    "df_resultados = pd.DataFrame(dados_tabela)\n",
    "\n",
    "# Criar tabela comparativa lado a lado\n",
    "print(\"\\nüìä COMPARA√á√ÉO LADO A LADO:\\n\")\n",
    "\n",
    "# Preparar dados para tabela comparativa final\n",
    "dados_lado_a_lado = []\n",
    "\n",
    "for i in range(2):\n",
    "    doc_l2, score_l2 = resultados_l2[i]\n",
    "    doc_cosine, score_cosine = resultados_cosine[i]\n",
    "    \n",
    "    # Calcular √¢ngulo para o cosseno\n",
    "    similarity_clamped = np.clip(score_cosine, -1.0, 1.0)\n",
    "    angulo_graus = np.degrees(np.arccos(similarity_clamped))\n",
    "    \n",
    "    dados_lado_a_lado.append({\n",
    "        'Rank': i + 1,\n",
    "        'Doc L2': doc_l2.page_content[:40] + \"...\",\n",
    "        'Score L2': f\"{score_l2:.4f}\",\n",
    "        # 'Doc Cosseno': doc_cosine.page_content[:40] + \"...\",\n",
    "        'Score Cosseno': f\"{score_cosine:.4f}\",\n",
    "        '√Çngulo (¬∞)': f\"{angulo_graus:.2f}\"\n",
    "    })\n",
    "\n",
    "df_lado_a_lado = pd.DataFrame(dados_lado_a_lado)\n",
    "try:\n",
    "    print(df_lado_a_lado.to_markdown(index=False))\n",
    "except ImportError:\n",
    "    print(df_lado_a_lado.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüí° INTERPRETA√á√ÉO:\")\n",
    "print(\"  ‚Ä¢ L2: Menor score = maior similaridade\")\n",
    "print(\"  ‚Ä¢ Cosseno: Maior score = maior similaridade\")\n",
    "print(\"  ‚Ä¢ √Çngulo: Menor √¢ngulo = maior similaridade (0¬∞ = id√™ntico)\")\n",
    "\n",
    "# Verificar concord√¢ncia\n",
    "if resultados_l2[0][0].page_content == resultados_cosine[0][0].page_content:\n",
    "    print(\"\\n‚úÖ Ambas m√©tricas concordam no documento mais relevante!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  M√©tricas divergem - isso pode indicar diferen√ßas na normaliza√ß√£o\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81d186",
   "metadata": {},
   "source": [
    "## üìä An√°lise Comparativa dos Resultados\n",
    "\n",
    "### O que observar?\n",
    "\n",
    "Quando voc√™ executar a c√©lula acima, observe:\n",
    "\n",
    "1. **Os documentos retornados s√£o os mesmos em ambas m√©tricas?**\n",
    "   - ‚úÖ Esperado: Sim, geralmente os top-k s√£o id√™nticos\n",
    "   - ü§î Se diferentes: Pode indicar que magnitude dos vetores importa\n",
    "\n",
    "2. **A ordem √© a mesma?**\n",
    "   - ‚úÖ Geralmente sim, pois OpenAI normaliza embeddings\n",
    "   - ü§î Pequenas varia√ß√µes s√£o normais\n",
    "\n",
    "3. **Os scores fazem sentido?**\n",
    "   - **L2:** Valores menores (0.3-1.5 = muito relevante, >3.0 = pouco relevante)\n",
    "   - **Cosseno:** Valores maiores (>0.9 = muito relevante, <0.5 = pouco relevante)\n",
    "\n",
    "### Por que as m√©tricas concordam?\n",
    "\n",
    "**Embeddings da OpenAI s√£o normalizados:**\n",
    "- Todos os vetores t√™m magnitude ~1.0\n",
    "- Quando magnitude √© constante, L2 e Cosseno s√£o equivalentes\n",
    "- F√≥rmula: Para vetores unit√°rios, $d_{L2}^2 \\approx 2(1 - \\text{cosine})$\n",
    "\n",
    "**Visualiza√ß√£o matem√°tica:**\n",
    "\n",
    "Se $\\|v_1\\| = \\|v_2\\| = 1$ (vetores normalizados):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "d_{L2}(v_1, v_2)^2 &= \\|v_1 - v_2\\|^2 \\\\\n",
    "&= \\|v_1\\|^2 + \\|v_2\\|^2 - 2(v_1 \\cdot v_2) \\\\\n",
    "&= 1 + 1 - 2(v_1 \\cdot v_2) \\\\\n",
    "&= 2(1 - \\text{cosine}(v_1, v_2))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Lembre-se que a **norma (magnitude)** de um vetor √©:\n",
    "\n",
    "$$\\|v\\| = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2}$$\n",
    "\n",
    "**Implica√ß√£o:** Rankings tendem a ser id√™nticos!\n",
    "\n",
    "### Quando as m√©tricas podem divergir?\n",
    "\n",
    "1. **Vetores n√£o-normalizados:**\n",
    "   - Se usar modelos locais sem normaliza√ß√£o\n",
    "   - Cosseno ignora magnitude, L2 n√£o\n",
    "\n",
    "2. **Documentos muito curtos vs. muito longos:**\n",
    "   - L2 pode favorecer textos de tamanho similar √† query\n",
    "   - Cosseno √© invariante ao tamanho\n",
    "\n",
    "3. **Multimodalidade (texto + imagens):**\n",
    "   - Diferentes modalidades podem ter escalas diferentes\n",
    "   - Cosseno √© mais robusto\n",
    "\n",
    "### Qual usar em produ√ß√£o?\n",
    "\n",
    "**Recomenda√ß√£o geral:**\n",
    "- üü¢ **Similaridade de Cosseno** - Padr√£o da ind√∫stria para embeddings de texto\n",
    "- üîµ **L2** - Tamb√©m funciona bem com embeddings OpenAI\n",
    "\n",
    "**Decis√£o pr√°tica:**\n",
    "- Para OpenAI/Google embeddings ‚Üí **Cosseno** (conven√ß√£o)\n",
    "- Para embeddings customizados ‚Üí Testar ambos e comparar\n",
    "- Para multimodal ‚Üí **Cosseno** (mais robusto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef1cc27",
   "metadata": {},
   "source": [
    "## üìà An√°lise Detalhada: Todos os Documentos com Scores\n",
    "\n",
    "Vamos ver os scores de **todos** os 5 documentos para entender melhor como cada m√©trica ranqueia os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f3c277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ AN√ÅLISE COMPLETA - TODOS OS DOCUMENTOS\n",
      "======================================================================\n",
      "\n",
      "üìä Tabela Comparativa de Rankings:\n",
      "\n",
      " Rank L2  Rank Cosseno   Categoria                                             Documento Score L2 Score Cosseno √Çngulo (¬∞)\n",
      "       1             1     üñ•Ô∏è Tech           A placa de v√≠deo RTX 4090 roda jogos em 4K.   1.4026        0.2983      72.65\n",
      "       2             2     üñ•Ô∏è Tech O novo iPhone 15 tem uma lente perisc√≥pica incr√≠ve...   1.4345        0.2828      73.57\n",
      "       3             3 üç∞ Culin√°ria      Receita de lasanha √† bolonhesa com muito queijo.   1.6202        0.1900      79.05\n",
      "       4             4 üç∞ Culin√°ria     Para fazer um bolo macio, bata as claras em neve.   1.6491        0.1748      79.93\n",
      "       5             5   ‚öΩ Esporte         O atacante chutou a bola no √¢ngulo e foi gol.   1.7688        0.1156      83.36\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üí° Interpreta√ß√£o:\n",
      "  ‚Ä¢ L2: Scores MENORES = mais similar (dist√¢ncia)\n",
      "  ‚Ä¢ Cosseno: Scores MAIORES = mais similar (produto interno)\n",
      "  ‚Ä¢ √Çngulo: MENOR √¢ngulo = mais similar (0¬∞ = id√™ntico, 90¬∞ = perpendicular)\n",
      "  ‚Ä¢ ‚úÖ Documentos de 'Tech' devem ter melhores scores e menores √¢ngulos\n",
      "  ‚Ä¢ ‚ùå Documentos de 'Culin√°ria' e 'Esporte' devem ter scores piores e √¢ngulos maiores\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üî¨ AN√ÅLISE COMPLETA - TODOS OS DOCUMENTOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Buscar TODOS os documentos (k=5)\n",
    "resultados_l2_todos = vector_store_l2.similarity_search_with_score(query, k=5)\n",
    "resultados_cosine_todos = vector_store_cosine.similarity_search_with_score(query, k=5)\n",
    "\n",
    "# Criar tabela comparativa\n",
    "dados_comparacao = []\n",
    "\n",
    "for i in range(5):\n",
    "    doc_l2, score_l2 = resultados_l2_todos[i]\n",
    "    doc_cosine, score_cosine = resultados_cosine_todos[i]\n",
    "    \n",
    "    # Calcular √¢ngulo do cosseno\n",
    "    similarity_clamped = np.clip(score_cosine, -1.0, 1.0)\n",
    "    angulo_radianos = np.arccos(similarity_clamped)\n",
    "    angulo_graus = np.degrees(angulo_radianos)\n",
    "    \n",
    "    # Extrair categoria do documento\n",
    "    texto = doc_l2.page_content\n",
    "    if \"iPhone\" in texto or \"RTX\" in texto or \"placa\" in texto:\n",
    "        categoria = \"üñ•Ô∏è Tech\"\n",
    "    elif \"bolo\" in texto or \"lasanha\" in texto or \"Receita\" in texto:\n",
    "        categoria = \"üç∞ Culin√°ria\"\n",
    "    else:\n",
    "        categoria = \"‚öΩ Esporte\"\n",
    "    \n",
    "    dados_comparacao.append({\n",
    "        'Rank L2': i + 1,\n",
    "        'Rank Cosseno': i + 1,\n",
    "        'Categoria': categoria,\n",
    "        'Documento': texto[:50] + \"...\" if len(texto) > 50 else texto,\n",
    "        'Score L2': f\"{score_l2:.4f}\",\n",
    "        'Score Cosseno': f\"{score_cosine:.4f}\",\n",
    "        '√Çngulo (¬∞)': f\"{angulo_graus:.2f}\"\n",
    "    })\n",
    "\n",
    "# Criar DataFrame\n",
    "df_comparacao = pd.DataFrame(dados_comparacao)\n",
    "\n",
    "print(\"\\nüìä Tabela Comparativa de Rankings:\\n\")\n",
    "print(df_comparacao.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüí° Interpreta√ß√£o:\")\n",
    "print(\"  ‚Ä¢ L2: Scores MENORES = mais similar (dist√¢ncia)\")\n",
    "print(\"  ‚Ä¢ Cosseno: Scores MAIORES = mais similar (produto interno)\")\n",
    "print(\"  ‚Ä¢ √Çngulo: MENOR √¢ngulo = mais similar (0¬∞ = id√™ntico, 90¬∞ = perpendicular)\")\n",
    "print(\"  ‚Ä¢ ‚úÖ Documentos de 'Tech' devem ter melhores scores e menores √¢ngulos\")\n",
    "print(\"  ‚Ä¢ ‚ùå Documentos de 'Culin√°ria' e 'Esporte' devem ter scores piores e √¢ngulos maiores\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31830a3e",
   "metadata": {},
   "source": [
    "## üìã Resumo Executivo: L2 vs Cosseno vs √Çngulo\n",
    "\n",
    "### Principais Diferen√ßas\n",
    "\n",
    "| Aspecto | Dist√¢ncia L2 (Euclidiana) | Similaridade de Cosseno | √Çngulo do Cosseno |\n",
    "|---------|---------------------------|------------------------|-------------------|\n",
    "| **F√≥rmula** | $\\sqrt{\\sum(v_1 - v_2)^2}$ | $\\frac{v_1 \\cdot v_2}{\\|v_1\\| \\|v_2\\|}$ | $\\arccos(\\text{cosseno})$ |\n",
    "| **O que mede** | Dist√¢ncia no espa√ßo | Produto escalar normalizado | Orienta√ß√£o angular |\n",
    "| **Escala** | 0 a ‚àû | -1 a 1 | 0¬∞ a 180¬∞ |\n",
    "| **Interpreta√ß√£o** | Menor = mais similar | Maior = mais similar | Menor = mais similar |\n",
    "| **Valor ideal** | 0 (id√™ntico) | 1 (id√™ntico) | 0¬∞ (id√™ntico) |\n",
    "| **Sens√≠vel √† magnitude** | ‚úÖ Sim | ‚ùå N√£o |  |\n",
    "| **Normaliza√ß√£o** | N√£o necess√°ria | Autom√°tica (FAISS) |  |\n",
    "| **Uso em NLP** | üü° Comum | üü¢ Padr√£o da ind√∫stria |  |\n",
    "| **OpenAI/Google** | üü¢ Funciona bem | üü¢ Recomendado |  |\n",
    "| **Performance** | ‚ö° Muito r√°pida | ‚ö° Muito r√°pida |  |\n",
    "\n",
    "### üìê Interpreta√ß√£o do √Çngulo\n",
    "\n",
    "**Faixas de Similaridade:**\n",
    "\n",
    "| √Çngulo | Cosseno aproximado | Classifica√ß√£o | Exemplo |\n",
    "|--------|-------------------|---------------|---------|\n",
    "| **0¬∞ - 30¬∞** | 0.87 - 1.00 | üü¢ Muito similar | Query vs documento relevante |\n",
    "| **30¬∞ - 60¬∞** | 0.50 - 0.87 | üü° Moderadamente similar | T√≥picos relacionados |\n",
    "| **60¬∞ - 90¬∞** | 0.00 - 0.50 | üî¥ Pouco similar | T√≥picos diferentes |\n",
    "| **90¬∞** | 0.00 | ‚ö´ Perpendicular | Sem rela√ß√£o sem√¢ntica |\n",
    "| **90¬∞ - 180¬∞** | -1.00 - 0.00 | üü£ Oposto | Significados contr√°rios |\n",
    "\n",
    "**Vantagens do √Çngulo:**\n",
    "- ‚úÖ **Intui√ß√£o geom√©trica:** F√°cil visualizar mentalmente\n",
    "- ‚úÖ **Escala familiar:** Graus s√£o mais intuitivos que valores -1 a 1\n",
    "- ‚úÖ **Interpreta√ß√£o direta:** \"20¬∞ = muito pr√≥ximo, 80¬∞ = muito distante\"\n",
    "- ‚úÖ **Educacional:** Ajuda a entender embeddings geometricamente\n",
    "\n",
    "**Convers√£o:**\n",
    "```python\n",
    "# De cosseno para √¢ngulo\n",
    "import numpy as np\n",
    "angulo_rad = np.arccos(cosseno)\n",
    "angulo_graus = np.degrees(angulo_rad)\n",
    "\n",
    "# De √¢ngulo para cosseno\n",
    "cosseno = np.cos(np.radians(angulo_graus))\n",
    "```\n",
    "\n",
    "### Resultado Esperado\n",
    "\n",
    "**Para embeddings OpenAI (normalizados):**\n",
    "- ‚úÖ **Rankings id√™nticos** ou muito similares em todas as 3 m√©tricas\n",
    "- ‚úÖ L2 e Cosseno s√£o matematicamente relacionados para vetores unit√°rios\n",
    "- ‚úÖ √Çngulo fornece interpreta√ß√£o mais intuitiva do cosseno\n",
    "- ‚úÖ Todas identificam corretamente documentos relevantes\n",
    "\n",
    "**Rela√ß√£o matem√°tica (vetores normalizados):**\n",
    "$$d_{L2}^2 = 2(1 - \\cos\\theta) = 2(1 - \\text{cosseno})$$\n",
    "\n",
    "**Quando divergem:**\n",
    "- Vetores n√£o-normalizados\n",
    "- Diferentes magnitudes (textos curtos vs longos)\n",
    "- Embeddings customizados sem normaliza√ß√£o\n",
    "\n",
    "### Recomenda√ß√£o Final\n",
    "\n",
    "üèÜ **Use Similaridade de Cosseno** como padr√£o para embeddings de texto (conven√ß√£o da √°rea)\n",
    "\n",
    "üìê **Exiba o √Çngulo** para interpreta√ß√£o humana e visualiza√ß√£o\n",
    "\n",
    "üîß **Use L2** se precisar considerar magnitude dos vetores ou para compatibilidade com sistemas legados\n",
    "\n",
    "### üí° Dica Pr√°tica\n",
    "\n",
    "Para apresenta√ß√µes e relat√≥rios:\n",
    "- **T√©cnico:** Mostre scores de cosseno (valores num√©ricos precisos)\n",
    "- **Gest√£o/Stakeholders:** Mostre √¢ngulos em graus (mais intuitivo)\n",
    "- **Desenvolvedor:** Use L2 se pipeline j√° estiver configurado assim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a986f2",
   "metadata": {},
   "source": [
    "\n",
    "### üß™ Experimentos para Tentar\n",
    "\n",
    "#### Experimento 1: Testar outras queries com ambas m√©tricas\n",
    "```python\n",
    "# Query espec√≠fica\n",
    "pergunta_teste = \"receitas de massas italianas\"\n",
    "\n",
    "print(\"üîµ L2:\")\n",
    "resultados_l2 = vector_store_l2.similarity_search(pergunta_teste, k=2)\n",
    "for doc in resultados_l2:\n",
    "    print(f\"  ‚Ä¢ {doc.page_content}\")\n",
    "\n",
    "print(\"\\nüü¢ Cosseno:\")\n",
    "resultados_cos = vector_store_cosine.similarity_search(pergunta_teste, k=2)\n",
    "for doc in resultados_cos:\n",
    "    print(f\"  ‚Ä¢ {doc.page_content}\")\n",
    "\n",
    "# Deve retornar: lasanha (e talvez bolo como 2¬∫)\n",
    "\n",
    "# Query amb√≠gua\n",
    "pergunta_teste = \"como melhorar performance\"\n",
    "# Vai retornar hardware ou esporte? ü§î\n",
    "# Compare os resultados das duas m√©tricas!\n",
    "\n",
    "# Query fora do dom√≠nio\n",
    "pergunta_teste = \"viagens para a Europa\"\n",
    "# Vai retornar o que est√° \"menos distante\" (mas nada relevante)\n",
    "# As m√©tricas concordam sobre qual √© o \"menos pior\"?\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b0a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2aa056",
   "metadata": {},
   "source": [
    "\n",
    "#### Experimento 2: Ajustar k (Top-K)\n",
    "```python\n",
    "# Ver todos os resultados\n",
    "resultados = vector_store.similarity_search(pergunta, k=5)\n",
    "# Agora voc√™ v√™ TODOS os 5 documentos ordenados por relev√¢ncia\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92009bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb696356",
   "metadata": {},
   "source": [
    "\n",
    "#### Experimento 3: Comparar scores com threshold (limiar de relev√¢ncia)\n",
    "```python\n",
    "# Ver os scores de similaridade e definir um threshold\n",
    "pergunta_teste = \"Quero sugest√µes de hardware para computador ou celular\"\n",
    "\n",
    "print(\"üîµ L2 - An√°lise de Threshold:\")\n",
    "resultados_l2 = vector_store_l2.similarity_search_with_score(pergunta_teste, k=5)\n",
    "for doc, score in resultados_l2:\n",
    "    relevante = \"‚úÖ RELEVANTE\" if score < 1.0 else \"‚ùå IRRELEVANTE\"\n",
    "    print(f\"  Score: {score:.4f} {relevante} | {doc.page_content[:50]}\")\n",
    "\n",
    "print(\"\\nüü¢ Cosseno - An√°lise de Threshold:\")\n",
    "resultados_cos = vector_store_cosine.similarity_search_with_score(pergunta_teste, k=5)\n",
    "for doc, score in resultados_cos:\n",
    "    relevante = \"‚úÖ RELEVANTE\" if score > 0.7 else \"‚ùå IRRELEVANTE\"\n",
    "    print(f\"  Score: {score:.4f} {relevante} | {doc.page_content[:50]}\")\n",
    "\n",
    "# T√≠pico para L2: <0.8 = muito relevante, >2.0 = pouco relevante\n",
    "# T√≠pico para Cosseno: >0.8 = muito relevante, <0.5 = pouco relevante\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c9371f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36341ae",
   "metadata": {},
   "source": [
    "\n",
    "#### Experimento 4: Comparar com Google Embeddings\n",
    "```python\n",
    "# Descomente as linhas de GoogleGenerativeAIEmbeddings\n",
    "# Crie um novo vector_store com Google\n",
    "# Compare os resultados!\n",
    "\n",
    "# Perguntas para reflex√£o:\n",
    "# - Os resultados s√£o iguais?\n",
    "# - Um modelo √© mais r√°pido?\n",
    "# - Qual voc√™ prefere?\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e6076",
   "metadata": {},
   "source": [
    "\n",
    "### üí° Conceitos-chave para lembrar\n",
    "\n",
    "1. **Embedding transforma texto em vetor** via API na nuvem\n",
    "2. **OpenAI = qualidade m√°xima** mas paga por uso\n",
    "3. **FAISS armazena vetores** e faz buscas instant√¢neas localmente\n",
    "4. **Duas m√©tricas principais:**\n",
    "   - **L2 (Euclidiana):** Dist√¢ncia no espa√ßo (menor = melhor)\n",
    "   - **Cosseno:** √Çngulo entre vetores (maior = melhor)\n",
    "5. **Para embeddings OpenAI, ambas funcionam bem** (vetores normalizados)\n",
    "6. **k define quantos resultados** voc√™ quer ver\n",
    "7. **Scores ajudam a definir thresholds** de relev√¢ncia\n",
    "\n",
    "### üéØ Quando usar cada m√©trica?\n",
    "\n",
    "| Cen√°rio | M√©trica Recomendada | Motivo |\n",
    "|---------|-------------------|---------|\n",
    "| **Embeddings OpenAI/Google** | üü¢ Cosseno | Padr√£o da ind√∫stria, vetores normalizados |\n",
    "| **Embeddings locais (Ollama)** | üîµ L2 ou üü¢ Cosseno | Testar ambos e comparar |\n",
    "| **Textos de tamanhos muito variados** | üü¢ Cosseno | Invariante √† magnitude |\n",
    "| **Dados n√£o-normalizados** | üîµ L2 | Considera magnitude |\n",
    "| **Multimodal (texto + imagem)** | üü¢ Cosseno | Mais robusto entre modalidades |\n",
    "| **Quando em d√∫vida** | üü¢ Cosseno | Conven√ß√£o para NLP |\n",
    "\n",
    "### üìê Rela√ß√£o matem√°tica entre L2 e Cosseno\n",
    "\n",
    "Para vetores normalizados (||v|| = 1), como os da OpenAI:\n",
    "\n",
    "$$d_{L2}^2(v_1, v_2) = 2(1 - \\cos(v_1, v_2))$$\n",
    "\n",
    "**Implica√ß√£o:** Quando vetores s√£o normalizados, L2 e Cosseno produzem o **mesmo ranking**!\n",
    "\n",
    "A diferen√ßa √© apenas na escala dos scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526314d4",
   "metadata": {},
   "source": [
    "\n",
    "### üí∞ Gest√£o de Custos e Performance\n",
    "\n",
    "**Boas pr√°ticas:**\n",
    "- ‚úÖ Cache embeddings j√° calculados (n√£o recalcular)\n",
    "- ‚úÖ Use batch processing para m√∫ltiplos textos\n",
    "- ‚úÖ Monitore uso com `openai.api_requestor`\n",
    "- ‚úÖ Considere rate limits (3,000 RPM tier gratuito)\n",
    "- ‚úÖ Reutilize √≠ndices FAISS (salve em disco se necess√°rio)\n",
    "\n",
    "**Exemplo de custo real:**\n",
    "```text\n",
    "Aplica√ß√£o com 10k documentos:\n",
    "- Indexa√ß√£o inicial: 10k docs √ó 50 tokens = 500k tokens\n",
    "- Custo: 500k / 1M √ó $0.02 = $0.01 (um centavo!)\n",
    "- Queries: praticamente gr√°tis (<$0.001 por 1000 queries)\n",
    "  (vetores j√° est√£o no cache, busca √© local no FAISS)\n",
    "```\n",
    "\n",
    "**Performance das m√©tricas:**\n",
    "\n",
    "| M√©trica | Velocidade | Mem√≥ria | Precis√£o |\n",
    "|---------|-----------|---------|----------|\n",
    "| **L2** | ‚ö°‚ö°‚ö° Muito r√°pida | üíæ Baixa | ‚úÖ Excelente |\n",
    "| **Cosseno (IP)** | ‚ö°‚ö°‚ö° Muito r√°pida | üíæ Baixa | ‚úÖ Excelente |\n",
    "\n",
    "**Ambas s√£o igualmente r√°pidas no FAISS!** A escolha √© mais sobre interpreta√ß√£o dos scores e conven√ß√£o da √°rea.\n",
    "\n",
    "### ‚ö° Otimiza√ß√µes Avan√ßadas\n",
    "\n",
    "1. **Salvar √≠ndice FAISS em disco:**\n",
    "```python\n",
    "# Salvar\n",
    "vector_store_cosine.save_local(\"meu_indice_faiss\")\n",
    "\n",
    "# Carregar depois (sem chamar API novamente!)\n",
    "vector_store = FAISS.load_local(\"meu_indice_faiss\", embeddings)\n",
    "```\n",
    "\n",
    "2. **Criar √≠ndices mais eficientes para grandes datasets:**\n",
    "```python\n",
    "# IVF (Inverted File) para milh√µes de vetores\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss\n",
    "\n",
    "# Usar IndexIVFFlat ao inv√©s de IndexFlat\n",
    "# Muito mais r√°pido para >100k documentos\n",
    "```\n",
    "\n",
    "3. **Filtrar por metadata antes da busca:**\n",
    "```python\n",
    "# Adicionar metadata aos documentos\n",
    "metadatas = [{\"categoria\": \"tech\"}, {\"categoria\": \"food\"}, ...]\n",
    "vector_store = FAISS.from_texts(textos, embeddings, metadatas=metadatas)\n",
    "\n",
    "# Buscar apenas em uma categoria\n",
    "resultados = vector_store.similarity_search(\n",
    "    pergunta, \n",
    "    k=2,\n",
    "    filter={\"categoria\": \"tech\"}\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf49795",
   "metadata": {},
   "source": [
    "\n",
    "### üéì Em resumo\n",
    "\n",
    "Voc√™ acabou de construir um sistema de busca sem√¢ntica com **qualidade OpenAI** e aprendeu a comparar diferentes m√©tricas de similaridade! üéâ\n",
    "\n",
    "**O que voc√™ dominou:**\n",
    "- ‚úÖ Embeddings via API em nuvem (OpenAI)\n",
    "- ‚úÖ Indexa√ß√£o vetorial com FAISS\n",
    "- ‚úÖ **Dist√¢ncia L2 (Euclidiana)** - mede dist√¢ncia no espa√ßo\n",
    "- ‚úÖ **Similaridade de Cosseno** - mede √¢ngulo entre vetores\n",
    "- ‚úÖ Compara√ß√£o de m√©tricas e interpreta√ß√£o de scores\n",
    "- ‚úÖ Visualiza√ß√£o e an√°lise de resultados\n",
    "- ‚úÖ Otimiza√ß√µes e boas pr√°ticas\n",
    "\n",
    "Este √© o mesmo princ√≠pio usado em:\n",
    "- üîç **Buscadores avan√ßados** (Elasticsearch, Algolia)\n",
    "- ü§ñ **Chatbots empresariais** (RAG - Retrieval Augmented Generation)\n",
    "- üìö **Sistemas de recomenda√ß√£o** (Netflix, Spotify, Amazon)\n",
    "- üî¨ **Ferramentas de pesquisa acad√™mica** (Semantic Scholar)\n",
    "- üíº **Busca sem√¢ntica corporativa** (Confluence, Notion)\n",
    "\n",
    "\n",
    "### üìö Recursos Adicionais\n",
    "\n",
    "**Documenta√ß√£o:**\n",
    "- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)\n",
    "- [FAISS Documentation](https://github.com/facebookresearch/faiss/wiki)\n",
    "- [LangChain Vector Stores](https://python.langchain.com/docs/modules/data_connection/vectorstores/)\n",
    "\n",
    "**Benchmarks:**\n",
    "- [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) - Compare modelos de embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840ed32",
   "metadata": {},
   "source": [
    "### ‚úÖ Checklist de Aprendizado\n",
    "\n",
    "Marque os conceitos que voc√™ compreendeu:\n",
    "\n",
    "**Fundamentos:**\n",
    "- [ ] O que s√£o embeddings e como s√£o gerados via API\n",
    "- [ ] Diferen√ßa entre busca tradicional e sem√¢ntica\n",
    "- [ ] Como FAISS armazena e busca vetores\n",
    "\n",
    "**M√©tricas de Similaridade:**\n",
    "- [ ] O que √© Dist√¢ncia L2 (Euclidiana) e como interpretar\n",
    "- [ ] O que √© Similaridade de Cosseno e como interpretar\n",
    "- [ ] O que √© o √Çngulo do Cosseno e como interpretar\n",
    "- [ ] Diferen√ßas entre as tr√™s m√©tricas\n",
    "- [ ] Quando usar cada uma\n",
    "- [ ] Rela√ß√£o matem√°tica entre cosseno e √¢ngulo (Œ∏ = arccos(similarity))\n",
    "\n",
    "**Pr√°tica:**\n",
    "- [ ] Executei compara√ß√µes com ambas m√©tricas\n",
    "- [ ] Interpretei os scores corretamente (L2, Cosseno e √Çngulo)\n",
    "- [ ] Visualizei os resultados em gr√°ficos\n",
    "- [ ] Testei queries diferentes\n",
    "- [ ] Entendi que √¢ngulos menores = maior similaridade\n",
    "\n",
    "**Conceitos Avan√ßados:**\n",
    "- [ ] Rela√ß√£o matem√°tica entre L2 e Cosseno (vetores normalizados)\n",
    "- [ ] Por que OpenAI normaliza embeddings\n",
    "- [ ] Como definir thresholds de relev√¢ncia (em todas as m√©tricas)\n",
    "- [ ] Estrat√©gias de otimiza√ß√£o (cache, batch processing)\n",
    "- [ ] Convers√£o entre cosseno e √¢ngulo (arccos e cos)\n",
    "\n",
    "**Interpreta√ß√£o Geom√©trica:**\n",
    "- [ ] Visualizei vetores como setas no espa√ßo\n",
    "- [ ] Entendi que 0¬∞ = id√™ntico, 90¬∞ = perpendicular\n",
    "- [ ] Compreendi que √¢ngulo √© mais intuitivo para humanos\n",
    "- [ ] Aprendi faixas de interpreta√ß√£o (0-30¬∞ muito similar, 60-90¬∞ pouco similar)\n",
    "\n",
    "**Se voc√™ marcou todos:** Parab√©ns! Voc√™ est√° pronto para o pr√≥ximo lab! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11-34-engenharia-vetorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
